{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 7.1: Нейронні мережі в розпізнаванні образів. Частина 1\n",
    "### Шевченко Юлія, ФІ-31мн"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e08383b9ff321fbe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Binary Traffic Sign Classificator\n",
    "\n",
    "In this homework, you are going to use the code from ```TrafficSignsClassification``` notebook and create your own traffic sign classifier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27293c7836a926ac"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:30:32.477582Z",
     "start_time": "2024-03-08T20:30:32.473099Z"
    }
   },
   "outputs": [],
   "source": [
    "# All the imports for the task\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: class_id_0, Number of Images: 2220\n",
      "Class: class_id_1, Number of Images: 2250\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Visualize some examples and count images for each class\n",
    "data_dir = '../Lab_7/traffic_signs_set'\n",
    "classes = os.listdir(data_dir)\n",
    "num_images_per_class = {}\n",
    "\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    num_images = len(os.listdir(class_dir))\n",
    "    num_images_per_class[class_name] = num_images\n",
    "    print('Class: {}, Number of Images: {}'.format(class_name, num_images))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:06.909810Z",
     "start_time": "2024-03-08T19:56:06.904416Z"
    }
   },
   "id": "36640f7bff6eac06",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 2: Define the model with one single neuron\n",
    "def create_single_neuron_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Flatten(input_shape=input_shape),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:06.913329Z",
     "start_time": "2024-03-08T19:56:06.909810Z"
    }
   },
   "id": "7f9ddc0488be53f6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 3: Train the model with one single neuron\n",
    "def train_model(model, X_train, y_train, X_val, y_val, batch_size=32, epochs=10):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpoint = ModelCheckpoint('one_neuron.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[checkpoint])\n",
    "    \n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:06.917698Z",
     "start_time": "2024-03-08T19:56:06.913329Z"
    }
   },
   "id": "bbd8c690ca04d6",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 4: Load and preprocess the data\n",
    "image_size = (32, 32)\n",
    "batch_size = 32\n",
    "\n",
    "def load_and_preprocess_data(data_dir, image_size):\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    train_generator = datagen.flow_from_directory(data_dir, target_size=image_size, batch_size=batch_size, class_mode='binary', subset='training')\n",
    "    val_generator = datagen.flow_from_directory(data_dir, target_size=image_size, batch_size=batch_size, class_mode='binary', subset='validation')\n",
    "    \n",
    "    return train_generator, val_generator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:06.922586Z",
     "start_time": "2024-03-08T19:56:06.918697Z"
    }
   },
   "id": "c0f809454a034fb9",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = load_and_preprocess_data(data_dir, image_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:07.020924Z",
     "start_time": "2024-03-08T19:56:06.923585Z"
    }
   },
   "id": "4b4b38320de4a2e0",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 5: Split the data into training, and validation sets\n",
    "# No need to do this since we're using data generators"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:07.023896Z",
     "start_time": "2024-03-08T19:56:07.020924Z"
    }
   },
   "id": "ba5ba85297c0d247",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Study\\Sem_10\\SMPR\\Structural_Methods_of_Pattern_Recognition\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 3073      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3073 (12.00 KB)\n",
      "Trainable params: 3073 (12.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create and compile the model\n",
    "model = create_single_neuron_model(input_shape=(image_size[0], image_size[1], 3))  # 3 for RGB channels\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:07.171508Z",
     "start_time": "2024-03-08T19:56:07.023896Z"
    }
   },
   "id": "8b7d82b705f3bc2c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Study\\Sem_10\\SMPR\\Structural_Methods_of_Pattern_Recognition\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From D:\\Study\\Sem_10\\SMPR\\Structural_Methods_of_Pattern_Recognition\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "WARNING:tensorflow:From D:\\Study\\Sem_10\\SMPR\\Structural_Methods_of_Pattern_Recognition\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.6321 - accuracy: 0.6425\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74720, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 0.6327 - accuracy: 0.6418 - val_loss: 0.5774 - val_accuracy: 0.7472\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.7847\n",
      "Epoch 2: val_accuracy improved from 0.74720 to 0.79306, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5224 - accuracy: 0.7847 - val_loss: 0.5118 - val_accuracy: 0.7931\n",
      "Epoch 3/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4731 - accuracy: 0.8236\n",
      "Epoch 3: val_accuracy improved from 0.79306 to 0.84452, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4713 - accuracy: 0.8255 - val_loss: 0.4678 - val_accuracy: 0.8445\n",
      "Epoch 4/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4232 - accuracy: 0.8638\n",
      "Epoch 4: val_accuracy improved from 0.84452 to 0.87919, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4229 - accuracy: 0.8641 - val_loss: 0.4385 - val_accuracy: 0.8792\n",
      "Epoch 5/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3879 - accuracy: 0.8927\n",
      "Epoch 5: val_accuracy did not improve from 0.87919\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3868 - accuracy: 0.8926 - val_loss: 0.4074 - val_accuracy: 0.8781\n",
      "Epoch 6/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3635 - accuracy: 0.8969\n",
      "Epoch 6: val_accuracy improved from 0.87919 to 0.88926, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3647 - accuracy: 0.8951 - val_loss: 0.3964 - val_accuracy: 0.8893\n",
      "Epoch 7/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3387 - accuracy: 0.9102\n",
      "Epoch 7: val_accuracy improved from 0.88926 to 0.89821, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3392 - accuracy: 0.9102 - val_loss: 0.3718 - val_accuracy: 0.8982\n",
      "Epoch 8/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3163 - accuracy: 0.9211\n",
      "Epoch 8: val_accuracy improved from 0.89821 to 0.90268, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3158 - accuracy: 0.9220 - val_loss: 0.3540 - val_accuracy: 0.9027\n",
      "Epoch 9/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3018 - accuracy: 0.9267\n",
      "Epoch 9: val_accuracy did not improve from 0.90268\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3027 - accuracy: 0.9265 - val_loss: 0.3445 - val_accuracy: 0.9027\n",
      "Epoch 10/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2880 - accuracy: 0.9291\n",
      "Epoch 10: val_accuracy improved from 0.90268 to 0.91611, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2880 - accuracy: 0.9304 - val_loss: 0.3310 - val_accuracy: 0.9161\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Train the model\n",
    "history = train_model(model, train_generator, None, val_generator, None, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:19.567532Z",
     "start_time": "2024-03-08T19:56:07.171508Z"
    }
   },
   "id": "4bef422b4452ce1f",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 8: Plot the training history to see accuracy and loss curves\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:19.818229Z",
     "start_time": "2024-03-08T19:56:19.568531Z"
    }
   },
   "id": "b34a9d87ffb832b4",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 9: Evaluate the model on the test set\n",
    "def evaluate_model(model, test_generator):\n",
    "    model.load_weights('one_neuron.keras')\n",
    "    loss, accuracy = model.evaluate(test_generator)\n",
    "    print('Test Loss: {}, Test Accuracy: {}'.format(loss, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:19.822169Z",
     "start_time": "2024-03-08T19:56:19.819241Z"
    }
   },
   "id": "e54c9d61a5e2a7f7",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 9ms/step - loss: 0.3310 - accuracy: 0.9161\n",
      "Test Loss: 0.3309519588947296, Test Accuracy: 0.9161073565483093\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_generator = val_generator\n",
    "evaluate_model(model, test_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:20.152508Z",
     "start_time": "2024-03-08T19:56:19.823168Z"
    }
   },
   "id": "5485f44d3b5a236",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modifications and additional tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14813942a417e27e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 2: Define the model with one single neuron\n",
    "def create_single_neuron_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Flatten(input_shape=input_shape),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:20.156500Z",
     "start_time": "2024-03-08T19:56:20.153508Z"
    }
   },
   "id": "83346b08c710082a",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 3: Train the model with one single neuron\n",
    "def train_model(model, train_generator, val_generator, optimizer='adam', batch_size=32, epochs=10):\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpoint = ModelCheckpoint('best_neuron.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "    history = model.fit(train_generator, epochs=epochs, batch_size=batch_size, validation_data=val_generator, callbacks=[checkpoint])\n",
    "    \n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:20.162557Z",
     "start_time": "2024-03-08T19:56:20.158494Z"
    }
   },
   "id": "faf6158b43bdbab0",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 4: Load and preprocess the data\n",
    "image_size = (32, 32)\n",
    "batch_size = 32\n",
    "\n",
    "def load_and_preprocess_data(data_dir, image_size):\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    train_generator = datagen.flow_from_directory(data_dir, target_size=image_size, batch_size=batch_size, class_mode='binary', subset='training')\n",
    "    val_generator = datagen.flow_from_directory(data_dir, target_size=image_size, batch_size=batch_size, class_mode='binary', subset='validation')\n",
    "    \n",
    "    return train_generator, val_generator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T19:56:20.167339Z",
     "start_time": "2024-03-08T19:56:20.163557Z"
    }
   },
   "id": "4e796c6b7565ef1f",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with hyperparameters: {'epochs': 10, 'optimizer': 'adam'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6281 - accuracy: 0.6495\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64094, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 0.6278 - accuracy: 0.6493 - val_loss: 0.6212 - val_accuracy: 0.6409\n",
      "Epoch 2/10\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.5234 - accuracy: 0.7976\n",
      "Epoch 2: val_accuracy improved from 0.64094 to 0.78188, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5220 - accuracy: 0.7989 - val_loss: 0.5182 - val_accuracy: 0.7819\n",
      "Epoch 3/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4842 - accuracy: 0.8082\n",
      "Epoch 3: val_accuracy improved from 0.78188 to 0.80649, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4819 - accuracy: 0.8093 - val_loss: 0.4906 - val_accuracy: 0.8065\n",
      "Epoch 4/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4212 - accuracy: 0.8729\n",
      "Epoch 4: val_accuracy improved from 0.80649 to 0.86465, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4207 - accuracy: 0.8733 - val_loss: 0.4414 - val_accuracy: 0.8647\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8929\n",
      "Epoch 5: val_accuracy improved from 0.86465 to 0.89150, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3863 - accuracy: 0.8929 - val_loss: 0.4135 - val_accuracy: 0.8915\n",
      "Epoch 6/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3647 - accuracy: 0.8995\n",
      "Epoch 6: val_accuracy did not improve from 0.89150\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3647 - accuracy: 0.8990 - val_loss: 0.3919 - val_accuracy: 0.8893\n",
      "Epoch 7/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3403 - accuracy: 0.9137\n",
      "Epoch 7: val_accuracy improved from 0.89150 to 0.89374, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3396 - accuracy: 0.9130 - val_loss: 0.3786 - val_accuracy: 0.8937\n",
      "Epoch 8/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3245 - accuracy: 0.9131\n",
      "Epoch 8: val_accuracy improved from 0.89374 to 0.89709, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3261 - accuracy: 0.9128 - val_loss: 0.3604 - val_accuracy: 0.8971\n",
      "Epoch 9/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3003 - accuracy: 0.9297\n",
      "Epoch 9: val_accuracy improved from 0.89709 to 0.91499, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3009 - accuracy: 0.9293 - val_loss: 0.3441 - val_accuracy: 0.9150\n",
      "Epoch 10/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2910 - accuracy: 0.9309\n",
      "Epoch 10: val_accuracy did not improve from 0.91499\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2903 - accuracy: 0.9315 - val_loss: 0.3378 - val_accuracy: 0.9116\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 10, 'optimizer': 'sgd'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6406 - accuracy: 0.6451\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64765, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 0.6386 - accuracy: 0.6463 - val_loss: 0.6159 - val_accuracy: 0.6477\n",
      "Epoch 2/10\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.5581 - accuracy: 0.7489\n",
      "Epoch 2: val_accuracy improved from 0.64765 to 0.78412, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5571 - accuracy: 0.7506 - val_loss: 0.5423 - val_accuracy: 0.7841\n",
      "Epoch 3/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5162 - accuracy: 0.7887\n",
      "Epoch 3: val_accuracy improved from 0.78412 to 0.81208, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5139 - accuracy: 0.7914 - val_loss: 0.5136 - val_accuracy: 0.8121\n",
      "Epoch 4/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4690 - accuracy: 0.8460\n",
      "Epoch 4: val_accuracy did not improve from 0.81208\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4670 - accuracy: 0.8482 - val_loss: 0.4878 - val_accuracy: 0.8121\n",
      "Epoch 5/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4413 - accuracy: 0.8667\n",
      "Epoch 5: val_accuracy improved from 0.81208 to 0.85347, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4389 - accuracy: 0.8677 - val_loss: 0.4547 - val_accuracy: 0.8535\n",
      "Epoch 6/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4174 - accuracy: 0.8700\n",
      "Epoch 6: val_accuracy did not improve from 0.85347\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4170 - accuracy: 0.8714 - val_loss: 0.4789 - val_accuracy: 0.7852\n",
      "Epoch 7/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3963 - accuracy: 0.8901\n",
      "Epoch 7: val_accuracy improved from 0.85347 to 0.86913, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3969 - accuracy: 0.8890 - val_loss: 0.4254 - val_accuracy: 0.8691\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.9044\n",
      "Epoch 8: val_accuracy did not improve from 0.86913\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3773 - accuracy: 0.9044 - val_loss: 0.4198 - val_accuracy: 0.8535\n",
      "Epoch 9/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3659 - accuracy: 0.9037\n",
      "Epoch 9: val_accuracy improved from 0.86913 to 0.90380, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3653 - accuracy: 0.9044 - val_loss: 0.3959 - val_accuracy: 0.9038\n",
      "Epoch 10/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3514 - accuracy: 0.9152\n",
      "Epoch 10: val_accuracy improved from 0.90380 to 0.90716, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3512 - accuracy: 0.9153 - val_loss: 0.3851 - val_accuracy: 0.9072\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 10, 'optimizer': 'rmsprop'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.7032 - accuracy: 0.5767\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60738, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.7033 - accuracy: 0.5763 - val_loss: 0.6575 - val_accuracy: 0.6074\n",
      "Epoch 2/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6104 - accuracy: 0.6689\n",
      "Epoch 2: val_accuracy improved from 0.60738 to 0.64989, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6125 - accuracy: 0.6678 - val_loss: 0.6138 - val_accuracy: 0.6499\n",
      "Epoch 3/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5437 - accuracy: 0.7417\n",
      "Epoch 3: val_accuracy improved from 0.64989 to 0.82774, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5432 - accuracy: 0.7405 - val_loss: 0.5101 - val_accuracy: 0.8277\n",
      "Epoch 4/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4900 - accuracy: 0.7872\n",
      "Epoch 4: val_accuracy did not improve from 0.82774\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4877 - accuracy: 0.7908 - val_loss: 0.5573 - val_accuracy: 0.6957\n",
      "Epoch 5/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4623 - accuracy: 0.8183\n",
      "Epoch 5: val_accuracy improved from 0.82774 to 0.85123, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4595 - accuracy: 0.8182 - val_loss: 0.4417 - val_accuracy: 0.8512\n",
      "Epoch 6/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4222 - accuracy: 0.8466\n",
      "Epoch 6: val_accuracy did not improve from 0.85123\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4229 - accuracy: 0.8451 - val_loss: 0.4268 - val_accuracy: 0.8479\n",
      "Epoch 7/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4016 - accuracy: 0.8555\n",
      "Epoch 7: val_accuracy did not improve from 0.85123\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3983 - accuracy: 0.8591 - val_loss: 0.4544 - val_accuracy: 0.7998\n",
      "Epoch 8/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3809 - accuracy: 0.8623\n",
      "Epoch 8: val_accuracy improved from 0.85123 to 0.89374, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3812 - accuracy: 0.8607 - val_loss: 0.3851 - val_accuracy: 0.8937\n",
      "Epoch 9/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3638 - accuracy: 0.8759\n",
      "Epoch 9: val_accuracy improved from 0.89374 to 0.90045, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3599 - accuracy: 0.8784 - val_loss: 0.3669 - val_accuracy: 0.9004\n",
      "Epoch 10/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3443 - accuracy: 0.8848\n",
      "Epoch 10: val_accuracy did not improve from 0.90045\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3437 - accuracy: 0.8848 - val_loss: 0.4596 - val_accuracy: 0.7729\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 10, 'optimizer': 'adagrad'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6768 - accuracy: 0.5855\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58501, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6767 - accuracy: 0.5853 - val_loss: 0.6773 - val_accuracy: 0.5850\n",
      "Epoch 2/10\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6542 - accuracy: 0.6270\n",
      "Epoch 2: val_accuracy improved from 0.58501 to 0.60962, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6539 - accuracy: 0.6270 - val_loss: 0.6621 - val_accuracy: 0.6096\n",
      "Epoch 3/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6402 - accuracy: 0.6551\n",
      "Epoch 3: val_accuracy improved from 0.60962 to 0.62416, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6403 - accuracy: 0.6560 - val_loss: 0.6549 - val_accuracy: 0.6242\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.6667\n",
      "Epoch 4: val_accuracy improved from 0.62416 to 0.62640, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6305 - accuracy: 0.6667 - val_loss: 0.6426 - val_accuracy: 0.6264\n",
      "Epoch 5/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6227 - accuracy: 0.6738\n",
      "Epoch 5: val_accuracy improved from 0.62640 to 0.63758, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6225 - accuracy: 0.6762 - val_loss: 0.6365 - val_accuracy: 0.6376\n",
      "Epoch 6/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6156 - accuracy: 0.6847\n",
      "Epoch 6: val_accuracy improved from 0.63758 to 0.64877, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6161 - accuracy: 0.6829 - val_loss: 0.6312 - val_accuracy: 0.6488\n",
      "Epoch 7/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6104 - accuracy: 0.6888\n",
      "Epoch 7: val_accuracy improved from 0.64877 to 0.65772, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6102 - accuracy: 0.6882 - val_loss: 0.6270 - val_accuracy: 0.6577\n",
      "Epoch 8/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6058 - accuracy: 0.6965\n",
      "Epoch 8: val_accuracy improved from 0.65772 to 0.66331, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6045 - accuracy: 0.6980 - val_loss: 0.6244 - val_accuracy: 0.6633\n",
      "Epoch 9/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6002 - accuracy: 0.6980\n",
      "Epoch 9: val_accuracy did not improve from 0.66331\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5998 - accuracy: 0.6991 - val_loss: 0.6187 - val_accuracy: 0.6622\n",
      "Epoch 10/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5955 - accuracy: 0.7151\n",
      "Epoch 10: val_accuracy improved from 0.66331 to 0.67338, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5949 - accuracy: 0.7162 - val_loss: 0.6156 - val_accuracy: 0.6734\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 10, 'optimizer': 'adadelta'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7483 - accuracy: 0.4905\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48881, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.7472 - accuracy: 0.4927 - val_loss: 0.7479 - val_accuracy: 0.4888\n",
      "Epoch 2/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7329 - accuracy: 0.4917\n",
      "Epoch 2: val_accuracy did not improve from 0.48881\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7330 - accuracy: 0.4930 - val_loss: 0.7376 - val_accuracy: 0.4709\n",
      "Epoch 3/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7258 - accuracy: 0.4814\n",
      "Epoch 3: val_accuracy did not improve from 0.48881\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7257 - accuracy: 0.4815 - val_loss: 0.7321 - val_accuracy: 0.4597\n",
      "Epoch 4/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7224 - accuracy: 0.4702\n",
      "Epoch 4: val_accuracy did not improve from 0.48881\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7215 - accuracy: 0.4720 - val_loss: 0.7286 - val_accuracy: 0.4497\n",
      "Epoch 5/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7200 - accuracy: 0.4593\n",
      "Epoch 5: val_accuracy did not improve from 0.48881\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7187 - accuracy: 0.4639 - val_loss: 0.7262 - val_accuracy: 0.4430\n",
      "Epoch 6/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7176 - accuracy: 0.4577\n",
      "Epoch 6: val_accuracy did not improve from 0.48881\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7166 - accuracy: 0.4595 - val_loss: 0.7242 - val_accuracy: 0.4385\n",
      "Epoch 7/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7149 - accuracy: 0.4572\n",
      "Epoch 7: val_accuracy did not improve from 0.48881\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7149 - accuracy: 0.4555 - val_loss: 0.7226 - val_accuracy: 0.4407\n",
      "Epoch 8/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7136 - accuracy: 0.4548\n",
      "Epoch 8: val_accuracy did not improve from 0.48881\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7133 - accuracy: 0.4550 - val_loss: 0.7211 - val_accuracy: 0.4396\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.7119 - accuracy: 0.4550\n",
      "Epoch 9: val_accuracy did not improve from 0.48881\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7119 - accuracy: 0.4550 - val_loss: 0.7197 - val_accuracy: 0.4418\n",
      "Epoch 10/10\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.7108 - accuracy: 0.4543\n",
      "Epoch 10: val_accuracy did not improve from 0.48881\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7105 - accuracy: 0.4558 - val_loss: 0.7184 - val_accuracy: 0.4407\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 10, 'optimizer': 'adamax'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6662 - accuracy: 0.6025\n",
      "Epoch 1: val_accuracy improved from -inf to 0.65884, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6632 - accuracy: 0.6082 - val_loss: 0.6277 - val_accuracy: 0.6588\n",
      "Epoch 2/10\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.5944 - accuracy: 0.7118\n",
      "Epoch 2: val_accuracy did not improve from 0.65884\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5946 - accuracy: 0.7100 - val_loss: 0.6506 - val_accuracy: 0.5928\n",
      "Epoch 3/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5541 - accuracy: 0.7565\n",
      "Epoch 3: val_accuracy improved from 0.65884 to 0.73154, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5532 - accuracy: 0.7573 - val_loss: 0.5662 - val_accuracy: 0.7315\n",
      "Epoch 4/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5173 - accuracy: 0.8059\n",
      "Epoch 4: val_accuracy improved from 0.73154 to 0.77517, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5172 - accuracy: 0.8054 - val_loss: 0.5384 - val_accuracy: 0.7752\n",
      "Epoch 5/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4922 - accuracy: 0.8271\n",
      "Epoch 5: val_accuracy improved from 0.77517 to 0.79642, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4916 - accuracy: 0.8261 - val_loss: 0.5073 - val_accuracy: 0.7964\n",
      "Epoch 6/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4661 - accuracy: 0.8443\n",
      "Epoch 6: val_accuracy improved from 0.79642 to 0.80537, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4648 - accuracy: 0.8445 - val_loss: 0.4924 - val_accuracy: 0.8054\n",
      "Epoch 7/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4464 - accuracy: 0.8623\n",
      "Epoch 7: val_accuracy improved from 0.80537 to 0.85347, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4454 - accuracy: 0.8649 - val_loss: 0.4695 - val_accuracy: 0.8535\n",
      "Epoch 8/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4256 - accuracy: 0.8777\n",
      "Epoch 8: val_accuracy did not improve from 0.85347\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4255 - accuracy: 0.8770 - val_loss: 0.4613 - val_accuracy: 0.8333\n",
      "Epoch 9/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4092 - accuracy: 0.8892\n",
      "Epoch 9: val_accuracy improved from 0.85347 to 0.87025, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4079 - accuracy: 0.8901 - val_loss: 0.4410 - val_accuracy: 0.8702\n",
      "Epoch 10/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3962 - accuracy: 0.8845\n",
      "Epoch 10: val_accuracy improved from 0.87025 to 0.87584, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3949 - accuracy: 0.8873 - val_loss: 0.4254 - val_accuracy: 0.8758\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 10, 'optimizer': 'ftrl'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6693 - accuracy: 0.6141\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60291, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6681 - accuracy: 0.6174 - val_loss: 0.6615 - val_accuracy: 0.6029\n",
      "Epoch 2/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6448 - accuracy: 0.6637\n",
      "Epoch 2: val_accuracy improved from 0.60291 to 0.62640, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6447 - accuracy: 0.6639 - val_loss: 0.6506 - val_accuracy: 0.6264\n",
      "Epoch 3/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6320 - accuracy: 0.6939\n",
      "Epoch 3: val_accuracy improved from 0.62640 to 0.64765, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6307 - accuracy: 0.6935 - val_loss: 0.6373 - val_accuracy: 0.6477\n",
      "Epoch 4/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6208 - accuracy: 0.6944\n",
      "Epoch 4: val_accuracy improved from 0.64765 to 0.67002, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6212 - accuracy: 0.6952 - val_loss: 0.6303 - val_accuracy: 0.6700\n",
      "Epoch 5/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6136 - accuracy: 0.7040\n",
      "Epoch 5: val_accuracy improved from 0.67002 to 0.67114, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6133 - accuracy: 0.7044 - val_loss: 0.6254 - val_accuracy: 0.6711\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6060 - accuracy: 0.7097\n",
      "Epoch 6: val_accuracy improved from 0.67114 to 0.67785, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6060 - accuracy: 0.7097 - val_loss: 0.6197 - val_accuracy: 0.6779\n",
      "Epoch 7/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6010 - accuracy: 0.7216\n",
      "Epoch 7: val_accuracy improved from 0.67785 to 0.68792, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6002 - accuracy: 0.7229 - val_loss: 0.6160 - val_accuracy: 0.6879\n",
      "Epoch 8/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5974 - accuracy: 0.7240\n",
      "Epoch 8: val_accuracy did not improve from 0.68792\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5954 - accuracy: 0.7273 - val_loss: 0.6127 - val_accuracy: 0.6868\n",
      "Epoch 9/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5897 - accuracy: 0.7308\n",
      "Epoch 9: val_accuracy improved from 0.68792 to 0.70694, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5902 - accuracy: 0.7301 - val_loss: 0.6072 - val_accuracy: 0.7069\n",
      "Epoch 10/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5857 - accuracy: 0.7358\n",
      "Epoch 10: val_accuracy did not improve from 0.70694\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5861 - accuracy: 0.7346 - val_loss: 0.6039 - val_accuracy: 0.7058\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 10, 'optimizer': 'nadam'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 0.6409 - accuracy: 0.6317\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72819, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6377 - accuracy: 0.6359 - val_loss: 0.5880 - val_accuracy: 0.7282\n",
      "Epoch 2/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5310 - accuracy: 0.7781\n",
      "Epoch 2: val_accuracy improved from 0.72819 to 0.79978, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.5311 - accuracy: 0.7760 - val_loss: 0.5219 - val_accuracy: 0.7998\n",
      "Epoch 3/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4655 - accuracy: 0.8475\n",
      "Epoch 3: val_accuracy improved from 0.79978 to 0.82327, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4649 - accuracy: 0.8490 - val_loss: 0.4752 - val_accuracy: 0.8233\n",
      "Epoch 4/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4195 - accuracy: 0.8729\n",
      "Epoch 4: val_accuracy improved from 0.82327 to 0.86465, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4176 - accuracy: 0.8739 - val_loss: 0.4392 - val_accuracy: 0.8647\n",
      "Epoch 5/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3848 - accuracy: 0.8966\n",
      "Epoch 5: val_accuracy improved from 0.86465 to 0.89038, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3818 - accuracy: 0.8979 - val_loss: 0.4115 - val_accuracy: 0.8904\n",
      "Epoch 6/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3556 - accuracy: 0.9087\n",
      "Epoch 6: val_accuracy improved from 0.89038 to 0.90380, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3558 - accuracy: 0.9086 - val_loss: 0.3885 - val_accuracy: 0.9038\n",
      "Epoch 7/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3333 - accuracy: 0.9217\n",
      "Epoch 7: val_accuracy did not improve from 0.90380\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3319 - accuracy: 0.9220 - val_loss: 0.3786 - val_accuracy: 0.8915\n",
      "Epoch 8/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3138 - accuracy: 0.9255\n",
      "Epoch 8: val_accuracy did not improve from 0.90380\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3136 - accuracy: 0.9251 - val_loss: 0.3558 - val_accuracy: 0.8893\n",
      "Epoch 9/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2951 - accuracy: 0.9300\n",
      "Epoch 9: val_accuracy did not improve from 0.90380\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2959 - accuracy: 0.9287 - val_loss: 0.3529 - val_accuracy: 0.9016\n",
      "Epoch 10/10\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2809 - accuracy: 0.9329\n",
      "Epoch 10: val_accuracy did not improve from 0.90380\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2819 - accuracy: 0.9323 - val_loss: 0.3336 - val_accuracy: 0.9004\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 20, 'optimizer': 'adam'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6387 - accuracy: 0.6395\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63982, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6356 - accuracy: 0.6423 - val_loss: 0.6203 - val_accuracy: 0.6398\n",
      "Epoch 2/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5412 - accuracy: 0.7657\n",
      "Epoch 2: val_accuracy improved from 0.63982 to 0.76510, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5383 - accuracy: 0.7671 - val_loss: 0.5276 - val_accuracy: 0.7651\n",
      "Epoch 3/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4771 - accuracy: 0.8180\n",
      "Epoch 3: val_accuracy improved from 0.76510 to 0.86130, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4755 - accuracy: 0.8213 - val_loss: 0.4761 - val_accuracy: 0.8613\n",
      "Epoch 4/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4285 - accuracy: 0.8741\n",
      "Epoch 4: val_accuracy did not improve from 0.86130\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4278 - accuracy: 0.8744 - val_loss: 0.4498 - val_accuracy: 0.8512\n",
      "Epoch 5/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4024 - accuracy: 0.8747\n",
      "Epoch 5: val_accuracy improved from 0.86130 to 0.89150, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4001 - accuracy: 0.8764 - val_loss: 0.4167 - val_accuracy: 0.8915\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.9013\n",
      "Epoch 6: val_accuracy did not improve from 0.89150\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3678 - accuracy: 0.9013 - val_loss: 0.4207 - val_accuracy: 0.8523\n",
      "Epoch 7/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3480 - accuracy: 0.9072\n",
      "Epoch 7: val_accuracy improved from 0.89150 to 0.89821, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3479 - accuracy: 0.9077 - val_loss: 0.3757 - val_accuracy: 0.8982\n",
      "Epoch 8/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3190 - accuracy: 0.9243\n",
      "Epoch 8: val_accuracy did not improve from 0.89821\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3231 - accuracy: 0.9209 - val_loss: 0.3747 - val_accuracy: 0.8602\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3089 - accuracy: 0.9203\n",
      "Epoch 9: val_accuracy did not improve from 0.89821\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3089 - accuracy: 0.9203 - val_loss: 0.3695 - val_accuracy: 0.8781\n",
      "Epoch 10/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2948 - accuracy: 0.9276\n",
      "Epoch 10: val_accuracy improved from 0.89821 to 0.91499, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2944 - accuracy: 0.9279 - val_loss: 0.3342 - val_accuracy: 0.9150\n",
      "Epoch 11/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2833 - accuracy: 0.9319\n",
      "Epoch 11: val_accuracy did not improve from 0.91499\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2815 - accuracy: 0.9329 - val_loss: 0.3309 - val_accuracy: 0.9105\n",
      "Epoch 12/20\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2688 - accuracy: 0.9391\n",
      "Epoch 12: val_accuracy did not improve from 0.91499\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2688 - accuracy: 0.9388 - val_loss: 0.3242 - val_accuracy: 0.8949\n",
      "Epoch 13/20\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.2620 - accuracy: 0.9354\n",
      "Epoch 13: val_accuracy did not improve from 0.91499\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2623 - accuracy: 0.9354 - val_loss: 0.3388 - val_accuracy: 0.8781\n",
      "Epoch 14/20\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.2478 - accuracy: 0.9429\n",
      "Epoch 14: val_accuracy improved from 0.91499 to 0.91834, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.2486 - accuracy: 0.9418 - val_loss: 0.2978 - val_accuracy: 0.9183\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.9446\n",
      "Epoch 15: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2429 - accuracy: 0.9446 - val_loss: 0.2915 - val_accuracy: 0.9183\n",
      "Epoch 16/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2425 - accuracy: 0.9379\n",
      "Epoch 16: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2410 - accuracy: 0.9396 - val_loss: 0.2968 - val_accuracy: 0.9139\n",
      "Epoch 17/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2298 - accuracy: 0.9480\n",
      "Epoch 17: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2283 - accuracy: 0.9483 - val_loss: 0.2898 - val_accuracy: 0.9161\n",
      "Epoch 18/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2233 - accuracy: 0.9483\n",
      "Epoch 18: val_accuracy improved from 0.91834 to 0.92841, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2236 - accuracy: 0.9474 - val_loss: 0.2733 - val_accuracy: 0.9284\n",
      "Epoch 19/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2155 - accuracy: 0.9517\n",
      "Epoch 19: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2156 - accuracy: 0.9513 - val_loss: 0.2691 - val_accuracy: 0.9228\n",
      "Epoch 20/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2131 - accuracy: 0.9530\n",
      "Epoch 20: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2117 - accuracy: 0.9541 - val_loss: 0.2669 - val_accuracy: 0.9284\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 20, 'optimizer': 'sgd'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6600 - accuracy: 0.6093\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66555, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6585 - accuracy: 0.6119 - val_loss: 0.6143 - val_accuracy: 0.6655\n",
      "Epoch 2/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5846 - accuracy: 0.7110\n",
      "Epoch 2: val_accuracy did not improve from 0.66555\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5832 - accuracy: 0.7134 - val_loss: 0.6170 - val_accuracy: 0.6152\n",
      "Epoch 3/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5373 - accuracy: 0.7580\n",
      "Epoch 3: val_accuracy improved from 0.66555 to 0.78971, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5338 - accuracy: 0.7623 - val_loss: 0.5286 - val_accuracy: 0.7897\n",
      "Epoch 4/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4897 - accuracy: 0.8141\n",
      "Epoch 4: val_accuracy improved from 0.78971 to 0.82550, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4893 - accuracy: 0.8140 - val_loss: 0.4893 - val_accuracy: 0.8255\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.8319\n",
      "Epoch 5: val_accuracy improved from 0.82550 to 0.85123, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4561 - accuracy: 0.8319 - val_loss: 0.4649 - val_accuracy: 0.8512\n",
      "Epoch 6/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4211 - accuracy: 0.8777\n",
      "Epoch 6: val_accuracy did not improve from 0.85123\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4211 - accuracy: 0.8784 - val_loss: 0.4481 - val_accuracy: 0.8501\n",
      "Epoch 7/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4012 - accuracy: 0.8788\n",
      "Epoch 7: val_accuracy did not improve from 0.85123\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4015 - accuracy: 0.8798 - val_loss: 0.4482 - val_accuracy: 0.8110\n",
      "Epoch 8/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3838 - accuracy: 0.8989\n",
      "Epoch 8: val_accuracy improved from 0.85123 to 0.87248, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3845 - accuracy: 0.8988 - val_loss: 0.4176 - val_accuracy: 0.8725\n",
      "Epoch 9/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3743 - accuracy: 0.9016\n",
      "Epoch 9: val_accuracy did not improve from 0.87248\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3725 - accuracy: 0.9038 - val_loss: 0.4206 - val_accuracy: 0.8523\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3567 - accuracy: 0.9105\n",
      "Epoch 10: val_accuracy improved from 0.87248 to 0.89374, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3567 - accuracy: 0.9105 - val_loss: 0.3917 - val_accuracy: 0.8937\n",
      "Epoch 11/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3461 - accuracy: 0.9131\n",
      "Epoch 11: val_accuracy did not improve from 0.89374\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3457 - accuracy: 0.9139 - val_loss: 0.3958 - val_accuracy: 0.8602\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.9192\n",
      "Epoch 12: val_accuracy improved from 0.89374 to 0.90380, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3328 - accuracy: 0.9192 - val_loss: 0.3746 - val_accuracy: 0.9038\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.9209\n",
      "Epoch 13: val_accuracy did not improve from 0.90380\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3240 - accuracy: 0.9209 - val_loss: 0.3689 - val_accuracy: 0.8937\n",
      "Epoch 14/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3136 - accuracy: 0.9291\n",
      "Epoch 14: val_accuracy improved from 0.90380 to 0.91051, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3157 - accuracy: 0.9276 - val_loss: 0.3590 - val_accuracy: 0.9105\n",
      "Epoch 15/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3066 - accuracy: 0.9238\n",
      "Epoch 15: val_accuracy improved from 0.91051 to 0.91946, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3079 - accuracy: 0.9234 - val_loss: 0.3508 - val_accuracy: 0.9195\n",
      "Epoch 16/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2993 - accuracy: 0.9314\n",
      "Epoch 16: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3008 - accuracy: 0.9315 - val_loss: 0.3470 - val_accuracy: 0.9139\n",
      "Epoch 17/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2954 - accuracy: 0.9329\n",
      "Epoch 17: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2945 - accuracy: 0.9332 - val_loss: 0.3777 - val_accuracy: 0.8602\n",
      "Epoch 18/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2866 - accuracy: 0.9374\n",
      "Epoch 18: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2880 - accuracy: 0.9368 - val_loss: 0.3399 - val_accuracy: 0.8926\n",
      "Epoch 19/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2806 - accuracy: 0.9350\n",
      "Epoch 19: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2818 - accuracy: 0.9337 - val_loss: 0.3299 - val_accuracy: 0.9150\n",
      "Epoch 20/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2765 - accuracy: 0.9418\n",
      "Epoch 20: val_accuracy improved from 0.91946 to 0.92282, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2767 - accuracy: 0.9410 - val_loss: 0.3246 - val_accuracy: 0.9228\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 20, 'optimizer': 'rmsprop'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.7029 - accuracy: 0.5863\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62640, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 0.7018 - accuracy: 0.5870 - val_loss: 0.6392 - val_accuracy: 0.6264\n",
      "Epoch 2/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6053 - accuracy: 0.6912\n",
      "Epoch 2: val_accuracy improved from 0.62640 to 0.65213, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6030 - accuracy: 0.6916 - val_loss: 0.6062 - val_accuracy: 0.6521\n",
      "Epoch 3/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5520 - accuracy: 0.7275\n",
      "Epoch 3: val_accuracy improved from 0.65213 to 0.78523, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5509 - accuracy: 0.7293 - val_loss: 0.5110 - val_accuracy: 0.7852\n",
      "Epoch 4/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4978 - accuracy: 0.7840\n",
      "Epoch 4: val_accuracy improved from 0.78523 to 0.79306, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4974 - accuracy: 0.7824 - val_loss: 0.4998 - val_accuracy: 0.7931\n",
      "Epoch 5/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4664 - accuracy: 0.8029\n",
      "Epoch 5: val_accuracy did not improve from 0.79306\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4632 - accuracy: 0.8056 - val_loss: 0.4979 - val_accuracy: 0.7461\n",
      "Epoch 6/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4333 - accuracy: 0.8342\n",
      "Epoch 6: val_accuracy improved from 0.79306 to 0.85570, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4350 - accuracy: 0.8319 - val_loss: 0.4382 - val_accuracy: 0.8557\n",
      "Epoch 7/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4029 - accuracy: 0.8528\n",
      "Epoch 7: val_accuracy did not improve from 0.85570\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4041 - accuracy: 0.8512 - val_loss: 0.5332 - val_accuracy: 0.7013\n",
      "Epoch 8/20\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.3778 - accuracy: 0.8653\n",
      "Epoch 8: val_accuracy did not improve from 0.85570\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3781 - accuracy: 0.8661 - val_loss: 0.4701 - val_accuracy: 0.7707\n",
      "Epoch 9/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3627 - accuracy: 0.8732\n",
      "Epoch 9: val_accuracy did not improve from 0.85570\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3621 - accuracy: 0.8736 - val_loss: 0.3906 - val_accuracy: 0.8501\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3402 - accuracy: 0.8935\n",
      "Epoch 10: val_accuracy did not improve from 0.85570\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3402 - accuracy: 0.8935 - val_loss: 0.4269 - val_accuracy: 0.7886\n",
      "Epoch 11/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3369 - accuracy: 0.8901\n",
      "Epoch 11: val_accuracy improved from 0.85570 to 0.91275, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3365 - accuracy: 0.8893 - val_loss: 0.3435 - val_accuracy: 0.9128\n",
      "Epoch 12/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3155 - accuracy: 0.9034\n",
      "Epoch 12: val_accuracy did not improve from 0.91275\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3160 - accuracy: 0.9030 - val_loss: 0.3385 - val_accuracy: 0.8982\n",
      "Epoch 13/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3010 - accuracy: 0.9046\n",
      "Epoch 13: val_accuracy did not improve from 0.91275\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3005 - accuracy: 0.9052 - val_loss: 0.3255 - val_accuracy: 0.9105\n",
      "Epoch 14/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2912 - accuracy: 0.9161\n",
      "Epoch 14: val_accuracy did not improve from 0.91275\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2909 - accuracy: 0.9158 - val_loss: 0.3285 - val_accuracy: 0.8926\n",
      "Epoch 15/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2796 - accuracy: 0.9158\n",
      "Epoch 15: val_accuracy did not improve from 0.91275\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2792 - accuracy: 0.9153 - val_loss: 0.3257 - val_accuracy: 0.8993\n",
      "Epoch 16/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2733 - accuracy: 0.9143\n",
      "Epoch 16: val_accuracy did not improve from 0.91275\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2723 - accuracy: 0.9161 - val_loss: 0.3130 - val_accuracy: 0.8937\n",
      "Epoch 17/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2656 - accuracy: 0.9235\n",
      "Epoch 17: val_accuracy improved from 0.91275 to 0.91834, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2691 - accuracy: 0.9206 - val_loss: 0.2970 - val_accuracy: 0.9183\n",
      "Epoch 18/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2527 - accuracy: 0.9255\n",
      "Epoch 18: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2538 - accuracy: 0.9242 - val_loss: 0.2960 - val_accuracy: 0.9072\n",
      "Epoch 19/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2439 - accuracy: 0.9347\n",
      "Epoch 19: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2454 - accuracy: 0.9332 - val_loss: 0.3609 - val_accuracy: 0.8345\n",
      "Epoch 20/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2463 - accuracy: 0.9279\n",
      "Epoch 20: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2456 - accuracy: 0.9287 - val_loss: 0.2824 - val_accuracy: 0.9116\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 20, 'optimizer': 'adagrad'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6637 - accuracy: 0.6389\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63870, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6635 - accuracy: 0.6393 - val_loss: 0.6528 - val_accuracy: 0.6387\n",
      "Epoch 2/20\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6403 - accuracy: 0.6828\n",
      "Epoch 2: val_accuracy improved from 0.63870 to 0.65324, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6405 - accuracy: 0.6826 - val_loss: 0.6407 - val_accuracy: 0.6532\n",
      "Epoch 3/20\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6260 - accuracy: 0.6970\n",
      "Epoch 3: val_accuracy improved from 0.65324 to 0.66219, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6262 - accuracy: 0.6960 - val_loss: 0.6341 - val_accuracy: 0.6622\n",
      "Epoch 4/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6157 - accuracy: 0.6992\n",
      "Epoch 4: val_accuracy improved from 0.66219 to 0.67226, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6162 - accuracy: 0.7016 - val_loss: 0.6257 - val_accuracy: 0.6723\n",
      "Epoch 5/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6085 - accuracy: 0.7119\n",
      "Epoch 5: val_accuracy improved from 0.67226 to 0.67450, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6082 - accuracy: 0.7128 - val_loss: 0.6238 - val_accuracy: 0.6745\n",
      "Epoch 6/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6016 - accuracy: 0.7169\n",
      "Epoch 6: val_accuracy improved from 0.67450 to 0.68121, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6018 - accuracy: 0.7162 - val_loss: 0.6155 - val_accuracy: 0.6812\n",
      "Epoch 7/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5957 - accuracy: 0.7284\n",
      "Epoch 7: val_accuracy improved from 0.68121 to 0.70134, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5959 - accuracy: 0.7296 - val_loss: 0.6122 - val_accuracy: 0.7013\n",
      "Epoch 8/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5888 - accuracy: 0.7320\n",
      "Epoch 8: val_accuracy did not improve from 0.70134\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5903 - accuracy: 0.7315 - val_loss: 0.6067 - val_accuracy: 0.7002\n",
      "Epoch 9/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5875 - accuracy: 0.7332\n",
      "Epoch 9: val_accuracy did not improve from 0.70134\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5861 - accuracy: 0.7349 - val_loss: 0.6028 - val_accuracy: 0.7002\n",
      "Epoch 10/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5825 - accuracy: 0.7367\n",
      "Epoch 10: val_accuracy improved from 0.70134 to 0.70470, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5815 - accuracy: 0.7385 - val_loss: 0.5995 - val_accuracy: 0.7047\n",
      "Epoch 11/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5772 - accuracy: 0.7494\n",
      "Epoch 11: val_accuracy improved from 0.70470 to 0.71141, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5778 - accuracy: 0.7492 - val_loss: 0.5963 - val_accuracy: 0.7114\n",
      "Epoch 12/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5738 - accuracy: 0.7459\n",
      "Epoch 12: val_accuracy improved from 0.71141 to 0.71365, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5736 - accuracy: 0.7478 - val_loss: 0.5934 - val_accuracy: 0.7136\n",
      "Epoch 13/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5697 - accuracy: 0.7524\n",
      "Epoch 13: val_accuracy improved from 0.71365 to 0.71924, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5700 - accuracy: 0.7503 - val_loss: 0.5933 - val_accuracy: 0.7192\n",
      "Epoch 14/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5672 - accuracy: 0.7595\n",
      "Epoch 14: val_accuracy did not improve from 0.71924\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5668 - accuracy: 0.7592 - val_loss: 0.5902 - val_accuracy: 0.7159\n",
      "Epoch 15/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5642 - accuracy: 0.7562\n",
      "Epoch 15: val_accuracy improved from 0.71924 to 0.72148, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5641 - accuracy: 0.7567 - val_loss: 0.5855 - val_accuracy: 0.7215\n",
      "Epoch 16/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5604 - accuracy: 0.7680\n",
      "Epoch 16: val_accuracy improved from 0.72148 to 0.72483, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5609 - accuracy: 0.7682 - val_loss: 0.5832 - val_accuracy: 0.7248\n",
      "Epoch 17/20\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.5583 - accuracy: 0.7647\n",
      "Epoch 17: val_accuracy improved from 0.72483 to 0.73154, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5583 - accuracy: 0.7651 - val_loss: 0.5811 - val_accuracy: 0.7315\n",
      "Epoch 18/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5558 - accuracy: 0.7686\n",
      "Epoch 18: val_accuracy improved from 0.73154 to 0.73266, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5558 - accuracy: 0.7676 - val_loss: 0.5788 - val_accuracy: 0.7327\n",
      "Epoch 19/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5534 - accuracy: 0.7722\n",
      "Epoch 19: val_accuracy improved from 0.73266 to 0.73937, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5529 - accuracy: 0.7732 - val_loss: 0.5768 - val_accuracy: 0.7394\n",
      "Epoch 20/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5505 - accuracy: 0.7822\n",
      "Epoch 20: val_accuracy did not improve from 0.73937\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5508 - accuracy: 0.7816 - val_loss: 0.5746 - val_accuracy: 0.7349\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 20, 'optimizer': 'adadelta'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 1.0051 - accuracy: 0.5020\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50336, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 1.0013 - accuracy: 0.5031 - val_loss: 0.9629 - val_accuracy: 0.5034\n",
      "Epoch 2/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.9442 - accuracy: 0.5021\n",
      "Epoch 2: val_accuracy did not improve from 0.50336\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.9415 - accuracy: 0.5031 - val_loss: 0.9066 - val_accuracy: 0.5022\n",
      "Epoch 3/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.8865 - accuracy: 0.5033\n",
      "Epoch 3: val_accuracy did not improve from 0.50336\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.8850 - accuracy: 0.5031 - val_loss: 0.8554 - val_accuracy: 0.5011\n",
      "Epoch 4/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.8346 - accuracy: 0.5053\n",
      "Epoch 4: val_accuracy did not improve from 0.50336\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.8354 - accuracy: 0.5022 - val_loss: 0.8116 - val_accuracy: 0.4989\n",
      "Epoch 5/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7950 - accuracy: 0.5024\n",
      "Epoch 5: val_accuracy did not improve from 0.50336\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7936 - accuracy: 0.5014 - val_loss: 0.7758 - val_accuracy: 0.4933\n",
      "Epoch 6/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7622 - accuracy: 0.4967\n",
      "Epoch 6: val_accuracy did not improve from 0.50336\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7599 - accuracy: 0.5006 - val_loss: 0.7479 - val_accuracy: 0.4966\n",
      "Epoch 7/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7359 - accuracy: 0.4994\n",
      "Epoch 7: val_accuracy did not improve from 0.50336\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7340 - accuracy: 0.5022 - val_loss: 0.7272 - val_accuracy: 0.4989\n",
      "Epoch 8/20\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.7160 - accuracy: 0.5078\n",
      "Epoch 8: val_accuracy improved from 0.50336 to 0.50895, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7153 - accuracy: 0.5095 - val_loss: 0.7129 - val_accuracy: 0.5089\n",
      "Epoch 9/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7009 - accuracy: 0.5222\n",
      "Epoch 9: val_accuracy improved from 0.50895 to 0.51454, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7023 - accuracy: 0.5213 - val_loss: 0.7035 - val_accuracy: 0.5145\n",
      "Epoch 10/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6948 - accuracy: 0.5334\n",
      "Epoch 10: val_accuracy improved from 0.51454 to 0.53803, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6940 - accuracy: 0.5355 - val_loss: 0.6978 - val_accuracy: 0.5380\n",
      "Epoch 11/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6889 - accuracy: 0.5502\n",
      "Epoch 11: val_accuracy improved from 0.53803 to 0.56040, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6888 - accuracy: 0.5512 - val_loss: 0.6945 - val_accuracy: 0.5604\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.5666\n",
      "Epoch 12: val_accuracy did not improve from 0.56040\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6857 - accuracy: 0.5666 - val_loss: 0.6926 - val_accuracy: 0.5492\n",
      "Epoch 13/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6844 - accuracy: 0.5709\n",
      "Epoch 13: val_accuracy did not improve from 0.56040\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6838 - accuracy: 0.5730 - val_loss: 0.6915 - val_accuracy: 0.5403\n",
      "Epoch 14/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6833 - accuracy: 0.5694\n",
      "Epoch 14: val_accuracy did not improve from 0.56040\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6825 - accuracy: 0.5707 - val_loss: 0.6908 - val_accuracy: 0.5358\n",
      "Epoch 15/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6814 - accuracy: 0.5680\n",
      "Epoch 15: val_accuracy did not improve from 0.56040\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6817 - accuracy: 0.5696 - val_loss: 0.6903 - val_accuracy: 0.5414\n",
      "Epoch 16/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6808 - accuracy: 0.5718\n",
      "Epoch 16: val_accuracy did not improve from 0.56040\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6811 - accuracy: 0.5716 - val_loss: 0.6900 - val_accuracy: 0.5459\n",
      "Epoch 17/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6807 - accuracy: 0.5718\n",
      "Epoch 17: val_accuracy did not improve from 0.56040\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6806 - accuracy: 0.5716 - val_loss: 0.6897 - val_accuracy: 0.5492\n",
      "Epoch 18/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6817 - accuracy: 0.5691\n",
      "Epoch 18: val_accuracy did not improve from 0.56040\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6802 - accuracy: 0.5733 - val_loss: 0.6894 - val_accuracy: 0.5481\n",
      "Epoch 19/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6807 - accuracy: 0.5733\n",
      "Epoch 19: val_accuracy did not improve from 0.56040\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6797 - accuracy: 0.5749 - val_loss: 0.6891 - val_accuracy: 0.5492\n",
      "Epoch 20/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6802 - accuracy: 0.5715\n",
      "Epoch 20: val_accuracy did not improve from 0.56040\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6793 - accuracy: 0.5747 - val_loss: 0.6887 - val_accuracy: 0.5492\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 20, 'optimizer': 'adamax'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6517 - accuracy: 0.6268\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67002, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6499 - accuracy: 0.6298 - val_loss: 0.6176 - val_accuracy: 0.6700\n",
      "Epoch 2/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5898 - accuracy: 0.7119\n",
      "Epoch 2: val_accuracy improved from 0.67002 to 0.72483, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5875 - accuracy: 0.7131 - val_loss: 0.5775 - val_accuracy: 0.7248\n",
      "Epoch 3/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5446 - accuracy: 0.7704\n",
      "Epoch 3: val_accuracy improved from 0.72483 to 0.77517, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5427 - accuracy: 0.7746 - val_loss: 0.5500 - val_accuracy: 0.7752\n",
      "Epoch 4/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5135 - accuracy: 0.8007\n",
      "Epoch 4: val_accuracy did not improve from 0.77517\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5144 - accuracy: 0.7989 - val_loss: 0.5503 - val_accuracy: 0.7438\n",
      "Epoch 5/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4881 - accuracy: 0.8292\n",
      "Epoch 5: val_accuracy did not improve from 0.77517\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4872 - accuracy: 0.8311 - val_loss: 0.5223 - val_accuracy: 0.7729\n",
      "Epoch 6/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4662 - accuracy: 0.8443\n",
      "Epoch 6: val_accuracy improved from 0.77517 to 0.84452, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4661 - accuracy: 0.8434 - val_loss: 0.4853 - val_accuracy: 0.8445\n",
      "Epoch 7/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4444 - accuracy: 0.8673\n",
      "Epoch 7: val_accuracy did not improve from 0.84452\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4442 - accuracy: 0.8669 - val_loss: 0.4700 - val_accuracy: 0.8423\n",
      "Epoch 8/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4237 - accuracy: 0.8794\n",
      "Epoch 8: val_accuracy improved from 0.84452 to 0.86801, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4259 - accuracy: 0.8764 - val_loss: 0.4551 - val_accuracy: 0.8680\n",
      "Epoch 9/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4079 - accuracy: 0.8859\n",
      "Epoch 9: val_accuracy improved from 0.86801 to 0.88591, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4089 - accuracy: 0.8853 - val_loss: 0.4426 - val_accuracy: 0.8859\n",
      "Epoch 10/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3995 - accuracy: 0.8910\n",
      "Epoch 10: val_accuracy did not improve from 0.88591\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3999 - accuracy: 0.8890 - val_loss: 0.4301 - val_accuracy: 0.8635\n",
      "Epoch 11/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3829 - accuracy: 0.8992\n",
      "Epoch 11: val_accuracy did not improve from 0.88591\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3815 - accuracy: 0.9004 - val_loss: 0.4177 - val_accuracy: 0.8792\n",
      "Epoch 12/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3689 - accuracy: 0.9031\n",
      "Epoch 12: val_accuracy improved from 0.88591 to 0.88814, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3694 - accuracy: 0.9041 - val_loss: 0.4089 - val_accuracy: 0.8881\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.9161\n",
      "Epoch 13: val_accuracy improved from 0.88814 to 0.89374, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3562 - accuracy: 0.9161 - val_loss: 0.3963 - val_accuracy: 0.8937\n",
      "Epoch 14/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3435 - accuracy: 0.9146\n",
      "Epoch 14: val_accuracy improved from 0.89374 to 0.90604, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3446 - accuracy: 0.9133 - val_loss: 0.3837 - val_accuracy: 0.9060\n",
      "Epoch 15/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3346 - accuracy: 0.9169\n",
      "Epoch 15: val_accuracy improved from 0.90604 to 0.91051, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3360 - accuracy: 0.9158 - val_loss: 0.3751 - val_accuracy: 0.9105\n",
      "Epoch 16/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3248 - accuracy: 0.9217\n",
      "Epoch 16: val_accuracy did not improve from 0.91051\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3236 - accuracy: 0.9223 - val_loss: 0.3662 - val_accuracy: 0.8993\n",
      "Epoch 17/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3160 - accuracy: 0.9208\n",
      "Epoch 17: val_accuracy did not improve from 0.91051\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3137 - accuracy: 0.9231 - val_loss: 0.3697 - val_accuracy: 0.8982\n",
      "Epoch 18/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3059 - accuracy: 0.9285\n",
      "Epoch 18: val_accuracy improved from 0.91051 to 0.91163, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3057 - accuracy: 0.9284 - val_loss: 0.3513 - val_accuracy: 0.9116\n",
      "Epoch 19/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2965 - accuracy: 0.9309\n",
      "Epoch 19: val_accuracy did not improve from 0.91163\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2983 - accuracy: 0.9298 - val_loss: 0.3459 - val_accuracy: 0.9105\n",
      "Epoch 20/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2929 - accuracy: 0.9335\n",
      "Epoch 20: val_accuracy did not improve from 0.91163\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2932 - accuracy: 0.9337 - val_loss: 0.3474 - val_accuracy: 0.8904\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 20, 'optimizer': 'ftrl'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6677 - accuracy: 0.6034\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62416, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6674 - accuracy: 0.6040 - val_loss: 0.6594 - val_accuracy: 0.6242\n",
      "Epoch 2/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6452 - accuracy: 0.6649\n",
      "Epoch 2: val_accuracy improved from 0.62416 to 0.63199, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6440 - accuracy: 0.6667 - val_loss: 0.6464 - val_accuracy: 0.6320\n",
      "Epoch 3/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6289 - accuracy: 0.6874\n",
      "Epoch 3: val_accuracy improved from 0.63199 to 0.66331, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6310 - accuracy: 0.6818 - val_loss: 0.6377 - val_accuracy: 0.6633\n",
      "Epoch 4/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6229 - accuracy: 0.6939\n",
      "Epoch 4: val_accuracy did not improve from 0.66331\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6215 - accuracy: 0.6971 - val_loss: 0.6352 - val_accuracy: 0.6521\n",
      "Epoch 5/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6151 - accuracy: 0.6995\n",
      "Epoch 5: val_accuracy improved from 0.66331 to 0.67562, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6143 - accuracy: 0.7027 - val_loss: 0.6250 - val_accuracy: 0.6756\n",
      "Epoch 6/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6070 - accuracy: 0.7110\n",
      "Epoch 6: val_accuracy did not improve from 0.67562\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6076 - accuracy: 0.7083 - val_loss: 0.6201 - val_accuracy: 0.6756\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6005 - accuracy: 0.7190\n",
      "Epoch 7: val_accuracy improved from 0.67562 to 0.68456, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6005 - accuracy: 0.7190 - val_loss: 0.6154 - val_accuracy: 0.6846\n",
      "Epoch 8/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5954 - accuracy: 0.7255\n",
      "Epoch 8: val_accuracy improved from 0.68456 to 0.69687, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5961 - accuracy: 0.7248 - val_loss: 0.6115 - val_accuracy: 0.6969\n",
      "Epoch 9/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5909 - accuracy: 0.7308\n",
      "Epoch 9: val_accuracy improved from 0.69687 to 0.69911, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5912 - accuracy: 0.7304 - val_loss: 0.6077 - val_accuracy: 0.6991\n",
      "Epoch 10/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5864 - accuracy: 0.7343\n",
      "Epoch 10: val_accuracy improved from 0.69911 to 0.70246, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5864 - accuracy: 0.7357 - val_loss: 0.6048 - val_accuracy: 0.7025\n",
      "Epoch 11/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5815 - accuracy: 0.7388\n",
      "Epoch 11: val_accuracy improved from 0.70246 to 0.70582, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5830 - accuracy: 0.7377 - val_loss: 0.6019 - val_accuracy: 0.7058\n",
      "Epoch 12/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5786 - accuracy: 0.7447\n",
      "Epoch 12: val_accuracy improved from 0.70582 to 0.71700, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5793 - accuracy: 0.7430 - val_loss: 0.5982 - val_accuracy: 0.7170\n",
      "Epoch 13/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5761 - accuracy: 0.7459\n",
      "Epoch 13: val_accuracy did not improve from 0.71700\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5754 - accuracy: 0.7478 - val_loss: 0.5959 - val_accuracy: 0.7148\n",
      "Epoch 14/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5725 - accuracy: 0.7500\n",
      "Epoch 14: val_accuracy improved from 0.71700 to 0.71812, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 18ms/step - loss: 0.5720 - accuracy: 0.7520 - val_loss: 0.5933 - val_accuracy: 0.7181\n",
      "Epoch 15/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5675 - accuracy: 0.7595\n",
      "Epoch 15: val_accuracy improved from 0.71812 to 0.72371, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5684 - accuracy: 0.7559 - val_loss: 0.5909 - val_accuracy: 0.7237\n",
      "Epoch 16/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5642 - accuracy: 0.7594\n",
      "Epoch 16: val_accuracy improved from 0.72371 to 0.73043, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5657 - accuracy: 0.7576 - val_loss: 0.5879 - val_accuracy: 0.7304\n",
      "Epoch 17/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5621 - accuracy: 0.7689\n",
      "Epoch 17: val_accuracy improved from 0.73043 to 0.73602, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5627 - accuracy: 0.7679 - val_loss: 0.5854 - val_accuracy: 0.7360\n",
      "Epoch 18/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5593 - accuracy: 0.7683\n",
      "Epoch 18: val_accuracy did not improve from 0.73602\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5601 - accuracy: 0.7685 - val_loss: 0.5828 - val_accuracy: 0.7338\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.7710\n",
      "Epoch 19: val_accuracy improved from 0.73602 to 0.73937, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5575 - accuracy: 0.7710 - val_loss: 0.5810 - val_accuracy: 0.7394\n",
      "Epoch 20/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.7710\n",
      "Epoch 20: val_accuracy improved from 0.73937 to 0.74273, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5543 - accuracy: 0.7710 - val_loss: 0.5786 - val_accuracy: 0.7427\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 20, 'optimizer': 'nadam'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6268 - accuracy: 0.6608\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72148, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6222 - accuracy: 0.6678 - val_loss: 0.5779 - val_accuracy: 0.7215\n",
      "Epoch 2/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5214 - accuracy: 0.7970\n",
      "Epoch 2: val_accuracy improved from 0.72148 to 0.79866, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5196 - accuracy: 0.7984 - val_loss: 0.5119 - val_accuracy: 0.7987\n",
      "Epoch 3/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4566 - accuracy: 0.8511\n",
      "Epoch 3: val_accuracy improved from 0.79866 to 0.84340, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4553 - accuracy: 0.8537 - val_loss: 0.4633 - val_accuracy: 0.8434\n",
      "Epoch 4/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4158 - accuracy: 0.8726\n",
      "Epoch 4: val_accuracy improved from 0.84340 to 0.86689, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4125 - accuracy: 0.8758 - val_loss: 0.4376 - val_accuracy: 0.8669\n",
      "Epoch 5/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3782 - accuracy: 0.8960\n",
      "Epoch 5: val_accuracy improved from 0.86689 to 0.87919, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3781 - accuracy: 0.8963 - val_loss: 0.4059 - val_accuracy: 0.8792\n",
      "Epoch 6/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3497 - accuracy: 0.9099\n",
      "Epoch 6: val_accuracy improved from 0.87919 to 0.89821, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3497 - accuracy: 0.9105 - val_loss: 0.3806 - val_accuracy: 0.8982\n",
      "Epoch 7/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3286 - accuracy: 0.9196\n",
      "Epoch 7: val_accuracy improved from 0.89821 to 0.90380, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3276 - accuracy: 0.9203 - val_loss: 0.3673 - val_accuracy: 0.9038\n",
      "Epoch 8/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3073 - accuracy: 0.9269\n",
      "Epoch 8: val_accuracy improved from 0.90380 to 0.90604, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3086 - accuracy: 0.9259 - val_loss: 0.3545 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2915 - accuracy: 0.9309\n",
      "Epoch 9: val_accuracy did not improve from 0.90604\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2923 - accuracy: 0.9306 - val_loss: 0.3369 - val_accuracy: 0.9004\n",
      "Epoch 10/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2802 - accuracy: 0.9343\n",
      "Epoch 10: val_accuracy improved from 0.90604 to 0.91834, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2802 - accuracy: 0.9340 - val_loss: 0.3230 - val_accuracy: 0.9183\n",
      "Epoch 11/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2691 - accuracy: 0.9369\n",
      "Epoch 11: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2671 - accuracy: 0.9379 - val_loss: 0.3482 - val_accuracy: 0.8680\n",
      "Epoch 12/20\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.9419\n",
      "Epoch 12: val_accuracy improved from 0.91834 to 0.92394, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2578 - accuracy: 0.9424 - val_loss: 0.3041 - val_accuracy: 0.9239\n",
      "Epoch 13/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2468 - accuracy: 0.9439\n",
      "Epoch 13: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2458 - accuracy: 0.9441 - val_loss: 0.2961 - val_accuracy: 0.9172\n",
      "Epoch 14/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2411 - accuracy: 0.9474\n",
      "Epoch 14: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2399 - accuracy: 0.9480 - val_loss: 0.3011 - val_accuracy: 0.9038\n",
      "Epoch 15/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2307 - accuracy: 0.9465\n",
      "Epoch 15: val_accuracy improved from 0.92394 to 0.92953, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2315 - accuracy: 0.9457 - val_loss: 0.2831 - val_accuracy: 0.9295\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.9505\n",
      "Epoch 16: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2242 - accuracy: 0.9505 - val_loss: 0.2801 - val_accuracy: 0.9228\n",
      "Epoch 17/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2162 - accuracy: 0.9489\n",
      "Epoch 17: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2169 - accuracy: 0.9494 - val_loss: 0.2715 - val_accuracy: 0.9239\n",
      "Epoch 18/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2130 - accuracy: 0.9527\n",
      "Epoch 18: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2117 - accuracy: 0.9533 - val_loss: 0.2679 - val_accuracy: 0.9273\n",
      "Epoch 19/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2065 - accuracy: 0.9560\n",
      "Epoch 19: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2053 - accuracy: 0.9561 - val_loss: 0.2613 - val_accuracy: 0.9251\n",
      "Epoch 20/20\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1975 - accuracy: 0.9560\n",
      "Epoch 20: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2006 - accuracy: 0.9547 - val_loss: 0.2730 - val_accuracy: 0.9016\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 30, 'optimizer': 'adam'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6435 - accuracy: 0.6288\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72707, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6403 - accuracy: 0.6331 - val_loss: 0.5873 - val_accuracy: 0.7271\n",
      "Epoch 2/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5418 - accuracy: 0.7621\n",
      "Epoch 2: val_accuracy improved from 0.72707 to 0.78635, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5395 - accuracy: 0.7654 - val_loss: 0.5256 - val_accuracy: 0.7864\n",
      "Epoch 3/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4797 - accuracy: 0.8162\n",
      "Epoch 3: val_accuracy improved from 0.78635 to 0.85347, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4778 - accuracy: 0.8194 - val_loss: 0.4794 - val_accuracy: 0.8535\n",
      "Epoch 4/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4358 - accuracy: 0.8638\n",
      "Epoch 4: val_accuracy did not improve from 0.85347\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4328 - accuracy: 0.8652 - val_loss: 0.4753 - val_accuracy: 0.7774\n",
      "Epoch 5/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3984 - accuracy: 0.8853\n",
      "Epoch 5: val_accuracy improved from 0.85347 to 0.86130, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3965 - accuracy: 0.8851 - val_loss: 0.4280 - val_accuracy: 0.8613\n",
      "Epoch 6/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3751 - accuracy: 0.8954\n",
      "Epoch 6: val_accuracy improved from 0.86130 to 0.88367, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3709 - accuracy: 0.8988 - val_loss: 0.3976 - val_accuracy: 0.8837\n",
      "Epoch 7/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3544 - accuracy: 0.8856\n",
      "Epoch 7: val_accuracy did not improve from 0.88367\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3552 - accuracy: 0.8839 - val_loss: 0.3921 - val_accuracy: 0.8758\n",
      "Epoch 8/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3274 - accuracy: 0.9164\n",
      "Epoch 8: val_accuracy improved from 0.88367 to 0.90940, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3240 - accuracy: 0.9175 - val_loss: 0.3616 - val_accuracy: 0.9094\n",
      "Epoch 9/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3067 - accuracy: 0.9258\n",
      "Epoch 9: val_accuracy did not improve from 0.90940\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3070 - accuracy: 0.9251 - val_loss: 0.3526 - val_accuracy: 0.9072\n",
      "Epoch 10/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2975 - accuracy: 0.9252\n",
      "Epoch 10: val_accuracy did not improve from 0.90940\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2981 - accuracy: 0.9256 - val_loss: 0.3666 - val_accuracy: 0.8758\n",
      "Epoch 11/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2799 - accuracy: 0.9365\n",
      "Epoch 11: val_accuracy did not improve from 0.90940\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2805 - accuracy: 0.9354 - val_loss: 0.3613 - val_accuracy: 0.8490\n",
      "Epoch 12/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2777 - accuracy: 0.9303\n",
      "Epoch 12: val_accuracy improved from 0.90940 to 0.92617, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2765 - accuracy: 0.9309 - val_loss: 0.3171 - val_accuracy: 0.9262\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.9281\n",
      "Epoch 13: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2648 - accuracy: 0.9281 - val_loss: 0.3102 - val_accuracy: 0.9139\n",
      "Epoch 14/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2524 - accuracy: 0.9453\n",
      "Epoch 14: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2525 - accuracy: 0.9446 - val_loss: 0.3230 - val_accuracy: 0.9038\n",
      "Epoch 15/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2467 - accuracy: 0.9415\n",
      "Epoch 15: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2471 - accuracy: 0.9410 - val_loss: 0.3012 - val_accuracy: 0.9128\n",
      "Epoch 16/30\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.2398 - accuracy: 0.9378\n",
      "Epoch 16: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2395 - accuracy: 0.9379 - val_loss: 0.2917 - val_accuracy: 0.9161\n",
      "Epoch 17/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2321 - accuracy: 0.9415\n",
      "Epoch 17: val_accuracy improved from 0.92617 to 0.92841, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2333 - accuracy: 0.9410 - val_loss: 0.2829 - val_accuracy: 0.9284\n",
      "Epoch 18/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2237 - accuracy: 0.9498\n",
      "Epoch 18: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2233 - accuracy: 0.9488 - val_loss: 0.2756 - val_accuracy: 0.9284\n",
      "Epoch 19/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2189 - accuracy: 0.9501\n",
      "Epoch 19: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2194 - accuracy: 0.9497 - val_loss: 0.2813 - val_accuracy: 0.9172\n",
      "Epoch 20/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2132 - accuracy: 0.9504\n",
      "Epoch 20: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2134 - accuracy: 0.9508 - val_loss: 0.2780 - val_accuracy: 0.8993\n",
      "Epoch 21/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2103 - accuracy: 0.9492\n",
      "Epoch 21: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2092 - accuracy: 0.9502 - val_loss: 0.2726 - val_accuracy: 0.9172\n",
      "Epoch 22/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2033 - accuracy: 0.9501\n",
      "Epoch 22: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2047 - accuracy: 0.9497 - val_loss: 0.2799 - val_accuracy: 0.9083\n",
      "Epoch 23/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2019 - accuracy: 0.9509\n",
      "Epoch 23: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2003 - accuracy: 0.9505 - val_loss: 0.2574 - val_accuracy: 0.9217\n",
      "Epoch 24/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2021 - accuracy: 0.9462\n",
      "Epoch 24: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2021 - accuracy: 0.9474 - val_loss: 0.2521 - val_accuracy: 0.9228\n",
      "Epoch 25/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1950 - accuracy: 0.9483\n",
      "Epoch 25: val_accuracy improved from 0.92841 to 0.92953, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1941 - accuracy: 0.9491 - val_loss: 0.2466 - val_accuracy: 0.9295\n",
      "Epoch 26/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1888 - accuracy: 0.9527\n",
      "Epoch 26: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1874 - accuracy: 0.9544 - val_loss: 0.2455 - val_accuracy: 0.9295\n",
      "Epoch 27/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1853 - accuracy: 0.9586\n",
      "Epoch 27: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1865 - accuracy: 0.9572 - val_loss: 0.2498 - val_accuracy: 0.9172\n",
      "Epoch 28/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1862 - accuracy: 0.9530\n",
      "Epoch 28: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1850 - accuracy: 0.9527 - val_loss: 0.2491 - val_accuracy: 0.9161\n",
      "Epoch 29/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1784 - accuracy: 0.9589\n",
      "Epoch 29: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1777 - accuracy: 0.9592 - val_loss: 0.2378 - val_accuracy: 0.9295\n",
      "Epoch 30/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1720 - accuracy: 0.9601\n",
      "Epoch 30: val_accuracy improved from 0.92953 to 0.93289, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1739 - accuracy: 0.9600 - val_loss: 0.2312 - val_accuracy: 0.9329\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 30, 'optimizer': 'sgd'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6518 - accuracy: 0.6265\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63311, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6481 - accuracy: 0.6323 - val_loss: 0.6308 - val_accuracy: 0.6331\n",
      "Epoch 2/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5866 - accuracy: 0.7074\n",
      "Epoch 2: val_accuracy improved from 0.63311 to 0.76622, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5829 - accuracy: 0.7134 - val_loss: 0.5505 - val_accuracy: 0.7662\n",
      "Epoch 3/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5262 - accuracy: 0.7828\n",
      "Epoch 3: val_accuracy improved from 0.76622 to 0.80201, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5232 - accuracy: 0.7864 - val_loss: 0.5239 - val_accuracy: 0.8020\n",
      "Epoch 4/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.4811 - accuracy: 0.8217\n",
      "Epoch 4: val_accuracy improved from 0.80201 to 0.80761, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4807 - accuracy: 0.8213 - val_loss: 0.4921 - val_accuracy: 0.8076\n",
      "Epoch 5/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4459 - accuracy: 0.8632\n",
      "Epoch 5: val_accuracy improved from 0.80761 to 0.84676, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4451 - accuracy: 0.8624 - val_loss: 0.4618 - val_accuracy: 0.8468\n",
      "Epoch 6/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4264 - accuracy: 0.8650\n",
      "Epoch 6: val_accuracy improved from 0.84676 to 0.85011, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4242 - accuracy: 0.8686 - val_loss: 0.4425 - val_accuracy: 0.8501\n",
      "Epoch 7/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4030 - accuracy: 0.8815\n",
      "Epoch 7: val_accuracy did not improve from 0.85011\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4037 - accuracy: 0.8792 - val_loss: 0.4636 - val_accuracy: 0.7774\n",
      "Epoch 8/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3816 - accuracy: 0.8933\n",
      "Epoch 8: val_accuracy improved from 0.85011 to 0.89262, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3804 - accuracy: 0.8943 - val_loss: 0.4120 - val_accuracy: 0.8926\n",
      "Epoch 9/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.9083\n",
      "Epoch 9: val_accuracy improved from 0.89262 to 0.90380, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3655 - accuracy: 0.9086 - val_loss: 0.3994 - val_accuracy: 0.9038\n",
      "Epoch 10/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3546 - accuracy: 0.9131\n",
      "Epoch 10: val_accuracy improved from 0.90380 to 0.90716, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3534 - accuracy: 0.9139 - val_loss: 0.3884 - val_accuracy: 0.9072\n",
      "Epoch 11/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3417 - accuracy: 0.9196\n",
      "Epoch 11: val_accuracy did not improve from 0.90716\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3403 - accuracy: 0.9200 - val_loss: 0.3789 - val_accuracy: 0.9049\n",
      "Epoch 12/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3319 - accuracy: 0.9196\n",
      "Epoch 12: val_accuracy improved from 0.90716 to 0.90828, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3323 - accuracy: 0.9209 - val_loss: 0.3729 - val_accuracy: 0.9083\n",
      "Epoch 13/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3200 - accuracy: 0.9241\n",
      "Epoch 13: val_accuracy did not improve from 0.90828\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3196 - accuracy: 0.9248 - val_loss: 0.3679 - val_accuracy: 0.8926\n",
      "Epoch 14/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3162 - accuracy: 0.9246\n",
      "Epoch 14: val_accuracy did not improve from 0.90828\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3157 - accuracy: 0.9242 - val_loss: 0.3621 - val_accuracy: 0.8893\n",
      "Epoch 15/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3059 - accuracy: 0.9294\n",
      "Epoch 15: val_accuracy did not improve from 0.90828\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3068 - accuracy: 0.9279 - val_loss: 0.3577 - val_accuracy: 0.8870\n",
      "Epoch 16/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3005 - accuracy: 0.9317\n",
      "Epoch 16: val_accuracy improved from 0.90828 to 0.91723, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3015 - accuracy: 0.9312 - val_loss: 0.3446 - val_accuracy: 0.9172\n",
      "Epoch 17/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2923 - accuracy: 0.9344\n",
      "Epoch 17: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2940 - accuracy: 0.9340 - val_loss: 0.3385 - val_accuracy: 0.9139\n",
      "Epoch 18/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2871 - accuracy: 0.9322\n",
      "Epoch 18: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2863 - accuracy: 0.9332 - val_loss: 0.3447 - val_accuracy: 0.9038\n",
      "Epoch 19/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2791 - accuracy: 0.9406\n",
      "Epoch 19: val_accuracy improved from 0.91723 to 0.91834, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2803 - accuracy: 0.9390 - val_loss: 0.3309 - val_accuracy: 0.9183\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.9418\n",
      "Epoch 20: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2771 - accuracy: 0.9418 - val_loss: 0.3350 - val_accuracy: 0.8949\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.9390\n",
      "Epoch 21: val_accuracy improved from 0.91834 to 0.91946, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2721 - accuracy: 0.9390 - val_loss: 0.3217 - val_accuracy: 0.9195\n",
      "Epoch 22/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2648 - accuracy: 0.9397\n",
      "Epoch 22: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2689 - accuracy: 0.9374 - val_loss: 0.3171 - val_accuracy: 0.9183\n",
      "Epoch 23/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2649 - accuracy: 0.9421\n",
      "Epoch 23: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2635 - accuracy: 0.9427 - val_loss: 0.3166 - val_accuracy: 0.9161\n",
      "Epoch 24/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2555 - accuracy: 0.9459\n",
      "Epoch 24: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2575 - accuracy: 0.9444 - val_loss: 0.3118 - val_accuracy: 0.9172\n",
      "Epoch 25/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2516 - accuracy: 0.9447\n",
      "Epoch 25: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2537 - accuracy: 0.9441 - val_loss: 0.3092 - val_accuracy: 0.9183\n",
      "Epoch 26/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2525 - accuracy: 0.9453\n",
      "Epoch 26: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2507 - accuracy: 0.9457 - val_loss: 0.3067 - val_accuracy: 0.9139\n",
      "Epoch 27/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2504 - accuracy: 0.9415\n",
      "Epoch 27: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2490 - accuracy: 0.9427 - val_loss: 0.3058 - val_accuracy: 0.9161\n",
      "Epoch 28/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2437 - accuracy: 0.9501\n",
      "Epoch 28: val_accuracy improved from 0.91946 to 0.92170, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2428 - accuracy: 0.9502 - val_loss: 0.2987 - val_accuracy: 0.9217\n",
      "Epoch 29/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2428 - accuracy: 0.9465\n",
      "Epoch 29: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2424 - accuracy: 0.9460 - val_loss: 0.3042 - val_accuracy: 0.9072\n",
      "Epoch 30/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2385 - accuracy: 0.9504\n",
      "Epoch 30: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2381 - accuracy: 0.9491 - val_loss: 0.2930 - val_accuracy: 0.9217\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 30, 'optimizer': 'rmsprop'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6899 - accuracy: 0.5889\n",
      "Epoch 1: val_accuracy improved from -inf to 0.65772, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6883 - accuracy: 0.5909 - val_loss: 0.6131 - val_accuracy: 0.6577\n",
      "Epoch 2/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5909 - accuracy: 0.6971\n",
      "Epoch 2: val_accuracy improved from 0.65772 to 0.73266, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5862 - accuracy: 0.7019 - val_loss: 0.5592 - val_accuracy: 0.7327\n",
      "Epoch 3/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5417 - accuracy: 0.7337\n",
      "Epoch 3: val_accuracy improved from 0.73266 to 0.80089, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5392 - accuracy: 0.7380 - val_loss: 0.5046 - val_accuracy: 0.8009\n",
      "Epoch 4/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4904 - accuracy: 0.7816\n",
      "Epoch 4: val_accuracy improved from 0.80089 to 0.83110, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4875 - accuracy: 0.7852 - val_loss: 0.4707 - val_accuracy: 0.8311\n",
      "Epoch 5/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4670 - accuracy: 0.8035\n",
      "Epoch 5: val_accuracy improved from 0.83110 to 0.83781, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4621 - accuracy: 0.8079 - val_loss: 0.4436 - val_accuracy: 0.8378\n",
      "Epoch 6/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4264 - accuracy: 0.8389\n",
      "Epoch 6: val_accuracy did not improve from 0.83781\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4235 - accuracy: 0.8414 - val_loss: 0.4376 - val_accuracy: 0.8199\n",
      "Epoch 7/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3974 - accuracy: 0.8555\n",
      "Epoch 7: val_accuracy improved from 0.83781 to 0.87584, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4018 - accuracy: 0.8532 - val_loss: 0.4087 - val_accuracy: 0.8758\n",
      "Epoch 8/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3796 - accuracy: 0.8673\n",
      "Epoch 8: val_accuracy did not improve from 0.87584\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3761 - accuracy: 0.8705 - val_loss: 0.4451 - val_accuracy: 0.7796\n",
      "Epoch 9/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3607 - accuracy: 0.8744\n",
      "Epoch 9: val_accuracy did not improve from 0.87584\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3614 - accuracy: 0.8742 - val_loss: 0.4734 - val_accuracy: 0.7539\n",
      "Epoch 10/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3433 - accuracy: 0.8942\n",
      "Epoch 10: val_accuracy did not improve from 0.87584\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3423 - accuracy: 0.8929 - val_loss: 0.3729 - val_accuracy: 0.8557\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.8853\n",
      "Epoch 11: val_accuracy improved from 0.87584 to 0.90492, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3327 - accuracy: 0.8853 - val_loss: 0.3494 - val_accuracy: 0.9049\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.8988\n",
      "Epoch 12: val_accuracy improved from 0.90492 to 0.91275, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3132 - accuracy: 0.8988 - val_loss: 0.3343 - val_accuracy: 0.9128\n",
      "Epoch 13/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3052 - accuracy: 0.9025\n",
      "Epoch 13: val_accuracy did not improve from 0.91275\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3025 - accuracy: 0.9052 - val_loss: 0.3352 - val_accuracy: 0.8881\n",
      "Epoch 14/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2879 - accuracy: 0.9125\n",
      "Epoch 14: val_accuracy improved from 0.91275 to 0.92394, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2925 - accuracy: 0.9091 - val_loss: 0.3162 - val_accuracy: 0.9239\n",
      "Epoch 15/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2809 - accuracy: 0.9146\n",
      "Epoch 15: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2820 - accuracy: 0.9139 - val_loss: 0.3158 - val_accuracy: 0.9150\n",
      "Epoch 16/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2658 - accuracy: 0.9220\n",
      "Epoch 16: val_accuracy improved from 0.92394 to 0.92617, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2705 - accuracy: 0.9192 - val_loss: 0.3069 - val_accuracy: 0.9262\n",
      "Epoch 17/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2683 - accuracy: 0.9184\n",
      "Epoch 17: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2654 - accuracy: 0.9195 - val_loss: 0.3047 - val_accuracy: 0.8960\n",
      "Epoch 18/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2553 - accuracy: 0.9214\n",
      "Epoch 18: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2569 - accuracy: 0.9211 - val_loss: 0.2985 - val_accuracy: 0.9172\n",
      "Epoch 19/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2513 - accuracy: 0.9235\n",
      "Epoch 19: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2518 - accuracy: 0.9242 - val_loss: 0.3024 - val_accuracy: 0.9116\n",
      "Epoch 20/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2397 - accuracy: 0.9306\n",
      "Epoch 20: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2401 - accuracy: 0.9306 - val_loss: 0.2931 - val_accuracy: 0.8982\n",
      "Epoch 21/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2374 - accuracy: 0.9272\n",
      "Epoch 21: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2403 - accuracy: 0.9251 - val_loss: 0.2763 - val_accuracy: 0.9228\n",
      "Epoch 22/30\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9328\n",
      "Epoch 22: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2289 - accuracy: 0.9323 - val_loss: 0.3012 - val_accuracy: 0.8814\n",
      "Epoch 23/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2283 - accuracy: 0.9347\n",
      "Epoch 23: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2259 - accuracy: 0.9360 - val_loss: 0.3422 - val_accuracy: 0.8579\n",
      "Epoch 24/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2238 - accuracy: 0.9353\n",
      "Epoch 24: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2281 - accuracy: 0.9332 - val_loss: 0.2847 - val_accuracy: 0.8937\n",
      "Epoch 25/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2167 - accuracy: 0.9396\n",
      "Epoch 25: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2172 - accuracy: 0.9390 - val_loss: 0.2587 - val_accuracy: 0.9251\n",
      "Epoch 26/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2131 - accuracy: 0.9403\n",
      "Epoch 26: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2152 - accuracy: 0.9399 - val_loss: 0.2703 - val_accuracy: 0.9004\n",
      "Epoch 27/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2056 - accuracy: 0.9489\n",
      "Epoch 27: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2065 - accuracy: 0.9463 - val_loss: 0.2519 - val_accuracy: 0.9262\n",
      "Epoch 28/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2085 - accuracy: 0.9412\n",
      "Epoch 28: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2090 - accuracy: 0.9404 - val_loss: 0.2546 - val_accuracy: 0.9195\n",
      "Epoch 29/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1997 - accuracy: 0.9441\n",
      "Epoch 29: val_accuracy improved from 0.92617 to 0.92953, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1988 - accuracy: 0.9446 - val_loss: 0.2450 - val_accuracy: 0.9295\n",
      "Epoch 30/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2023 - accuracy: 0.9399\n",
      "Epoch 30: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2006 - accuracy: 0.9416 - val_loss: 0.2580 - val_accuracy: 0.9217\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 30, 'optimizer': 'adagrad'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6629 - accuracy: 0.6090\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59396, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6634 - accuracy: 0.6088 - val_loss: 0.6617 - val_accuracy: 0.5940\n",
      "Epoch 2/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6409 - accuracy: 0.6560\n",
      "Epoch 2: val_accuracy improved from 0.59396 to 0.62416, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6419 - accuracy: 0.6552 - val_loss: 0.6492 - val_accuracy: 0.6242\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.6681\n",
      "Epoch 3: val_accuracy improved from 0.62416 to 0.64094, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6289 - accuracy: 0.6681 - val_loss: 0.6395 - val_accuracy: 0.6409\n",
      "Epoch 4/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6192 - accuracy: 0.6847\n",
      "Epoch 4: val_accuracy improved from 0.64094 to 0.64877, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6189 - accuracy: 0.6848 - val_loss: 0.6359 - val_accuracy: 0.6488\n",
      "Epoch 5/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6127 - accuracy: 0.6995\n",
      "Epoch 5: val_accuracy improved from 0.64877 to 0.66443, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6117 - accuracy: 0.7011 - val_loss: 0.6273 - val_accuracy: 0.6644\n",
      "Epoch 6/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6040 - accuracy: 0.7008\n",
      "Epoch 6: val_accuracy improved from 0.66443 to 0.67338, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6041 - accuracy: 0.7027 - val_loss: 0.6221 - val_accuracy: 0.6734\n",
      "Epoch 7/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5988 - accuracy: 0.7139\n",
      "Epoch 7: val_accuracy improved from 0.67338 to 0.68456, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5987 - accuracy: 0.7153 - val_loss: 0.6175 - val_accuracy: 0.6846\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.7209\n",
      "Epoch 8: val_accuracy improved from 0.68456 to 0.69128, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5935 - accuracy: 0.7209 - val_loss: 0.6128 - val_accuracy: 0.6913\n",
      "Epoch 9/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5884 - accuracy: 0.7284\n",
      "Epoch 9: val_accuracy improved from 0.69128 to 0.69911, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5889 - accuracy: 0.7299 - val_loss: 0.6088 - val_accuracy: 0.6991\n",
      "Epoch 10/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5853 - accuracy: 0.7367\n",
      "Epoch 10: val_accuracy did not improve from 0.69911\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5838 - accuracy: 0.7377 - val_loss: 0.6090 - val_accuracy: 0.6924\n",
      "Epoch 11/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5809 - accuracy: 0.7411\n",
      "Epoch 11: val_accuracy improved from 0.69911 to 0.70694, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5804 - accuracy: 0.7433 - val_loss: 0.6020 - val_accuracy: 0.7069\n",
      "Epoch 12/30\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.5763 - accuracy: 0.7483\n",
      "Epoch 12: val_accuracy improved from 0.70694 to 0.71141, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5765 - accuracy: 0.7469 - val_loss: 0.5992 - val_accuracy: 0.7114\n",
      "Epoch 13/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5737 - accuracy: 0.7506\n",
      "Epoch 13: val_accuracy improved from 0.71141 to 0.71365, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5733 - accuracy: 0.7511 - val_loss: 0.5960 - val_accuracy: 0.7136\n",
      "Epoch 14/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5706 - accuracy: 0.7530\n",
      "Epoch 14: val_accuracy improved from 0.71365 to 0.72148, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5703 - accuracy: 0.7534 - val_loss: 0.5933 - val_accuracy: 0.7215\n",
      "Epoch 15/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5665 - accuracy: 0.7580\n",
      "Epoch 15: val_accuracy improved from 0.72148 to 0.72595, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5664 - accuracy: 0.7587 - val_loss: 0.5917 - val_accuracy: 0.7260\n",
      "Epoch 16/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5632 - accuracy: 0.7671\n",
      "Epoch 16: val_accuracy improved from 0.72595 to 0.72931, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5628 - accuracy: 0.7668 - val_loss: 0.5899 - val_accuracy: 0.7293\n",
      "Epoch 17/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5611 - accuracy: 0.7615\n",
      "Epoch 17: val_accuracy did not improve from 0.72931\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5605 - accuracy: 0.7634 - val_loss: 0.5859 - val_accuracy: 0.7282\n",
      "Epoch 18/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5574 - accuracy: 0.7713\n",
      "Epoch 18: val_accuracy improved from 0.72931 to 0.73490, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5580 - accuracy: 0.7707 - val_loss: 0.5839 - val_accuracy: 0.7349\n",
      "Epoch 19/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5554 - accuracy: 0.7722\n",
      "Epoch 19: val_accuracy did not improve from 0.73490\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5553 - accuracy: 0.7715 - val_loss: 0.5816 - val_accuracy: 0.7327\n",
      "Epoch 20/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5529 - accuracy: 0.7769\n",
      "Epoch 20: val_accuracy improved from 0.73490 to 0.74161, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5529 - accuracy: 0.7788 - val_loss: 0.5799 - val_accuracy: 0.7416\n",
      "Epoch 21/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5516 - accuracy: 0.7745\n",
      "Epoch 21: val_accuracy improved from 0.74161 to 0.74273, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5506 - accuracy: 0.7752 - val_loss: 0.5771 - val_accuracy: 0.7427\n",
      "Epoch 22/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5488 - accuracy: 0.7843\n",
      "Epoch 22: val_accuracy improved from 0.74273 to 0.74385, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5480 - accuracy: 0.7844 - val_loss: 0.5762 - val_accuracy: 0.7438\n",
      "Epoch 23/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5473 - accuracy: 0.7798\n",
      "Epoch 23: val_accuracy improved from 0.74385 to 0.75056, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5460 - accuracy: 0.7819 - val_loss: 0.5732 - val_accuracy: 0.7506\n",
      "Epoch 24/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5452 - accuracy: 0.7843\n",
      "Epoch 24: val_accuracy did not improve from 0.75056\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5435 - accuracy: 0.7850 - val_loss: 0.5717 - val_accuracy: 0.7483\n",
      "Epoch 25/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5422 - accuracy: 0.7872\n",
      "Epoch 25: val_accuracy improved from 0.75056 to 0.75168, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5418 - accuracy: 0.7872 - val_loss: 0.5696 - val_accuracy: 0.7517\n",
      "Epoch 26/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5393 - accuracy: 0.7893\n",
      "Epoch 26: val_accuracy did not improve from 0.75168\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5395 - accuracy: 0.7891 - val_loss: 0.5684 - val_accuracy: 0.7483\n",
      "Epoch 27/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5379 - accuracy: 0.7893\n",
      "Epoch 27: val_accuracy improved from 0.75168 to 0.75839, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5379 - accuracy: 0.7897 - val_loss: 0.5662 - val_accuracy: 0.7584\n",
      "Epoch 28/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5371 - accuracy: 0.7914\n",
      "Epoch 28: val_accuracy improved from 0.75839 to 0.76063, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5361 - accuracy: 0.7922 - val_loss: 0.5646 - val_accuracy: 0.7606\n",
      "Epoch 29/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5341 - accuracy: 0.7937\n",
      "Epoch 29: val_accuracy did not improve from 0.76063\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5338 - accuracy: 0.7950 - val_loss: 0.5640 - val_accuracy: 0.7517\n",
      "Epoch 30/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5319 - accuracy: 0.7934\n",
      "Epoch 30: val_accuracy improved from 0.76063 to 0.76734, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5326 - accuracy: 0.7939 - val_loss: 0.5613 - val_accuracy: 0.7673\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 30, 'optimizer': 'adadelta'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7225 - accuracy: 0.4248\n",
      "Epoch 1: val_accuracy improved from -inf to 0.42617, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.7225 - accuracy: 0.4231 - val_loss: 0.7193 - val_accuracy: 0.4262\n",
      "Epoch 2/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7174 - accuracy: 0.4119\n",
      "Epoch 2: val_accuracy improved from 0.42617 to 0.43289, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7173 - accuracy: 0.4133 - val_loss: 0.7161 - val_accuracy: 0.4329\n",
      "Epoch 3/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7135 - accuracy: 0.4208\n",
      "Epoch 3: val_accuracy did not improve from 0.43289\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7141 - accuracy: 0.4192 - val_loss: 0.7140 - val_accuracy: 0.4228\n",
      "Epoch 4/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7119 - accuracy: 0.4273\n",
      "Epoch 4: val_accuracy did not improve from 0.43289\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7120 - accuracy: 0.4267 - val_loss: 0.7125 - val_accuracy: 0.4306\n",
      "Epoch 5/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7106 - accuracy: 0.4326\n",
      "Epoch 5: val_accuracy improved from 0.43289 to 0.43400, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7102 - accuracy: 0.4360 - val_loss: 0.7111 - val_accuracy: 0.4340\n",
      "Epoch 6/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7085 - accuracy: 0.4495\n",
      "Epoch 6: val_accuracy did not improve from 0.43400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7086 - accuracy: 0.4488 - val_loss: 0.7099 - val_accuracy: 0.4329\n",
      "Epoch 7/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7071 - accuracy: 0.4539\n",
      "Epoch 7: val_accuracy did not improve from 0.43400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7072 - accuracy: 0.4522 - val_loss: 0.7087 - val_accuracy: 0.4284\n",
      "Epoch 8/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7063 - accuracy: 0.4613\n",
      "Epoch 8: val_accuracy did not improve from 0.43400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7059 - accuracy: 0.4617 - val_loss: 0.7076 - val_accuracy: 0.4329\n",
      "Epoch 9/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7045 - accuracy: 0.4654\n",
      "Epoch 9: val_accuracy improved from 0.43400 to 0.43736, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7046 - accuracy: 0.4622 - val_loss: 0.7064 - val_accuracy: 0.4374\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.7034 - accuracy: 0.4667\n",
      "Epoch 10: val_accuracy improved from 0.43736 to 0.43960, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7034 - accuracy: 0.4667 - val_loss: 0.7053 - val_accuracy: 0.4396\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.4690\n",
      "Epoch 11: val_accuracy improved from 0.43960 to 0.44407, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7023 - accuracy: 0.4690 - val_loss: 0.7043 - val_accuracy: 0.4441\n",
      "Epoch 12/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7008 - accuracy: 0.4740\n",
      "Epoch 12: val_accuracy improved from 0.44407 to 0.44855, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7011 - accuracy: 0.4718 - val_loss: 0.7033 - val_accuracy: 0.4485\n",
      "Epoch 13/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6999 - accuracy: 0.4743\n",
      "Epoch 13: val_accuracy improved from 0.44855 to 0.45078, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7000 - accuracy: 0.4732 - val_loss: 0.7023 - val_accuracy: 0.4508\n",
      "Epoch 14/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6992 - accuracy: 0.4752\n",
      "Epoch 14: val_accuracy improved from 0.45078 to 0.45190, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6990 - accuracy: 0.4762 - val_loss: 0.7014 - val_accuracy: 0.4519\n",
      "Epoch 15/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6980 - accuracy: 0.4846\n",
      "Epoch 15: val_accuracy improved from 0.45190 to 0.45302, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6980 - accuracy: 0.4829 - val_loss: 0.7005 - val_accuracy: 0.4530\n",
      "Epoch 16/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6973 - accuracy: 0.4829\n",
      "Epoch 16: val_accuracy did not improve from 0.45302\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6971 - accuracy: 0.4843 - val_loss: 0.6997 - val_accuracy: 0.4530\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.4874\n",
      "Epoch 17: val_accuracy improved from 0.45302 to 0.45973, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6962 - accuracy: 0.4874 - val_loss: 0.6988 - val_accuracy: 0.4597\n",
      "Epoch 18/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6949 - accuracy: 0.4941\n",
      "Epoch 18: val_accuracy improved from 0.45973 to 0.46868, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6953 - accuracy: 0.4913 - val_loss: 0.6980 - val_accuracy: 0.4687\n",
      "Epoch 19/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.4924\n",
      "Epoch 19: val_accuracy did not improve from 0.46868\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6944 - accuracy: 0.4930 - val_loss: 0.6972 - val_accuracy: 0.4664\n",
      "Epoch 20/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6938 - accuracy: 0.4965\n",
      "Epoch 20: val_accuracy improved from 0.46868 to 0.47315, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6935 - accuracy: 0.4966 - val_loss: 0.6965 - val_accuracy: 0.4732\n",
      "Epoch 21/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5009\n",
      "Epoch 21: val_accuracy improved from 0.47315 to 0.47763, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6927 - accuracy: 0.5008 - val_loss: 0.6957 - val_accuracy: 0.4776\n",
      "Epoch 22/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6916 - accuracy: 0.5068\n",
      "Epoch 22: val_accuracy improved from 0.47763 to 0.47875, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6919 - accuracy: 0.5078 - val_loss: 0.6950 - val_accuracy: 0.4787\n",
      "Epoch 23/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6904 - accuracy: 0.5127\n",
      "Epoch 23: val_accuracy improved from 0.47875 to 0.48770, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6911 - accuracy: 0.5109 - val_loss: 0.6943 - val_accuracy: 0.4877\n",
      "Epoch 24/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6903 - accuracy: 0.5180\n",
      "Epoch 24: val_accuracy improved from 0.48770 to 0.49105, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6903 - accuracy: 0.5179 - val_loss: 0.6936 - val_accuracy: 0.4911\n",
      "Epoch 25/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6900 - accuracy: 0.5201\n",
      "Epoch 25: val_accuracy improved from 0.49105 to 0.49664, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6895 - accuracy: 0.5196 - val_loss: 0.6929 - val_accuracy: 0.4966\n",
      "Epoch 26/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6882 - accuracy: 0.5233\n",
      "Epoch 26: val_accuracy improved from 0.49664 to 0.49888, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6887 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.4989\n",
      "Epoch 27/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6881 - accuracy: 0.5245\n",
      "Epoch 27: val_accuracy did not improve from 0.49888\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6880 - accuracy: 0.5249 - val_loss: 0.6916 - val_accuracy: 0.4955\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.5260\n",
      "Epoch 28: val_accuracy did not improve from 0.49888\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6873 - accuracy: 0.5260 - val_loss: 0.6910 - val_accuracy: 0.4966\n",
      "Epoch 29/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6863 - accuracy: 0.5272\n",
      "Epoch 29: val_accuracy improved from 0.49888 to 0.50224, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6866 - accuracy: 0.5254 - val_loss: 0.6905 - val_accuracy: 0.5022\n",
      "Epoch 30/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6856 - accuracy: 0.5298\n",
      "Epoch 30: val_accuracy improved from 0.50224 to 0.50671, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6860 - accuracy: 0.5268 - val_loss: 0.6899 - val_accuracy: 0.5067\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 30, 'optimizer': 'adamax'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6677 - accuracy: 0.5969\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63982, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6669 - accuracy: 0.5990 - val_loss: 0.6345 - val_accuracy: 0.6398\n",
      "Epoch 2/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5998 - accuracy: 0.7064\n",
      "Epoch 2: val_accuracy improved from 0.63982 to 0.70022, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.5985 - accuracy: 0.7072 - val_loss: 0.5967 - val_accuracy: 0.7002\n",
      "Epoch 3/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5550 - accuracy: 0.7527\n",
      "Epoch 3: val_accuracy improved from 0.70022 to 0.76398, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5540 - accuracy: 0.7536 - val_loss: 0.5632 - val_accuracy: 0.7640\n",
      "Epoch 4/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5189 - accuracy: 0.7982\n",
      "Epoch 4: val_accuracy did not improve from 0.76398\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5183 - accuracy: 0.7984 - val_loss: 0.5584 - val_accuracy: 0.7327\n",
      "Epoch 5/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4976 - accuracy: 0.8187\n",
      "Epoch 5: val_accuracy improved from 0.76398 to 0.76734, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4954 - accuracy: 0.8207 - val_loss: 0.5229 - val_accuracy: 0.7673\n",
      "Epoch 6/30\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.4710 - accuracy: 0.8408\n",
      "Epoch 6: val_accuracy did not improve from 0.76734\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4714 - accuracy: 0.8398 - val_loss: 0.5297 - val_accuracy: 0.7394\n",
      "Epoch 7/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4542 - accuracy: 0.8487\n",
      "Epoch 7: val_accuracy improved from 0.76734 to 0.83893, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4527 - accuracy: 0.8490 - val_loss: 0.4804 - val_accuracy: 0.8389\n",
      "Epoch 8/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4358 - accuracy: 0.8629\n",
      "Epoch 8: val_accuracy did not improve from 0.83893\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4339 - accuracy: 0.8655 - val_loss: 0.4678 - val_accuracy: 0.8277\n",
      "Epoch 9/30\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.4176 - accuracy: 0.8790\n",
      "Epoch 9: val_accuracy improved from 0.83893 to 0.85794, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.4171 - accuracy: 0.8795 - val_loss: 0.4501 - val_accuracy: 0.8579\n",
      "Epoch 10/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4029 - accuracy: 0.8951\n",
      "Epoch 10: val_accuracy did not improve from 0.85794\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4014 - accuracy: 0.8963 - val_loss: 0.4435 - val_accuracy: 0.8535\n",
      "Epoch 11/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3874 - accuracy: 0.9037\n",
      "Epoch 11: val_accuracy improved from 0.85794 to 0.87584, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3889 - accuracy: 0.9021 - val_loss: 0.4256 - val_accuracy: 0.8758\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8979\n",
      "Epoch 12: val_accuracy improved from 0.87584 to 0.89038, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3779 - accuracy: 0.8979 - val_loss: 0.4160 - val_accuracy: 0.8904\n",
      "Epoch 13/30\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.3647 - accuracy: 0.9138\n",
      "Epoch 13: val_accuracy did not improve from 0.89038\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3647 - accuracy: 0.9133 - val_loss: 0.4065 - val_accuracy: 0.8859\n",
      "Epoch 14/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3522 - accuracy: 0.9190\n",
      "Epoch 14: val_accuracy did not improve from 0.89038\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3536 - accuracy: 0.9181 - val_loss: 0.4013 - val_accuracy: 0.8770\n",
      "Epoch 15/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3438 - accuracy: 0.9184\n",
      "Epoch 15: val_accuracy improved from 0.89038 to 0.90157, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3459 - accuracy: 0.9169 - val_loss: 0.3873 - val_accuracy: 0.9016\n",
      "Epoch 16/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3328 - accuracy: 0.9245\n",
      "Epoch 16: val_accuracy did not improve from 0.90157\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3347 - accuracy: 0.9231 - val_loss: 0.3848 - val_accuracy: 0.8960\n",
      "Epoch 17/30\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.3292 - accuracy: 0.9179\n",
      "Epoch 17: val_accuracy did not improve from 0.90157\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3298 - accuracy: 0.9169 - val_loss: 0.3841 - val_accuracy: 0.8669\n",
      "Epoch 18/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3213 - accuracy: 0.9235\n",
      "Epoch 18: val_accuracy did not improve from 0.90157\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3204 - accuracy: 0.9228 - val_loss: 0.3704 - val_accuracy: 0.8859\n",
      "Epoch 19/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3120 - accuracy: 0.9273\n",
      "Epoch 19: val_accuracy improved from 0.90157 to 0.91163, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3108 - accuracy: 0.9281 - val_loss: 0.3565 - val_accuracy: 0.9116\n",
      "Epoch 20/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3043 - accuracy: 0.9291\n",
      "Epoch 20: val_accuracy did not improve from 0.91163\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3044 - accuracy: 0.9301 - val_loss: 0.3513 - val_accuracy: 0.8993\n",
      "Epoch 21/30\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.2966 - accuracy: 0.9299\n",
      "Epoch 21: val_accuracy did not improve from 0.91163\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2966 - accuracy: 0.9295 - val_loss: 0.3439 - val_accuracy: 0.9105\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2910 - accuracy: 0.9348\n",
      "Epoch 22: val_accuracy did not improve from 0.91163\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.2910 - accuracy: 0.9348 - val_loss: 0.3429 - val_accuracy: 0.9116\n",
      "Epoch 23/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2826 - accuracy: 0.9356\n",
      "Epoch 23: val_accuracy did not improve from 0.91163\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2820 - accuracy: 0.9360 - val_loss: 0.3510 - val_accuracy: 0.8926\n",
      "Epoch 24/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2808 - accuracy: 0.9326\n",
      "Epoch 24: val_accuracy did not improve from 0.91163\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2785 - accuracy: 0.9334 - val_loss: 0.3355 - val_accuracy: 0.8937\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.9360\n",
      "Epoch 25: val_accuracy did not improve from 0.91163\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2711 - accuracy: 0.9360 - val_loss: 0.3356 - val_accuracy: 0.8859\n",
      "Epoch 26/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2698 - accuracy: 0.9359\n",
      "Epoch 26: val_accuracy did not improve from 0.91163\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2689 - accuracy: 0.9360 - val_loss: 0.3202 - val_accuracy: 0.9060\n",
      "Epoch 27/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2600 - accuracy: 0.9433\n",
      "Epoch 27: val_accuracy improved from 0.91163 to 0.91499, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2595 - accuracy: 0.9430 - val_loss: 0.3157 - val_accuracy: 0.9150\n",
      "Epoch 28/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2563 - accuracy: 0.9403\n",
      "Epoch 28: val_accuracy improved from 0.91499 to 0.92282, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2562 - accuracy: 0.9404 - val_loss: 0.3071 - val_accuracy: 0.9228\n",
      "Epoch 29/30\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.2511 - accuracy: 0.9403\n",
      "Epoch 29: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.2508 - accuracy: 0.9402 - val_loss: 0.3121 - val_accuracy: 0.9016\n",
      "Epoch 30/30\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.2472 - accuracy: 0.9431\n",
      "Epoch 30: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2481 - accuracy: 0.9424 - val_loss: 0.2997 - val_accuracy: 0.9183\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 30, 'optimizer': 'ftrl'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6690 - accuracy: 0.6194\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62752, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6686 - accuracy: 0.6188 - val_loss: 0.6584 - val_accuracy: 0.6275\n",
      "Epoch 2/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6450 - accuracy: 0.6598\n",
      "Epoch 2: val_accuracy improved from 0.62752 to 0.64094, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6450 - accuracy: 0.6591 - val_loss: 0.6465 - val_accuracy: 0.6409\n",
      "Epoch 3/30\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.6314 - accuracy: 0.6810\n",
      "Epoch 3: val_accuracy improved from 0.64094 to 0.65213, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6309 - accuracy: 0.6826 - val_loss: 0.6383 - val_accuracy: 0.6521\n",
      "Epoch 4/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6222 - accuracy: 0.6998\n",
      "Epoch 4: val_accuracy improved from 0.65213 to 0.66779, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6218 - accuracy: 0.6994 - val_loss: 0.6308 - val_accuracy: 0.6678\n",
      "Epoch 5/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6143 - accuracy: 0.7015\n",
      "Epoch 5: val_accuracy improved from 0.66779 to 0.67114, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6139 - accuracy: 0.7027 - val_loss: 0.6254 - val_accuracy: 0.6711\n",
      "Epoch 6/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6069 - accuracy: 0.7104\n",
      "Epoch 6: val_accuracy improved from 0.67114 to 0.67673, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6074 - accuracy: 0.7109 - val_loss: 0.6205 - val_accuracy: 0.6767\n",
      "Epoch 7/30\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.5990 - accuracy: 0.7195\n",
      "Epoch 7: val_accuracy improved from 0.67673 to 0.67897, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6005 - accuracy: 0.7159 - val_loss: 0.6178 - val_accuracy: 0.6790\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.7271\n",
      "Epoch 8: val_accuracy improved from 0.67897 to 0.68904, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.5961 - accuracy: 0.7271 - val_loss: 0.6118 - val_accuracy: 0.6890\n",
      "Epoch 9/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5903 - accuracy: 0.7249\n",
      "Epoch 9: val_accuracy improved from 0.68904 to 0.69351, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5913 - accuracy: 0.7248 - val_loss: 0.6082 - val_accuracy: 0.6935\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5869 - accuracy: 0.7318\n",
      "Epoch 10: val_accuracy improved from 0.69351 to 0.70134, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5869 - accuracy: 0.7318 - val_loss: 0.6054 - val_accuracy: 0.7013\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5833 - accuracy: 0.7397\n",
      "Epoch 11: val_accuracy improved from 0.70134 to 0.71141, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5833 - accuracy: 0.7397 - val_loss: 0.6015 - val_accuracy: 0.7114\n",
      "Epoch 12/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5776 - accuracy: 0.7515\n",
      "Epoch 12: val_accuracy improved from 0.71141 to 0.71365, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5794 - accuracy: 0.7461 - val_loss: 0.5985 - val_accuracy: 0.7136\n",
      "Epoch 13/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5751 - accuracy: 0.7527\n",
      "Epoch 13: val_accuracy did not improve from 0.71365\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5750 - accuracy: 0.7528 - val_loss: 0.5970 - val_accuracy: 0.7125\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.7472\n",
      "Epoch 14: val_accuracy improved from 0.71365 to 0.71924, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5722 - accuracy: 0.7472 - val_loss: 0.5938 - val_accuracy: 0.7192\n",
      "Epoch 15/30\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.5697 - accuracy: 0.7546\n",
      "Epoch 15: val_accuracy improved from 0.71924 to 0.72036, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5691 - accuracy: 0.7562 - val_loss: 0.5915 - val_accuracy: 0.7204\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7601\n",
      "Epoch 16: val_accuracy improved from 0.72036 to 0.72819, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 15ms/step - loss: 0.5662 - accuracy: 0.7601 - val_loss: 0.5886 - val_accuracy: 0.7282\n",
      "Epoch 17/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5635 - accuracy: 0.7586\n",
      "Epoch 17: val_accuracy improved from 0.72819 to 0.73266, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5632 - accuracy: 0.7598 - val_loss: 0.5857 - val_accuracy: 0.7327\n",
      "Epoch 18/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5606 - accuracy: 0.7665\n",
      "Epoch 18: val_accuracy did not improve from 0.73266\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5607 - accuracy: 0.7659 - val_loss: 0.5834 - val_accuracy: 0.7327\n",
      "Epoch 19/30\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.5590 - accuracy: 0.7659\n",
      "Epoch 19: val_accuracy improved from 0.73266 to 0.74161, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.5583 - accuracy: 0.7676 - val_loss: 0.5813 - val_accuracy: 0.7416\n",
      "Epoch 20/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5560 - accuracy: 0.7766\n",
      "Epoch 20: val_accuracy did not improve from 0.74161\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5555 - accuracy: 0.7763 - val_loss: 0.5794 - val_accuracy: 0.7383\n",
      "Epoch 21/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5532 - accuracy: 0.7716\n",
      "Epoch 21: val_accuracy improved from 0.74161 to 0.74385, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5531 - accuracy: 0.7732 - val_loss: 0.5775 - val_accuracy: 0.7438\n",
      "Epoch 22/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.5510 - accuracy: 0.7765\n",
      "Epoch 22: val_accuracy did not improve from 0.74385\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5508 - accuracy: 0.7777 - val_loss: 0.5758 - val_accuracy: 0.7438\n",
      "Epoch 23/30\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 0.5492 - accuracy: 0.7755\n",
      "Epoch 23: val_accuracy improved from 0.74385 to 0.74832, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.5487 - accuracy: 0.7771 - val_loss: 0.5735 - val_accuracy: 0.7483\n",
      "Epoch 24/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5473 - accuracy: 0.7810\n",
      "Epoch 24: val_accuracy improved from 0.74832 to 0.75280, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5465 - accuracy: 0.7833 - val_loss: 0.5716 - val_accuracy: 0.7528\n",
      "Epoch 25/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5439 - accuracy: 0.7858\n",
      "Epoch 25: val_accuracy did not improve from 0.75280\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5444 - accuracy: 0.7864 - val_loss: 0.5701 - val_accuracy: 0.7494\n",
      "Epoch 26/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5412 - accuracy: 0.7902\n",
      "Epoch 26: val_accuracy improved from 0.75280 to 0.75392, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5423 - accuracy: 0.7880 - val_loss: 0.5681 - val_accuracy: 0.7539\n",
      "Epoch 27/30\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.5408 - accuracy: 0.7867\n",
      "Epoch 27: val_accuracy improved from 0.75392 to 0.75839, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.5405 - accuracy: 0.7869 - val_loss: 0.5668 - val_accuracy: 0.7584\n",
      "Epoch 28/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5393 - accuracy: 0.7881\n",
      "Epoch 28: val_accuracy did not improve from 0.75839\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5385 - accuracy: 0.7894 - val_loss: 0.5650 - val_accuracy: 0.7573\n",
      "Epoch 29/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5348 - accuracy: 0.7949\n",
      "Epoch 29: val_accuracy improved from 0.75839 to 0.75951, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5365 - accuracy: 0.7914 - val_loss: 0.5635 - val_accuracy: 0.7595\n",
      "Epoch 30/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5346 - accuracy: 0.7973\n",
      "Epoch 30: val_accuracy improved from 0.75951 to 0.76063, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5349 - accuracy: 0.7959 - val_loss: 0.5618 - val_accuracy: 0.7606\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 30, 'optimizer': 'nadam'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.6242 - accuracy: 0.6549\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71812, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 0.6232 - accuracy: 0.6560 - val_loss: 0.5775 - val_accuracy: 0.7181\n",
      "Epoch 2/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5171 - accuracy: 0.7923\n",
      "Epoch 2: val_accuracy improved from 0.71812 to 0.76063, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5158 - accuracy: 0.7936 - val_loss: 0.5281 - val_accuracy: 0.7606\n",
      "Epoch 3/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4570 - accuracy: 0.8457\n",
      "Epoch 3: val_accuracy improved from 0.76063 to 0.84228, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4546 - accuracy: 0.8501 - val_loss: 0.4638 - val_accuracy: 0.8423\n",
      "Epoch 4/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4127 - accuracy: 0.8756\n",
      "Epoch 4: val_accuracy improved from 0.84228 to 0.88479, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4095 - accuracy: 0.8775 - val_loss: 0.4270 - val_accuracy: 0.8848\n",
      "Epoch 5/30\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.3741 - accuracy: 0.9003\n",
      "Epoch 5: val_accuracy did not improve from 0.88479\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3746 - accuracy: 0.8996 - val_loss: 0.4107 - val_accuracy: 0.8702\n",
      "Epoch 6/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3479 - accuracy: 0.9121\n",
      "Epoch 6: val_accuracy improved from 0.88479 to 0.88814, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3474 - accuracy: 0.9119 - val_loss: 0.3881 - val_accuracy: 0.8881\n",
      "Epoch 7/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3259 - accuracy: 0.9193\n",
      "Epoch 7: val_accuracy improved from 0.88814 to 0.90492, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3253 - accuracy: 0.9200 - val_loss: 0.3643 - val_accuracy: 0.9049\n",
      "Epoch 8/30\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.3079 - accuracy: 0.9237\n",
      "Epoch 8: val_accuracy improved from 0.90492 to 0.92170, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3086 - accuracy: 0.9220 - val_loss: 0.3490 - val_accuracy: 0.9217\n",
      "Epoch 9/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2913 - accuracy: 0.9332\n",
      "Epoch 9: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2910 - accuracy: 0.9334 - val_loss: 0.3363 - val_accuracy: 0.9072\n",
      "Epoch 10/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2772 - accuracy: 0.9382\n",
      "Epoch 10: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2781 - accuracy: 0.9365 - val_loss: 0.3295 - val_accuracy: 0.8904\n",
      "Epoch 11/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2647 - accuracy: 0.9359\n",
      "Epoch 11: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2678 - accuracy: 0.9337 - val_loss: 0.3140 - val_accuracy: 0.9083\n",
      "Epoch 12/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2555 - accuracy: 0.9421\n",
      "Epoch 12: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2564 - accuracy: 0.9407 - val_loss: 0.3230 - val_accuracy: 0.8837\n",
      "Epoch 13/30\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2461 - accuracy: 0.9419\n",
      "Epoch 13: val_accuracy improved from 0.92170 to 0.92394, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2465 - accuracy: 0.9413 - val_loss: 0.2966 - val_accuracy: 0.9239\n",
      "Epoch 14/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2386 - accuracy: 0.9433\n",
      "Epoch 14: val_accuracy improved from 0.92394 to 0.92841, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2394 - accuracy: 0.9421 - val_loss: 0.2911 - val_accuracy: 0.9284\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9474\n",
      "Epoch 15: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2308 - accuracy: 0.9474 - val_loss: 0.2852 - val_accuracy: 0.9284\n",
      "Epoch 16/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2259 - accuracy: 0.9450\n",
      "Epoch 16: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2255 - accuracy: 0.9452 - val_loss: 0.2772 - val_accuracy: 0.9251\n",
      "Epoch 17/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2159 - accuracy: 0.9560\n",
      "Epoch 17: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2164 - accuracy: 0.9550 - val_loss: 0.2731 - val_accuracy: 0.9206\n",
      "Epoch 18/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2112 - accuracy: 0.9515\n",
      "Epoch 18: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2127 - accuracy: 0.9516 - val_loss: 0.2662 - val_accuracy: 0.9228\n",
      "Epoch 19/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2032 - accuracy: 0.9545\n",
      "Epoch 19: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2054 - accuracy: 0.9536 - val_loss: 0.2617 - val_accuracy: 0.9284\n",
      "Epoch 20/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2007 - accuracy: 0.9583\n",
      "Epoch 20: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2004 - accuracy: 0.9583 - val_loss: 0.2569 - val_accuracy: 0.9284\n",
      "Epoch 21/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1952 - accuracy: 0.9589\n",
      "Epoch 21: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1947 - accuracy: 0.9592 - val_loss: 0.2534 - val_accuracy: 0.9284\n",
      "Epoch 22/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1926 - accuracy: 0.9577\n",
      "Epoch 22: val_accuracy improved from 0.92841 to 0.93177, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1922 - accuracy: 0.9581 - val_loss: 0.2476 - val_accuracy: 0.9318\n",
      "Epoch 23/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1888 - accuracy: 0.9577\n",
      "Epoch 23: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1887 - accuracy: 0.9572 - val_loss: 0.2576 - val_accuracy: 0.9228\n",
      "Epoch 24/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1845 - accuracy: 0.9595\n",
      "Epoch 24: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1841 - accuracy: 0.9592 - val_loss: 0.2436 - val_accuracy: 0.9284\n",
      "Epoch 25/30\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.9553\n",
      "Epoch 25: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1798 - accuracy: 0.9561 - val_loss: 0.2390 - val_accuracy: 0.9306\n",
      "Epoch 26/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1762 - accuracy: 0.9616\n",
      "Epoch 26: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1765 - accuracy: 0.9620 - val_loss: 0.2402 - val_accuracy: 0.9239\n",
      "Epoch 27/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1741 - accuracy: 0.9625\n",
      "Epoch 27: val_accuracy improved from 0.93177 to 0.93400, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1731 - accuracy: 0.9622 - val_loss: 0.2325 - val_accuracy: 0.9340\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9606\n",
      "Epoch 28: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1711 - accuracy: 0.9606 - val_loss: 0.2435 - val_accuracy: 0.9105\n",
      "Epoch 29/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1661 - accuracy: 0.9610\n",
      "Epoch 29: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1673 - accuracy: 0.9609 - val_loss: 0.2324 - val_accuracy: 0.9273\n",
      "Epoch 30/30\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1647 - accuracy: 0.9629\n",
      "Epoch 30: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1646 - accuracy: 0.9628 - val_loss: 0.2268 - val_accuracy: 0.9306\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 40, 'optimizer': 'adam'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6261 - accuracy: 0.6552\n",
      "Epoch 1: val_accuracy improved from -inf to 0.56823, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6261 - accuracy: 0.6552 - val_loss: 0.6648 - val_accuracy: 0.5682\n",
      "Epoch 2/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5259 - accuracy: 0.7855\n",
      "Epoch 2: val_accuracy improved from 0.56823 to 0.79418, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5231 - accuracy: 0.7880 - val_loss: 0.5171 - val_accuracy: 0.7942\n",
      "Epoch 3/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4567 - accuracy: 0.8505\n",
      "Epoch 3: val_accuracy improved from 0.79418 to 0.84340, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4559 - accuracy: 0.8518 - val_loss: 0.4676 - val_accuracy: 0.8434\n",
      "Epoch 4/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4129 - accuracy: 0.8800\n",
      "Epoch 4: val_accuracy did not improve from 0.84340\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4130 - accuracy: 0.8795 - val_loss: 0.4447 - val_accuracy: 0.8322\n",
      "Epoch 5/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8905\n",
      "Epoch 5: val_accuracy improved from 0.84340 to 0.88926, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3810 - accuracy: 0.8904 - val_loss: 0.4019 - val_accuracy: 0.8893\n",
      "Epoch 6/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3564 - accuracy: 0.9075\n",
      "Epoch 6: val_accuracy did not improve from 0.88926\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3565 - accuracy: 0.9052 - val_loss: 0.3879 - val_accuracy: 0.8770\n",
      "Epoch 7/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3302 - accuracy: 0.9158\n",
      "Epoch 7: val_accuracy improved from 0.88926 to 0.90604, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3302 - accuracy: 0.9147 - val_loss: 0.3646 - val_accuracy: 0.9060\n",
      "Epoch 8/40\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.3154 - accuracy: 0.9143\n",
      "Epoch 8: val_accuracy did not improve from 0.90604\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3157 - accuracy: 0.9136 - val_loss: 0.3638 - val_accuracy: 0.8691\n",
      "Epoch 9/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3059 - accuracy: 0.9131\n",
      "Epoch 9: val_accuracy improved from 0.90604 to 0.91723, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3044 - accuracy: 0.9122 - val_loss: 0.3365 - val_accuracy: 0.9172\n",
      "Epoch 10/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2781 - accuracy: 0.9385\n",
      "Epoch 10: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2800 - accuracy: 0.9360 - val_loss: 0.3251 - val_accuracy: 0.9150\n",
      "Epoch 11/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.9348\n",
      "Epoch 11: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2715 - accuracy: 0.9348 - val_loss: 0.3163 - val_accuracy: 0.9128\n",
      "Epoch 12/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2658 - accuracy: 0.9338\n",
      "Epoch 12: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2640 - accuracy: 0.9348 - val_loss: 0.3179 - val_accuracy: 0.8982\n",
      "Epoch 13/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2513 - accuracy: 0.9388\n",
      "Epoch 13: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2504 - accuracy: 0.9396 - val_loss: 0.3094 - val_accuracy: 0.9105\n",
      "Epoch 14/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9413\n",
      "Epoch 14: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2449 - accuracy: 0.9413 - val_loss: 0.3164 - val_accuracy: 0.8781\n",
      "Epoch 15/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2433 - accuracy: 0.9371\n",
      "Epoch 15: val_accuracy improved from 0.91723 to 0.92617, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2422 - accuracy: 0.9374 - val_loss: 0.2866 - val_accuracy: 0.9262\n",
      "Epoch 16/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2374 - accuracy: 0.9374\n",
      "Epoch 16: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2386 - accuracy: 0.9362 - val_loss: 0.3242 - val_accuracy: 0.8647\n",
      "Epoch 17/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2338 - accuracy: 0.9388\n",
      "Epoch 17: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2327 - accuracy: 0.9399 - val_loss: 0.2835 - val_accuracy: 0.9172\n",
      "Epoch 18/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2162 - accuracy: 0.9486\n",
      "Epoch 18: val_accuracy improved from 0.92617 to 0.92729, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2149 - accuracy: 0.9499 - val_loss: 0.2693 - val_accuracy: 0.9273\n",
      "Epoch 19/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2112 - accuracy: 0.9507\n",
      "Epoch 19: val_accuracy did not improve from 0.92729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2110 - accuracy: 0.9502 - val_loss: 0.2693 - val_accuracy: 0.9217\n",
      "Epoch 20/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2093 - accuracy: 0.9498\n",
      "Epoch 20: val_accuracy did not improve from 0.92729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2099 - accuracy: 0.9494 - val_loss: 0.2622 - val_accuracy: 0.9217\n",
      "Epoch 21/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1992 - accuracy: 0.9542\n",
      "Epoch 21: val_accuracy did not improve from 0.92729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2013 - accuracy: 0.9525 - val_loss: 0.2668 - val_accuracy: 0.9116\n",
      "Epoch 22/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1974 - accuracy: 0.9543\n",
      "Epoch 22: val_accuracy did not improve from 0.92729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1979 - accuracy: 0.9539 - val_loss: 0.2559 - val_accuracy: 0.9206\n",
      "Epoch 23/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.9578\n",
      "Epoch 23: val_accuracy did not improve from 0.92729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1924 - accuracy: 0.9578 - val_loss: 0.2556 - val_accuracy: 0.9239\n",
      "Epoch 24/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1864 - accuracy: 0.9569\n",
      "Epoch 24: val_accuracy improved from 0.92729 to 0.93065, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1873 - accuracy: 0.9555 - val_loss: 0.2463 - val_accuracy: 0.9306\n",
      "Epoch 25/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1853 - accuracy: 0.9595\n",
      "Epoch 25: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1853 - accuracy: 0.9583 - val_loss: 0.2455 - val_accuracy: 0.9251\n",
      "Epoch 26/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1831 - accuracy: 0.9598\n",
      "Epoch 26: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1833 - accuracy: 0.9583 - val_loss: 0.2871 - val_accuracy: 0.8792\n",
      "Epoch 27/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1846 - accuracy: 0.9560\n",
      "Epoch 27: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1863 - accuracy: 0.9553 - val_loss: 0.2418 - val_accuracy: 0.9251\n",
      "Epoch 28/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1739 - accuracy: 0.9592\n",
      "Epoch 28: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1742 - accuracy: 0.9586 - val_loss: 0.2373 - val_accuracy: 0.9251\n",
      "Epoch 29/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9592\n",
      "Epoch 29: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9592 - val_loss: 0.2322 - val_accuracy: 0.9284\n",
      "Epoch 30/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1693 - accuracy: 0.9607\n",
      "Epoch 30: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1709 - accuracy: 0.9609 - val_loss: 0.2361 - val_accuracy: 0.9251\n",
      "Epoch 31/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1711 - accuracy: 0.9583\n",
      "Epoch 31: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1700 - accuracy: 0.9592 - val_loss: 0.2654 - val_accuracy: 0.9049\n",
      "Epoch 32/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1657 - accuracy: 0.9607\n",
      "Epoch 32: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1658 - accuracy: 0.9603 - val_loss: 0.2331 - val_accuracy: 0.9206\n",
      "Epoch 33/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1618 - accuracy: 0.9613\n",
      "Epoch 33: val_accuracy improved from 0.93065 to 0.93400, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1619 - accuracy: 0.9622 - val_loss: 0.2216 - val_accuracy: 0.9340\n",
      "Epoch 34/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1614 - accuracy: 0.9631\n",
      "Epoch 34: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1623 - accuracy: 0.9617 - val_loss: 0.2435 - val_accuracy: 0.9060\n",
      "Epoch 35/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1589 - accuracy: 0.9622\n",
      "Epoch 35: val_accuracy improved from 0.93400 to 0.93512, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1586 - accuracy: 0.9622 - val_loss: 0.2193 - val_accuracy: 0.9351\n",
      "Epoch 36/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1538 - accuracy: 0.9650\n",
      "Epoch 36: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1544 - accuracy: 0.9648 - val_loss: 0.2186 - val_accuracy: 0.9329\n",
      "Epoch 37/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1541 - accuracy: 0.9648\n",
      "Epoch 37: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1532 - accuracy: 0.9659 - val_loss: 0.2242 - val_accuracy: 0.9295\n",
      "Epoch 38/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1565 - accuracy: 0.9625\n",
      "Epoch 38: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1560 - accuracy: 0.9617 - val_loss: 0.2235 - val_accuracy: 0.9262\n",
      "Epoch 39/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1538 - accuracy: 0.9620\n",
      "Epoch 39: val_accuracy improved from 0.93512 to 0.93624, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1539 - accuracy: 0.9625 - val_loss: 0.2114 - val_accuracy: 0.9362\n",
      "Epoch 40/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1459 - accuracy: 0.9660\n",
      "Epoch 40: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1471 - accuracy: 0.9639 - val_loss: 0.2514 - val_accuracy: 0.9094\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 40, 'optimizer': 'sgd'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6698 - accuracy: 0.6070\n",
      "Epoch 1: val_accuracy improved from -inf to 0.70134, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6658 - accuracy: 0.6119 - val_loss: 0.6096 - val_accuracy: 0.7013\n",
      "Epoch 2/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5817 - accuracy: 0.7101\n",
      "Epoch 2: val_accuracy improved from 0.70134 to 0.74608, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5792 - accuracy: 0.7114 - val_loss: 0.5699 - val_accuracy: 0.7461\n",
      "Epoch 3/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.5207 - accuracy: 0.7901\n",
      "Epoch 3: val_accuracy improved from 0.74608 to 0.75280, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5201 - accuracy: 0.7917 - val_loss: 0.5445 - val_accuracy: 0.7528\n",
      "Epoch 4/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4823 - accuracy: 0.8242\n",
      "Epoch 4: val_accuracy improved from 0.75280 to 0.82215, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4815 - accuracy: 0.8258 - val_loss: 0.4900 - val_accuracy: 0.8221\n",
      "Epoch 5/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4464 - accuracy: 0.8585\n",
      "Epoch 5: val_accuracy improved from 0.82215 to 0.84004, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4461 - accuracy: 0.8585 - val_loss: 0.4662 - val_accuracy: 0.8400\n",
      "Epoch 6/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4222 - accuracy: 0.8694\n",
      "Epoch 6: val_accuracy did not improve from 0.84004\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4213 - accuracy: 0.8688 - val_loss: 0.4703 - val_accuracy: 0.7942\n",
      "Epoch 7/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3987 - accuracy: 0.8859\n",
      "Epoch 7: val_accuracy improved from 0.84004 to 0.86689, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3994 - accuracy: 0.8873 - val_loss: 0.4319 - val_accuracy: 0.8669\n",
      "Epoch 8/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.9035\n",
      "Epoch 8: val_accuracy improved from 0.86689 to 0.89709, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3813 - accuracy: 0.9038 - val_loss: 0.4157 - val_accuracy: 0.8971\n",
      "Epoch 9/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3695 - accuracy: 0.9051\n",
      "Epoch 9: val_accuracy did not improve from 0.89709\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3668 - accuracy: 0.9072 - val_loss: 0.4312 - val_accuracy: 0.8356\n",
      "Epoch 10/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3534 - accuracy: 0.9113\n",
      "Epoch 10: val_accuracy improved from 0.89709 to 0.90604, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3543 - accuracy: 0.9100 - val_loss: 0.3906 - val_accuracy: 0.9060\n",
      "Epoch 11/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3428 - accuracy: 0.9161\n",
      "Epoch 11: val_accuracy did not improve from 0.90604\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3423 - accuracy: 0.9164 - val_loss: 0.3949 - val_accuracy: 0.8758\n",
      "Epoch 12/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3298 - accuracy: 0.9217\n",
      "Epoch 12: val_accuracy did not improve from 0.90604\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3317 - accuracy: 0.9214 - val_loss: 0.3735 - val_accuracy: 0.8993\n",
      "Epoch 13/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3188 - accuracy: 0.9279\n",
      "Epoch 13: val_accuracy did not improve from 0.90604\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3207 - accuracy: 0.9276 - val_loss: 0.3734 - val_accuracy: 0.9027\n",
      "Epoch 14/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3130 - accuracy: 0.9235\n",
      "Epoch 14: val_accuracy improved from 0.90604 to 0.91499, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3132 - accuracy: 0.9245 - val_loss: 0.3571 - val_accuracy: 0.9150\n",
      "Epoch 15/40\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.9328\n",
      "Epoch 15: val_accuracy improved from 0.91499 to 0.91611, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.3057 - accuracy: 0.9329 - val_loss: 0.3509 - val_accuracy: 0.9161\n",
      "Epoch 16/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.9317\n",
      "Epoch 16: val_accuracy did not improve from 0.91611\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2993 - accuracy: 0.9320 - val_loss: 0.3485 - val_accuracy: 0.9161\n",
      "Epoch 17/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2937 - accuracy: 0.9374\n",
      "Epoch 17: val_accuracy did not improve from 0.91611\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2931 - accuracy: 0.9371 - val_loss: 0.3523 - val_accuracy: 0.8770\n",
      "Epoch 18/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2889 - accuracy: 0.9359\n",
      "Epoch 18: val_accuracy did not improve from 0.91611\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2877 - accuracy: 0.9368 - val_loss: 0.3368 - val_accuracy: 0.9161\n",
      "Epoch 19/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2843 - accuracy: 0.9394\n",
      "Epoch 19: val_accuracy did not improve from 0.91611\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2817 - accuracy: 0.9413 - val_loss: 0.3351 - val_accuracy: 0.9150\n",
      "Epoch 20/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2761 - accuracy: 0.9397\n",
      "Epoch 20: val_accuracy improved from 0.91611 to 0.91834, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2745 - accuracy: 0.9416 - val_loss: 0.3285 - val_accuracy: 0.9183\n",
      "Epoch 21/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2702 - accuracy: 0.9379\n",
      "Epoch 21: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2698 - accuracy: 0.9388 - val_loss: 0.3221 - val_accuracy: 0.9161\n",
      "Epoch 22/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2676 - accuracy: 0.9400\n",
      "Epoch 22: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2669 - accuracy: 0.9399 - val_loss: 0.3179 - val_accuracy: 0.9183\n",
      "Epoch 23/40\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.2647 - accuracy: 0.9382\n",
      "Epoch 23: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2640 - accuracy: 0.9393 - val_loss: 0.3154 - val_accuracy: 0.9116\n",
      "Epoch 24/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2595 - accuracy: 0.9421\n",
      "Epoch 24: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2596 - accuracy: 0.9421 - val_loss: 0.3107 - val_accuracy: 0.9183\n",
      "Epoch 25/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2545 - accuracy: 0.9444\n",
      "Epoch 25: val_accuracy did not improve from 0.91834\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2550 - accuracy: 0.9441 - val_loss: 0.3078 - val_accuracy: 0.9183\n",
      "Epoch 26/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2510 - accuracy: 0.9439\n",
      "Epoch 26: val_accuracy improved from 0.91834 to 0.91946, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2525 - accuracy: 0.9438 - val_loss: 0.3049 - val_accuracy: 0.9195\n",
      "Epoch 27/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2472 - accuracy: 0.9471\n",
      "Epoch 27: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2475 - accuracy: 0.9463 - val_loss: 0.3018 - val_accuracy: 0.9183\n",
      "Epoch 28/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2455 - accuracy: 0.9468\n",
      "Epoch 28: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2445 - accuracy: 0.9474 - val_loss: 0.3035 - val_accuracy: 0.9161\n",
      "Epoch 29/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.9463\n",
      "Epoch 29: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2403 - accuracy: 0.9463 - val_loss: 0.3009 - val_accuracy: 0.9072\n",
      "Epoch 30/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2370 - accuracy: 0.9481\n",
      "Epoch 30: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2371 - accuracy: 0.9480 - val_loss: 0.2991 - val_accuracy: 0.9094\n",
      "Epoch 31/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2372 - accuracy: 0.9486\n",
      "Epoch 31: val_accuracy improved from 0.91946 to 0.92170, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2364 - accuracy: 0.9491 - val_loss: 0.2918 - val_accuracy: 0.9217\n",
      "Epoch 32/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2328 - accuracy: 0.9512\n",
      "Epoch 32: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2322 - accuracy: 0.9527 - val_loss: 0.2985 - val_accuracy: 0.9195\n",
      "Epoch 33/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2293 - accuracy: 0.9518\n",
      "Epoch 33: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2307 - accuracy: 0.9502 - val_loss: 0.2880 - val_accuracy: 0.9217\n",
      "Epoch 34/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2299 - accuracy: 0.9465\n",
      "Epoch 34: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2282 - accuracy: 0.9480 - val_loss: 0.2856 - val_accuracy: 0.9217\n",
      "Epoch 35/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9497\n",
      "Epoch 35: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2262 - accuracy: 0.9497 - val_loss: 0.2828 - val_accuracy: 0.9206\n",
      "Epoch 36/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2218 - accuracy: 0.9512\n",
      "Epoch 36: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2233 - accuracy: 0.9505 - val_loss: 0.2813 - val_accuracy: 0.9217\n",
      "Epoch 37/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2200 - accuracy: 0.9524\n",
      "Epoch 37: val_accuracy improved from 0.92170 to 0.92282, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2207 - accuracy: 0.9530 - val_loss: 0.2790 - val_accuracy: 0.9228\n",
      "Epoch 38/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2213 - accuracy: 0.9518\n",
      "Epoch 38: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2196 - accuracy: 0.9522 - val_loss: 0.2977 - val_accuracy: 0.9094\n",
      "Epoch 39/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2164 - accuracy: 0.9521\n",
      "Epoch 39: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2170 - accuracy: 0.9508 - val_loss: 0.2783 - val_accuracy: 0.9217\n",
      "Epoch 40/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2154 - accuracy: 0.9530\n",
      "Epoch 40: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2162 - accuracy: 0.9519 - val_loss: 0.2780 - val_accuracy: 0.9150\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 40, 'optimizer': 'rmsprop'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6908 - accuracy: 0.6127\n",
      "Epoch 1: val_accuracy improved from -inf to 0.65213, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6908 - accuracy: 0.6127 - val_loss: 0.6245 - val_accuracy: 0.6521\n",
      "Epoch 2/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5969 - accuracy: 0.6909\n",
      "Epoch 2: val_accuracy improved from 0.65213 to 0.78300, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5965 - accuracy: 0.6896 - val_loss: 0.5487 - val_accuracy: 0.7830\n",
      "Epoch 3/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5261 - accuracy: 0.7491\n",
      "Epoch 3: val_accuracy improved from 0.78300 to 0.81208, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5303 - accuracy: 0.7464 - val_loss: 0.5082 - val_accuracy: 0.8121\n",
      "Epoch 4/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4932 - accuracy: 0.7834\n",
      "Epoch 4: val_accuracy did not improve from 0.81208\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4942 - accuracy: 0.7799 - val_loss: 0.4830 - val_accuracy: 0.8087\n",
      "Epoch 5/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4559 - accuracy: 0.8094\n",
      "Epoch 5: val_accuracy did not improve from 0.81208\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4541 - accuracy: 0.8124 - val_loss: 0.4738 - val_accuracy: 0.8098\n",
      "Epoch 6/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4328 - accuracy: 0.8251\n",
      "Epoch 6: val_accuracy improved from 0.81208 to 0.81767, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4306 - accuracy: 0.8272 - val_loss: 0.4384 - val_accuracy: 0.8177\n",
      "Epoch 7/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3989 - accuracy: 0.8593\n",
      "Epoch 7: val_accuracy improved from 0.81767 to 0.87025, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4025 - accuracy: 0.8554 - val_loss: 0.4166 - val_accuracy: 0.8702\n",
      "Epoch 8/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3718 - accuracy: 0.8673\n",
      "Epoch 8: val_accuracy did not improve from 0.87025\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3720 - accuracy: 0.8669 - val_loss: 0.5346 - val_accuracy: 0.7013\n",
      "Epoch 9/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3664 - accuracy: 0.8715\n",
      "Epoch 9: val_accuracy improved from 0.87025 to 0.88591, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3645 - accuracy: 0.8728 - val_loss: 0.3763 - val_accuracy: 0.8859\n",
      "Epoch 10/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3456 - accuracy: 0.8871\n",
      "Epoch 10: val_accuracy improved from 0.88591 to 0.90268, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3431 - accuracy: 0.8907 - val_loss: 0.3581 - val_accuracy: 0.9027\n",
      "Epoch 11/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.8909\n",
      "Epoch 11: val_accuracy improved from 0.90268 to 0.91723, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3320 - accuracy: 0.8909 - val_loss: 0.3462 - val_accuracy: 0.9172\n",
      "Epoch 12/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3196 - accuracy: 0.8951\n",
      "Epoch 12: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3157 - accuracy: 0.8993 - val_loss: 0.3548 - val_accuracy: 0.8714\n",
      "Epoch 13/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3062 - accuracy: 0.9062\n",
      "Epoch 13: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3052 - accuracy: 0.9044 - val_loss: 0.5321 - val_accuracy: 0.7148\n",
      "Epoch 14/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2935 - accuracy: 0.9096\n",
      "Epoch 14: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2958 - accuracy: 0.9077 - val_loss: 0.4523 - val_accuracy: 0.7864\n",
      "Epoch 15/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2847 - accuracy: 0.9107\n",
      "Epoch 15: val_accuracy improved from 0.91723 to 0.92058, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2841 - accuracy: 0.9102 - val_loss: 0.3113 - val_accuracy: 0.9206\n",
      "Epoch 16/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2723 - accuracy: 0.9204\n",
      "Epoch 16: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2744 - accuracy: 0.9181 - val_loss: 0.3620 - val_accuracy: 0.8367\n",
      "Epoch 17/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2654 - accuracy: 0.9223\n",
      "Epoch 17: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2655 - accuracy: 0.9225 - val_loss: 0.2988 - val_accuracy: 0.9116\n",
      "Epoch 18/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2600 - accuracy: 0.9235\n",
      "Epoch 18: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2627 - accuracy: 0.9217 - val_loss: 0.2982 - val_accuracy: 0.9072\n",
      "Epoch 19/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2466 - accuracy: 0.9276\n",
      "Epoch 19: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2472 - accuracy: 0.9259 - val_loss: 0.3067 - val_accuracy: 0.9105\n",
      "Epoch 20/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2392 - accuracy: 0.9331\n",
      "Epoch 20: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2393 - accuracy: 0.9332 - val_loss: 0.4001 - val_accuracy: 0.7953\n",
      "Epoch 21/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2370 - accuracy: 0.9297\n",
      "Epoch 21: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2373 - accuracy: 0.9301 - val_loss: 0.2903 - val_accuracy: 0.8949\n",
      "Epoch 22/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2334 - accuracy: 0.9309\n",
      "Epoch 22: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2331 - accuracy: 0.9320 - val_loss: 0.2735 - val_accuracy: 0.9195\n",
      "Epoch 23/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.9396\n",
      "Epoch 23: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2243 - accuracy: 0.9396 - val_loss: 0.2752 - val_accuracy: 0.9116\n",
      "Epoch 24/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2250 - accuracy: 0.9309\n",
      "Epoch 24: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2239 - accuracy: 0.9326 - val_loss: 0.2810 - val_accuracy: 0.8982\n",
      "Epoch 25/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2184 - accuracy: 0.9371\n",
      "Epoch 25: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2172 - accuracy: 0.9371 - val_loss: 0.2690 - val_accuracy: 0.9161\n",
      "Epoch 26/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.9421\n",
      "Epoch 26: val_accuracy improved from 0.92058 to 0.92841, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2146 - accuracy: 0.9421 - val_loss: 0.2569 - val_accuracy: 0.9284\n",
      "Epoch 27/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2082 - accuracy: 0.9427\n",
      "Epoch 27: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2080 - accuracy: 0.9416 - val_loss: 0.2594 - val_accuracy: 0.9262\n",
      "Epoch 28/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2008 - accuracy: 0.9444\n",
      "Epoch 28: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2016 - accuracy: 0.9441 - val_loss: 0.2509 - val_accuracy: 0.9273\n",
      "Epoch 29/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2057 - accuracy: 0.9439\n",
      "Epoch 29: val_accuracy improved from 0.92841 to 0.93065, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2046 - accuracy: 0.9438 - val_loss: 0.2471 - val_accuracy: 0.9306\n",
      "Epoch 30/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2014 - accuracy: 0.9421\n",
      "Epoch 30: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2002 - accuracy: 0.9430 - val_loss: 0.2774 - val_accuracy: 0.9027\n",
      "Epoch 31/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1971 - accuracy: 0.9416\n",
      "Epoch 31: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1968 - accuracy: 0.9418 - val_loss: 0.2422 - val_accuracy: 0.9295\n",
      "Epoch 32/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1981 - accuracy: 0.9409\n",
      "Epoch 32: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1972 - accuracy: 0.9416 - val_loss: 0.2546 - val_accuracy: 0.9251\n",
      "Epoch 33/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1939 - accuracy: 0.9453\n",
      "Epoch 33: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1936 - accuracy: 0.9455 - val_loss: 0.2522 - val_accuracy: 0.9094\n",
      "Epoch 34/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1868 - accuracy: 0.9450\n",
      "Epoch 34: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1873 - accuracy: 0.9449 - val_loss: 0.2603 - val_accuracy: 0.9139\n",
      "Epoch 35/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1858 - accuracy: 0.9471\n",
      "Epoch 35: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1851 - accuracy: 0.9477 - val_loss: 0.3140 - val_accuracy: 0.8546\n",
      "Epoch 36/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1837 - accuracy: 0.9495\n",
      "Epoch 36: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1812 - accuracy: 0.9508 - val_loss: 0.2424 - val_accuracy: 0.9150\n",
      "Epoch 37/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.9491\n",
      "Epoch 37: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1826 - accuracy: 0.9491 - val_loss: 0.2289 - val_accuracy: 0.9295\n",
      "Epoch 38/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1784 - accuracy: 0.9495\n",
      "Epoch 38: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1758 - accuracy: 0.9508 - val_loss: 0.3132 - val_accuracy: 0.8702\n",
      "Epoch 39/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9516\n",
      "Epoch 39: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1749 - accuracy: 0.9516 - val_loss: 0.2760 - val_accuracy: 0.8937\n",
      "Epoch 40/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1745 - accuracy: 0.9530\n",
      "Epoch 40: val_accuracy improved from 0.93065 to 0.93400, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1725 - accuracy: 0.9536 - val_loss: 0.2238 - val_accuracy: 0.9340\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 40, 'optimizer': 'adagrad'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6734 - accuracy: 0.6014\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59396, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6720 - accuracy: 0.6043 - val_loss: 0.6677 - val_accuracy: 0.5940\n",
      "Epoch 2/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6456 - accuracy: 0.6608\n",
      "Epoch 2: val_accuracy improved from 0.59396 to 0.61633, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6454 - accuracy: 0.6622 - val_loss: 0.6488 - val_accuracy: 0.6163\n",
      "Epoch 3/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6334 - accuracy: 0.6764\n",
      "Epoch 3: val_accuracy improved from 0.61633 to 0.63199, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6323 - accuracy: 0.6801 - val_loss: 0.6397 - val_accuracy: 0.6320\n",
      "Epoch 4/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6218 - accuracy: 0.6953\n",
      "Epoch 4: val_accuracy improved from 0.63199 to 0.65213, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6217 - accuracy: 0.6941 - val_loss: 0.6326 - val_accuracy: 0.6521\n",
      "Epoch 5/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6141 - accuracy: 0.7057\n",
      "Epoch 5: val_accuracy improved from 0.65213 to 0.66443, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6133 - accuracy: 0.7069 - val_loss: 0.6263 - val_accuracy: 0.6644\n",
      "Epoch 6/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6049 - accuracy: 0.7163\n",
      "Epoch 6: val_accuracy improved from 0.66443 to 0.67338, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6061 - accuracy: 0.7136 - val_loss: 0.6206 - val_accuracy: 0.6734\n",
      "Epoch 7/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5990 - accuracy: 0.7249\n",
      "Epoch 7: val_accuracy improved from 0.67338 to 0.68792, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5997 - accuracy: 0.7226 - val_loss: 0.6165 - val_accuracy: 0.6879\n",
      "Epoch 8/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5945 - accuracy: 0.7276\n",
      "Epoch 8: val_accuracy did not improve from 0.68792\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5945 - accuracy: 0.7276 - val_loss: 0.6123 - val_accuracy: 0.6857\n",
      "Epoch 9/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5888 - accuracy: 0.7388\n",
      "Epoch 9: val_accuracy improved from 0.68792 to 0.69911, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5895 - accuracy: 0.7360 - val_loss: 0.6075 - val_accuracy: 0.6991\n",
      "Epoch 10/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5853 - accuracy: 0.7367\n",
      "Epoch 10: val_accuracy improved from 0.69911 to 0.71141, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5847 - accuracy: 0.7366 - val_loss: 0.6045 - val_accuracy: 0.7114\n",
      "Epoch 11/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5808 - accuracy: 0.7408\n",
      "Epoch 11: val_accuracy did not improve from 0.71141\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5808 - accuracy: 0.7408 - val_loss: 0.6005 - val_accuracy: 0.7081\n",
      "Epoch 12/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5771 - accuracy: 0.7420\n",
      "Epoch 12: val_accuracy improved from 0.71141 to 0.71253, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5769 - accuracy: 0.7422 - val_loss: 0.5974 - val_accuracy: 0.7125\n",
      "Epoch 13/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5722 - accuracy: 0.7485\n",
      "Epoch 13: val_accuracy improved from 0.71253 to 0.71924, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5729 - accuracy: 0.7489 - val_loss: 0.5944 - val_accuracy: 0.7192\n",
      "Epoch 14/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5695 - accuracy: 0.7550\n",
      "Epoch 14: val_accuracy did not improve from 0.71924\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5695 - accuracy: 0.7550 - val_loss: 0.5924 - val_accuracy: 0.7192\n",
      "Epoch 15/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5660 - accuracy: 0.7559\n",
      "Epoch 15: val_accuracy improved from 0.71924 to 0.73043, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5667 - accuracy: 0.7556 - val_loss: 0.5890 - val_accuracy: 0.7304\n",
      "Epoch 16/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5635 - accuracy: 0.7589\n",
      "Epoch 16: val_accuracy did not improve from 0.73043\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5635 - accuracy: 0.7587 - val_loss: 0.5864 - val_accuracy: 0.7304\n",
      "Epoch 17/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5605 - accuracy: 0.7630\n",
      "Epoch 17: val_accuracy did not improve from 0.73043\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5602 - accuracy: 0.7640 - val_loss: 0.5847 - val_accuracy: 0.7282\n",
      "Epoch 18/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5572 - accuracy: 0.7674\n",
      "Epoch 18: val_accuracy improved from 0.73043 to 0.73826, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5576 - accuracy: 0.7671 - val_loss: 0.5817 - val_accuracy: 0.7383\n",
      "Epoch 19/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5546 - accuracy: 0.7707\n",
      "Epoch 19: val_accuracy did not improve from 0.73826\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5548 - accuracy: 0.7707 - val_loss: 0.5805 - val_accuracy: 0.7360\n",
      "Epoch 20/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5521 - accuracy: 0.7745\n",
      "Epoch 20: val_accuracy improved from 0.73826 to 0.74385, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5525 - accuracy: 0.7740 - val_loss: 0.5774 - val_accuracy: 0.7438\n",
      "Epoch 21/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5520 - accuracy: 0.7730\n",
      "Epoch 21: val_accuracy improved from 0.74385 to 0.74497, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5502 - accuracy: 0.7746 - val_loss: 0.5753 - val_accuracy: 0.7450\n",
      "Epoch 22/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5477 - accuracy: 0.7807\n",
      "Epoch 22: val_accuracy improved from 0.74497 to 0.74608, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5474 - accuracy: 0.7816 - val_loss: 0.5733 - val_accuracy: 0.7461\n",
      "Epoch 23/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5443 - accuracy: 0.7837\n",
      "Epoch 23: val_accuracy did not improve from 0.74608\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5448 - accuracy: 0.7830 - val_loss: 0.5714 - val_accuracy: 0.7450\n",
      "Epoch 24/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5428 - accuracy: 0.7816\n",
      "Epoch 24: val_accuracy improved from 0.74608 to 0.75056, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5431 - accuracy: 0.7822 - val_loss: 0.5697 - val_accuracy: 0.7506\n",
      "Epoch 25/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5409 - accuracy: 0.7861\n",
      "Epoch 25: val_accuracy improved from 0.75056 to 0.75503, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5407 - accuracy: 0.7852 - val_loss: 0.5677 - val_accuracy: 0.7550\n",
      "Epoch 26/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5381 - accuracy: 0.7866\n",
      "Epoch 26: val_accuracy did not improve from 0.75503\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5387 - accuracy: 0.7886 - val_loss: 0.5660 - val_accuracy: 0.7506\n",
      "Epoch 27/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5374 - accuracy: 0.7908\n",
      "Epoch 27: val_accuracy did not improve from 0.75503\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5366 - accuracy: 0.7931 - val_loss: 0.5647 - val_accuracy: 0.7528\n",
      "Epoch 28/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5347 - accuracy: 0.7911\n",
      "Epoch 28: val_accuracy did not improve from 0.75503\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5349 - accuracy: 0.7922 - val_loss: 0.5627 - val_accuracy: 0.7539\n",
      "Epoch 29/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5330 - accuracy: 0.7949\n",
      "Epoch 29: val_accuracy did not improve from 0.75503\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5328 - accuracy: 0.7973 - val_loss: 0.5621 - val_accuracy: 0.7550\n",
      "Epoch 30/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5314 - accuracy: 0.7937\n",
      "Epoch 30: val_accuracy improved from 0.75503 to 0.75839, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5311 - accuracy: 0.7950 - val_loss: 0.5594 - val_accuracy: 0.7584\n",
      "Epoch 31/40\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.5294 - accuracy: 0.7984\n",
      "Epoch 31: val_accuracy did not improve from 0.75839\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5293 - accuracy: 0.7992 - val_loss: 0.5579 - val_accuracy: 0.7573\n",
      "Epoch 32/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5265 - accuracy: 0.8053\n",
      "Epoch 32: val_accuracy did not improve from 0.75839\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5276 - accuracy: 0.8026 - val_loss: 0.5565 - val_accuracy: 0.7584\n",
      "Epoch 33/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5262 - accuracy: 0.8082\n",
      "Epoch 33: val_accuracy improved from 0.75839 to 0.76174, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5258 - accuracy: 0.8070 - val_loss: 0.5550 - val_accuracy: 0.7617\n",
      "Epoch 34/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5243 - accuracy: 0.8044\n",
      "Epoch 34: val_accuracy improved from 0.76174 to 0.76734, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5240 - accuracy: 0.8051 - val_loss: 0.5543 - val_accuracy: 0.7673\n",
      "Epoch 35/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.8012\n",
      "Epoch 35: val_accuracy did not improve from 0.76734\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5223 - accuracy: 0.8012 - val_loss: 0.5532 - val_accuracy: 0.7651\n",
      "Epoch 36/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5210 - accuracy: 0.8053\n",
      "Epoch 36: val_accuracy did not improve from 0.76734\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5210 - accuracy: 0.8056 - val_loss: 0.5512 - val_accuracy: 0.7673\n",
      "Epoch 37/40\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.5193 - accuracy: 0.8141\n",
      "Epoch 37: val_accuracy improved from 0.76734 to 0.76846, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5195 - accuracy: 0.8132 - val_loss: 0.5494 - val_accuracy: 0.7685\n",
      "Epoch 38/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5181 - accuracy: 0.8112\n",
      "Epoch 38: val_accuracy improved from 0.76846 to 0.77181, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5180 - accuracy: 0.8104 - val_loss: 0.5484 - val_accuracy: 0.7718\n",
      "Epoch 39/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5161 - accuracy: 0.8132\n",
      "Epoch 39: val_accuracy improved from 0.77181 to 0.77293, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5165 - accuracy: 0.8143 - val_loss: 0.5470 - val_accuracy: 0.7729\n",
      "Epoch 40/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5150 - accuracy: 0.8174\n",
      "Epoch 40: val_accuracy did not improve from 0.77293\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5148 - accuracy: 0.8166 - val_loss: 0.5458 - val_accuracy: 0.7729\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 40, 'optimizer': 'adadelta'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7605 - accuracy: 0.4400\n",
      "Epoch 1: val_accuracy improved from -inf to 0.42729, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.7608 - accuracy: 0.4410 - val_loss: 0.7488 - val_accuracy: 0.4273\n",
      "Epoch 2/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.7440 - accuracy: 0.4376\n",
      "Epoch 2: val_accuracy did not improve from 0.42729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7440 - accuracy: 0.4376 - val_loss: 0.7373 - val_accuracy: 0.4150\n",
      "Epoch 3/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7342 - accuracy: 0.4403\n",
      "Epoch 3: val_accuracy did not improve from 0.42729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7344 - accuracy: 0.4390 - val_loss: 0.7305 - val_accuracy: 0.4116\n",
      "Epoch 4/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7279 - accuracy: 0.4539\n",
      "Epoch 4: val_accuracy did not improve from 0.42729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7283 - accuracy: 0.4527 - val_loss: 0.7263 - val_accuracy: 0.4094\n",
      "Epoch 5/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7245 - accuracy: 0.4583\n",
      "Epoch 5: val_accuracy did not improve from 0.42729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7243 - accuracy: 0.4578 - val_loss: 0.7233 - val_accuracy: 0.4262\n",
      "Epoch 6/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7204 - accuracy: 0.4704\n",
      "Epoch 6: val_accuracy improved from 0.42729 to 0.44295, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7213 - accuracy: 0.4673 - val_loss: 0.7210 - val_accuracy: 0.4430\n",
      "Epoch 7/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7188 - accuracy: 0.4726\n",
      "Epoch 7: val_accuracy improved from 0.44295 to 0.45078, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7189 - accuracy: 0.4740 - val_loss: 0.7192 - val_accuracy: 0.4508\n",
      "Epoch 8/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.7168 - accuracy: 0.4796\n",
      "Epoch 8: val_accuracy improved from 0.45078 to 0.47204, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7168 - accuracy: 0.4796 - val_loss: 0.7175 - val_accuracy: 0.4720\n",
      "Epoch 9/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7159 - accuracy: 0.4820\n",
      "Epoch 9: val_accuracy improved from 0.47204 to 0.47987, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7151 - accuracy: 0.4849 - val_loss: 0.7161 - val_accuracy: 0.4799\n",
      "Epoch 10/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7139 - accuracy: 0.4900\n",
      "Epoch 10: val_accuracy improved from 0.47987 to 0.49553, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7135 - accuracy: 0.4911 - val_loss: 0.7148 - val_accuracy: 0.4955\n",
      "Epoch 11/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7124 - accuracy: 0.4897\n",
      "Epoch 11: val_accuracy did not improve from 0.49553\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7120 - accuracy: 0.4919 - val_loss: 0.7135 - val_accuracy: 0.4955\n",
      "Epoch 12/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7111 - accuracy: 0.4956\n",
      "Epoch 12: val_accuracy did not improve from 0.49553\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7106 - accuracy: 0.4966 - val_loss: 0.7123 - val_accuracy: 0.4955\n",
      "Epoch 13/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7097 - accuracy: 0.5027\n",
      "Epoch 13: val_accuracy improved from 0.49553 to 0.49664, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7093 - accuracy: 0.5022 - val_loss: 0.7111 - val_accuracy: 0.4966\n",
      "Epoch 14/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7087 - accuracy: 0.5021\n",
      "Epoch 14: val_accuracy improved from 0.49664 to 0.49888, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7080 - accuracy: 0.5059 - val_loss: 0.7101 - val_accuracy: 0.4989\n",
      "Epoch 15/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7066 - accuracy: 0.5133\n",
      "Epoch 15: val_accuracy did not improve from 0.49888\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7069 - accuracy: 0.5109 - val_loss: 0.7091 - val_accuracy: 0.4989\n",
      "Epoch 16/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7063 - accuracy: 0.5121\n",
      "Epoch 16: val_accuracy improved from 0.49888 to 0.50336, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7058 - accuracy: 0.5131 - val_loss: 0.7081 - val_accuracy: 0.5034\n",
      "Epoch 17/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7049 - accuracy: 0.5145\n",
      "Epoch 17: val_accuracy did not improve from 0.50336\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7047 - accuracy: 0.5151 - val_loss: 0.7071 - val_accuracy: 0.5034\n",
      "Epoch 18/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7040 - accuracy: 0.5186\n",
      "Epoch 18: val_accuracy improved from 0.50336 to 0.50895, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7036 - accuracy: 0.5196 - val_loss: 0.7061 - val_accuracy: 0.5089\n",
      "Epoch 19/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7015 - accuracy: 0.5225\n",
      "Epoch 19: val_accuracy did not improve from 0.50895\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7025 - accuracy: 0.5201 - val_loss: 0.7052 - val_accuracy: 0.5067\n",
      "Epoch 20/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7016 - accuracy: 0.5224\n",
      "Epoch 20: val_accuracy improved from 0.50895 to 0.51007, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7015 - accuracy: 0.5213 - val_loss: 0.7043 - val_accuracy: 0.5101\n",
      "Epoch 21/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6999 - accuracy: 0.5269\n",
      "Epoch 21: val_accuracy improved from 0.51007 to 0.51342, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7004 - accuracy: 0.5240 - val_loss: 0.7033 - val_accuracy: 0.5134\n",
      "Epoch 22/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6989 - accuracy: 0.5278\n",
      "Epoch 22: val_accuracy improved from 0.51342 to 0.51566, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6994 - accuracy: 0.5240 - val_loss: 0.7025 - val_accuracy: 0.5157\n",
      "Epoch 23/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6994 - accuracy: 0.5233\n",
      "Epoch 23: val_accuracy improved from 0.51566 to 0.51902, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6985 - accuracy: 0.5260 - val_loss: 0.7017 - val_accuracy: 0.5190\n",
      "Epoch 24/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6978 - accuracy: 0.5269\n",
      "Epoch 24: val_accuracy improved from 0.51902 to 0.52125, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6976 - accuracy: 0.5277 - val_loss: 0.7009 - val_accuracy: 0.5213\n",
      "Epoch 25/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6965 - accuracy: 0.5263\n",
      "Epoch 25: val_accuracy did not improve from 0.52125\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6967 - accuracy: 0.5288 - val_loss: 0.7001 - val_accuracy: 0.5201\n",
      "Epoch 26/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6959 - accuracy: 0.5304\n",
      "Epoch 26: val_accuracy improved from 0.52125 to 0.52573, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6958 - accuracy: 0.5316 - val_loss: 0.6994 - val_accuracy: 0.5257\n",
      "Epoch 27/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6949 - accuracy: 0.5325\n",
      "Epoch 27: val_accuracy did not improve from 0.52573\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6949 - accuracy: 0.5313 - val_loss: 0.6986 - val_accuracy: 0.5257\n",
      "Epoch 28/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6946 - accuracy: 0.5361\n",
      "Epoch 28: val_accuracy improved from 0.52573 to 0.53020, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6941 - accuracy: 0.5364 - val_loss: 0.6979 - val_accuracy: 0.5302\n",
      "Epoch 29/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6936 - accuracy: 0.5375\n",
      "Epoch 29: val_accuracy did not improve from 0.53020\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6933 - accuracy: 0.5391 - val_loss: 0.6973 - val_accuracy: 0.5280\n",
      "Epoch 30/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6928 - accuracy: 0.5405\n",
      "Epoch 30: val_accuracy improved from 0.53020 to 0.53244, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6926 - accuracy: 0.5389 - val_loss: 0.6967 - val_accuracy: 0.5324\n",
      "Epoch 31/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6927 - accuracy: 0.5420\n",
      "Epoch 31: val_accuracy improved from 0.53244 to 0.53579, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6919 - accuracy: 0.5439 - val_loss: 0.6961 - val_accuracy: 0.5358\n",
      "Epoch 32/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6909 - accuracy: 0.5443\n",
      "Epoch 32: val_accuracy did not improve from 0.53579\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6912 - accuracy: 0.5456 - val_loss: 0.6955 - val_accuracy: 0.5347\n",
      "Epoch 33/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6910 - accuracy: 0.5485\n",
      "Epoch 33: val_accuracy improved from 0.53579 to 0.54139, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6905 - accuracy: 0.5489 - val_loss: 0.6949 - val_accuracy: 0.5414\n",
      "Epoch 34/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6895 - accuracy: 0.5502\n",
      "Epoch 34: val_accuracy did not improve from 0.54139\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6899 - accuracy: 0.5492 - val_loss: 0.6944 - val_accuracy: 0.5414\n",
      "Epoch 35/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6893 - accuracy: 0.5496\n",
      "Epoch 35: val_accuracy did not improve from 0.54139\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6892 - accuracy: 0.5489 - val_loss: 0.6938 - val_accuracy: 0.5391\n",
      "Epoch 36/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6888 - accuracy: 0.5526\n",
      "Epoch 36: val_accuracy did not improve from 0.54139\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6886 - accuracy: 0.5515 - val_loss: 0.6933 - val_accuracy: 0.5414\n",
      "Epoch 37/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6876 - accuracy: 0.5556\n",
      "Epoch 37: val_accuracy did not improve from 0.54139\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6880 - accuracy: 0.5529 - val_loss: 0.6928 - val_accuracy: 0.5391\n",
      "Epoch 38/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6873 - accuracy: 0.5570\n",
      "Epoch 38: val_accuracy did not improve from 0.54139\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6874 - accuracy: 0.5556 - val_loss: 0.6923 - val_accuracy: 0.5414\n",
      "Epoch 39/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6866 - accuracy: 0.5603\n",
      "Epoch 39: val_accuracy did not improve from 0.54139\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6868 - accuracy: 0.5584 - val_loss: 0.6918 - val_accuracy: 0.5380\n",
      "Epoch 40/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.5584\n",
      "Epoch 40: val_accuracy did not improve from 0.54139\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6863 - accuracy: 0.5584 - val_loss: 0.6914 - val_accuracy: 0.5391\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 40, 'optimizer': 'adamax'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6420 - accuracy: 0.6404\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66331, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6413 - accuracy: 0.6421 - val_loss: 0.6136 - val_accuracy: 0.6633\n",
      "Epoch 2/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5803 - accuracy: 0.7305\n",
      "Epoch 2: val_accuracy improved from 0.66331 to 0.71588, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5798 - accuracy: 0.7287 - val_loss: 0.5804 - val_accuracy: 0.7159\n",
      "Epoch 3/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5397 - accuracy: 0.7671\n",
      "Epoch 3: val_accuracy improved from 0.71588 to 0.79083, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5386 - accuracy: 0.7673 - val_loss: 0.5431 - val_accuracy: 0.7908\n",
      "Epoch 4/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5056 - accuracy: 0.8224\n",
      "Epoch 4: val_accuracy did not improve from 0.79083\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5034 - accuracy: 0.8255 - val_loss: 0.5310 - val_accuracy: 0.7595\n",
      "Epoch 5/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4747 - accuracy: 0.8401\n",
      "Epoch 5: val_accuracy improved from 0.79083 to 0.83445, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4762 - accuracy: 0.8375 - val_loss: 0.4932 - val_accuracy: 0.8345\n",
      "Epoch 6/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4509 - accuracy: 0.8632\n",
      "Epoch 6: val_accuracy improved from 0.83445 to 0.85235, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.4499 - accuracy: 0.8649 - val_loss: 0.4721 - val_accuracy: 0.8523\n",
      "Epoch 7/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4301 - accuracy: 0.8741\n",
      "Epoch 7: val_accuracy did not improve from 0.85235\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4283 - accuracy: 0.8767 - val_loss: 0.4656 - val_accuracy: 0.8412\n",
      "Epoch 8/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4091 - accuracy: 0.8833\n",
      "Epoch 8: val_accuracy improved from 0.85235 to 0.88143, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4098 - accuracy: 0.8834 - val_loss: 0.4371 - val_accuracy: 0.8814\n",
      "Epoch 9/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3937 - accuracy: 0.9046\n",
      "Epoch 9: val_accuracy did not improve from 0.88143\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3930 - accuracy: 0.9038 - val_loss: 0.4419 - val_accuracy: 0.8479\n",
      "Epoch 10/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3802 - accuracy: 0.9004\n",
      "Epoch 10: val_accuracy improved from 0.88143 to 0.88591, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3801 - accuracy: 0.8999 - val_loss: 0.4118 - val_accuracy: 0.8859\n",
      "Epoch 11/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3638 - accuracy: 0.9122\n",
      "Epoch 11: val_accuracy improved from 0.88591 to 0.89597, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3640 - accuracy: 0.9114 - val_loss: 0.3999 - val_accuracy: 0.8960\n",
      "Epoch 12/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3541 - accuracy: 0.9128\n",
      "Epoch 12: val_accuracy improved from 0.89597 to 0.90268, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3535 - accuracy: 0.9133 - val_loss: 0.3888 - val_accuracy: 0.9027\n",
      "Epoch 13/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3420 - accuracy: 0.9164\n",
      "Epoch 13: val_accuracy did not improve from 0.90268\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3401 - accuracy: 0.9167 - val_loss: 0.3815 - val_accuracy: 0.8893\n",
      "Epoch 14/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3294 - accuracy: 0.9255\n",
      "Epoch 14: val_accuracy improved from 0.90268 to 0.90716, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3298 - accuracy: 0.9253 - val_loss: 0.3705 - val_accuracy: 0.9072\n",
      "Epoch 15/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3239 - accuracy: 0.9246\n",
      "Epoch 15: val_accuracy did not improve from 0.90716\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3215 - accuracy: 0.9270 - val_loss: 0.3753 - val_accuracy: 0.8960\n",
      "Epoch 16/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3109 - accuracy: 0.9267\n",
      "Epoch 16: val_accuracy improved from 0.90716 to 0.91051, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3113 - accuracy: 0.9262 - val_loss: 0.3535 - val_accuracy: 0.9105\n",
      "Epoch 17/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3035 - accuracy: 0.9320\n",
      "Epoch 17: val_accuracy did not improve from 0.91051\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3027 - accuracy: 0.9323 - val_loss: 0.3668 - val_accuracy: 0.8870\n",
      "Epoch 18/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2957 - accuracy: 0.9278\n",
      "Epoch 18: val_accuracy improved from 0.91051 to 0.91723, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2948 - accuracy: 0.9295 - val_loss: 0.3393 - val_accuracy: 0.9172\n",
      "Epoch 19/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2888 - accuracy: 0.9371\n",
      "Epoch 19: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2866 - accuracy: 0.9382 - val_loss: 0.3518 - val_accuracy: 0.8792\n",
      "Epoch 20/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2801 - accuracy: 0.9306\n",
      "Epoch 20: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2826 - accuracy: 0.9304 - val_loss: 0.3302 - val_accuracy: 0.9072\n",
      "Epoch 21/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.9340\n",
      "Epoch 21: val_accuracy improved from 0.91723 to 0.92170, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2779 - accuracy: 0.9340 - val_loss: 0.3252 - val_accuracy: 0.9217\n",
      "Epoch 22/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2695 - accuracy: 0.9418\n",
      "Epoch 22: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2688 - accuracy: 0.9404 - val_loss: 0.3191 - val_accuracy: 0.9206\n",
      "Epoch 23/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2627 - accuracy: 0.9447\n",
      "Epoch 23: val_accuracy improved from 0.92170 to 0.92394, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2630 - accuracy: 0.9449 - val_loss: 0.3150 - val_accuracy: 0.9239\n",
      "Epoch 24/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2569 - accuracy: 0.9430\n",
      "Epoch 24: val_accuracy improved from 0.92394 to 0.92617, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2598 - accuracy: 0.9413 - val_loss: 0.3102 - val_accuracy: 0.9262\n",
      "Epoch 25/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2522 - accuracy: 0.9447\n",
      "Epoch 25: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2530 - accuracy: 0.9449 - val_loss: 0.3122 - val_accuracy: 0.9161\n",
      "Epoch 26/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2476 - accuracy: 0.9465\n",
      "Epoch 26: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2487 - accuracy: 0.9460 - val_loss: 0.3036 - val_accuracy: 0.9172\n",
      "Epoch 27/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2457 - accuracy: 0.9444\n",
      "Epoch 27: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2446 - accuracy: 0.9452 - val_loss: 0.3077 - val_accuracy: 0.8960\n",
      "Epoch 28/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2419 - accuracy: 0.9462\n",
      "Epoch 28: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2394 - accuracy: 0.9474 - val_loss: 0.2942 - val_accuracy: 0.9262\n",
      "Epoch 29/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2388 - accuracy: 0.9489\n",
      "Epoch 29: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2365 - accuracy: 0.9499 - val_loss: 0.2908 - val_accuracy: 0.9262\n",
      "Epoch 30/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2342 - accuracy: 0.9489\n",
      "Epoch 30: val_accuracy improved from 0.92617 to 0.92841, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2325 - accuracy: 0.9497 - val_loss: 0.2882 - val_accuracy: 0.9284\n",
      "Epoch 31/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2315 - accuracy: 0.9444\n",
      "Epoch 31: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2334 - accuracy: 0.9435 - val_loss: 0.2957 - val_accuracy: 0.8982\n",
      "Epoch 32/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2265 - accuracy: 0.9512\n",
      "Epoch 32: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2251 - accuracy: 0.9516 - val_loss: 0.2816 - val_accuracy: 0.9251\n",
      "Epoch 33/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2213 - accuracy: 0.9524\n",
      "Epoch 33: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2229 - accuracy: 0.9511 - val_loss: 0.2817 - val_accuracy: 0.9172\n",
      "Epoch 34/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2224 - accuracy: 0.9498\n",
      "Epoch 34: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2212 - accuracy: 0.9502 - val_loss: 0.2773 - val_accuracy: 0.9195\n",
      "Epoch 35/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2200 - accuracy: 0.9474\n",
      "Epoch 35: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2183 - accuracy: 0.9494 - val_loss: 0.2843 - val_accuracy: 0.9083\n",
      "Epoch 36/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2158 - accuracy: 0.9509\n",
      "Epoch 36: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2167 - accuracy: 0.9508 - val_loss: 0.2862 - val_accuracy: 0.9150\n",
      "Epoch 37/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2143 - accuracy: 0.9521\n",
      "Epoch 37: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2146 - accuracy: 0.9525 - val_loss: 0.2737 - val_accuracy: 0.9239\n",
      "Epoch 38/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2095 - accuracy: 0.9536\n",
      "Epoch 38: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2101 - accuracy: 0.9536 - val_loss: 0.2675 - val_accuracy: 0.9217\n",
      "Epoch 39/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2060 - accuracy: 0.9530\n",
      "Epoch 39: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2070 - accuracy: 0.9533 - val_loss: 0.2660 - val_accuracy: 0.9239\n",
      "Epoch 40/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2051 - accuracy: 0.9560\n",
      "Epoch 40: val_accuracy improved from 0.92841 to 0.92953, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2046 - accuracy: 0.9567 - val_loss: 0.2635 - val_accuracy: 0.9295\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 40, 'optimizer': 'ftrl'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6718 - accuracy: 0.6070\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62416, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6712 - accuracy: 0.6082 - val_loss: 0.6594 - val_accuracy: 0.6242\n",
      "Epoch 2/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6472 - accuracy: 0.6643\n",
      "Epoch 2: val_accuracy improved from 0.62416 to 0.63535, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6470 - accuracy: 0.6616 - val_loss: 0.6478 - val_accuracy: 0.6353\n",
      "Epoch 3/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6339 - accuracy: 0.6803\n",
      "Epoch 3: val_accuracy improved from 0.63535 to 0.64318, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6333 - accuracy: 0.6829 - val_loss: 0.6421 - val_accuracy: 0.6432\n",
      "Epoch 4/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6251 - accuracy: 0.6909\n",
      "Epoch 4: val_accuracy improved from 0.64318 to 0.64877, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6248 - accuracy: 0.6893 - val_loss: 0.6336 - val_accuracy: 0.6488\n",
      "Epoch 5/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6172 - accuracy: 0.6974\n",
      "Epoch 5: val_accuracy improved from 0.64877 to 0.67002, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6166 - accuracy: 0.6997 - val_loss: 0.6276 - val_accuracy: 0.6700\n",
      "Epoch 6/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6099 - accuracy: 0.7142\n",
      "Epoch 6: val_accuracy improved from 0.67002 to 0.68345, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6099 - accuracy: 0.7131 - val_loss: 0.6226 - val_accuracy: 0.6834\n",
      "Epoch 7/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6032 - accuracy: 0.7148\n",
      "Epoch 7: val_accuracy improved from 0.68345 to 0.69128, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6040 - accuracy: 0.7145 - val_loss: 0.6181 - val_accuracy: 0.6913\n",
      "Epoch 8/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5992 - accuracy: 0.7213\n",
      "Epoch 8: val_accuracy improved from 0.69128 to 0.69911, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5987 - accuracy: 0.7212 - val_loss: 0.6139 - val_accuracy: 0.6991\n",
      "Epoch 9/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5935 - accuracy: 0.7284\n",
      "Epoch 9: val_accuracy improved from 0.69911 to 0.70134, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5938 - accuracy: 0.7268 - val_loss: 0.6103 - val_accuracy: 0.7013\n",
      "Epoch 10/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5890 - accuracy: 0.7355\n",
      "Epoch 10: val_accuracy did not improve from 0.70134\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5896 - accuracy: 0.7341 - val_loss: 0.6067 - val_accuracy: 0.7013\n",
      "Epoch 11/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5846 - accuracy: 0.7400\n",
      "Epoch 11: val_accuracy improved from 0.70134 to 0.70358, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5856 - accuracy: 0.7383 - val_loss: 0.6035 - val_accuracy: 0.7036\n",
      "Epoch 12/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.5817 - accuracy: 0.7353\n",
      "Epoch 12: val_accuracy improved from 0.70358 to 0.70582, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5817 - accuracy: 0.7352 - val_loss: 0.6010 - val_accuracy: 0.7058\n",
      "Epoch 13/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5771 - accuracy: 0.7479\n",
      "Epoch 13: val_accuracy improved from 0.70582 to 0.71365, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5784 - accuracy: 0.7452 - val_loss: 0.5977 - val_accuracy: 0.7136\n",
      "Epoch 14/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5756 - accuracy: 0.7456\n",
      "Epoch 14: val_accuracy did not improve from 0.71365\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5751 - accuracy: 0.7469 - val_loss: 0.5960 - val_accuracy: 0.7103\n",
      "Epoch 15/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5713 - accuracy: 0.7538\n",
      "Epoch 15: val_accuracy improved from 0.71365 to 0.72371, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5719 - accuracy: 0.7531 - val_loss: 0.5928 - val_accuracy: 0.7237\n",
      "Epoch 16/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5703 - accuracy: 0.7553\n",
      "Epoch 16: val_accuracy did not improve from 0.72371\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5690 - accuracy: 0.7587 - val_loss: 0.5902 - val_accuracy: 0.7215\n",
      "Epoch 17/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5670 - accuracy: 0.7612\n",
      "Epoch 17: val_accuracy improved from 0.72371 to 0.72483, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5659 - accuracy: 0.7626 - val_loss: 0.5879 - val_accuracy: 0.7248\n",
      "Epoch 18/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5642 - accuracy: 0.7609\n",
      "Epoch 18: val_accuracy improved from 0.72483 to 0.73378, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5634 - accuracy: 0.7609 - val_loss: 0.5854 - val_accuracy: 0.7338\n",
      "Epoch 19/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5598 - accuracy: 0.7683\n",
      "Epoch 19: val_accuracy did not improve from 0.73378\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5605 - accuracy: 0.7668 - val_loss: 0.5836 - val_accuracy: 0.7338\n",
      "Epoch 20/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5586 - accuracy: 0.7671\n",
      "Epoch 20: val_accuracy improved from 0.73378 to 0.73602, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5579 - accuracy: 0.7687 - val_loss: 0.5819 - val_accuracy: 0.7360\n",
      "Epoch 21/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5561 - accuracy: 0.7683\n",
      "Epoch 21: val_accuracy improved from 0.73602 to 0.74049, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5555 - accuracy: 0.7693 - val_loss: 0.5792 - val_accuracy: 0.7405\n",
      "Epoch 22/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5527 - accuracy: 0.7793\n",
      "Epoch 22: val_accuracy improved from 0.74049 to 0.74161, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5532 - accuracy: 0.7760 - val_loss: 0.5774 - val_accuracy: 0.7416\n",
      "Epoch 23/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.7782\n",
      "Epoch 23: val_accuracy improved from 0.74161 to 0.74497, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5509 - accuracy: 0.7782 - val_loss: 0.5753 - val_accuracy: 0.7450\n",
      "Epoch 24/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5490 - accuracy: 0.7807\n",
      "Epoch 24: val_accuracy improved from 0.74497 to 0.74832, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5489 - accuracy: 0.7799 - val_loss: 0.5734 - val_accuracy: 0.7483\n",
      "Epoch 25/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5468 - accuracy: 0.7834\n",
      "Epoch 25: val_accuracy did not improve from 0.74832\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5467 - accuracy: 0.7833 - val_loss: 0.5721 - val_accuracy: 0.7461\n",
      "Epoch 26/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5435 - accuracy: 0.7881\n",
      "Epoch 26: val_accuracy did not improve from 0.74832\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5445 - accuracy: 0.7866 - val_loss: 0.5706 - val_accuracy: 0.7483\n",
      "Epoch 27/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5425 - accuracy: 0.7866\n",
      "Epoch 27: val_accuracy improved from 0.74832 to 0.74944, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5425 - accuracy: 0.7866 - val_loss: 0.5687 - val_accuracy: 0.7494\n",
      "Epoch 28/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5401 - accuracy: 0.7911\n",
      "Epoch 28: val_accuracy improved from 0.74944 to 0.75280, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5406 - accuracy: 0.7894 - val_loss: 0.5668 - val_accuracy: 0.7528\n",
      "Epoch 29/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5396 - accuracy: 0.7908\n",
      "Epoch 29: val_accuracy improved from 0.75280 to 0.75392, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5386 - accuracy: 0.7922 - val_loss: 0.5651 - val_accuracy: 0.7539\n",
      "Epoch 30/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5380 - accuracy: 0.7911\n",
      "Epoch 30: val_accuracy improved from 0.75392 to 0.75615, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5368 - accuracy: 0.7942 - val_loss: 0.5636 - val_accuracy: 0.7562\n",
      "Epoch 31/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5362 - accuracy: 0.7914\n",
      "Epoch 31: val_accuracy improved from 0.75615 to 0.75951, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5351 - accuracy: 0.7936 - val_loss: 0.5619 - val_accuracy: 0.7595\n",
      "Epoch 32/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5331 - accuracy: 0.7979\n",
      "Epoch 32: val_accuracy improved from 0.75951 to 0.76398, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5336 - accuracy: 0.7956 - val_loss: 0.5604 - val_accuracy: 0.7640\n",
      "Epoch 33/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5301 - accuracy: 0.8031\n",
      "Epoch 33: val_accuracy did not improve from 0.76398\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5314 - accuracy: 0.7978 - val_loss: 0.5590 - val_accuracy: 0.7629\n",
      "Epoch 34/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5314 - accuracy: 0.7983\n",
      "Epoch 34: val_accuracy improved from 0.76398 to 0.76510, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5299 - accuracy: 0.7989 - val_loss: 0.5577 - val_accuracy: 0.7651\n",
      "Epoch 35/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5285 - accuracy: 0.7991\n",
      "Epoch 35: val_accuracy improved from 0.76510 to 0.76622, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5285 - accuracy: 0.7992 - val_loss: 0.5562 - val_accuracy: 0.7662\n",
      "Epoch 36/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5273 - accuracy: 0.8026\n",
      "Epoch 36: val_accuracy improved from 0.76622 to 0.76846, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5266 - accuracy: 0.8034 - val_loss: 0.5549 - val_accuracy: 0.7685\n",
      "Epoch 37/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5249 - accuracy: 0.8041\n",
      "Epoch 37: val_accuracy did not improve from 0.76846\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5253 - accuracy: 0.8043 - val_loss: 0.5536 - val_accuracy: 0.7685\n",
      "Epoch 38/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5237 - accuracy: 0.8103\n",
      "Epoch 38: val_accuracy improved from 0.76846 to 0.76957, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5237 - accuracy: 0.8090 - val_loss: 0.5522 - val_accuracy: 0.7696\n",
      "Epoch 39/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5211 - accuracy: 0.8088\n",
      "Epoch 39: val_accuracy did not improve from 0.76957\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5217 - accuracy: 0.8068 - val_loss: 0.5517 - val_accuracy: 0.7685\n",
      "Epoch 40/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5207 - accuracy: 0.8091\n",
      "Epoch 40: val_accuracy improved from 0.76957 to 0.77069, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5208 - accuracy: 0.8084 - val_loss: 0.5497 - val_accuracy: 0.7707\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 40, 'optimizer': 'nadam'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6248 - accuracy: 0.6636\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74832, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6246 - accuracy: 0.6641 - val_loss: 0.5725 - val_accuracy: 0.7483\n",
      "Epoch 2/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5205 - accuracy: 0.7943\n",
      "Epoch 2: val_accuracy improved from 0.74832 to 0.78523, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5175 - accuracy: 0.7964 - val_loss: 0.5144 - val_accuracy: 0.7852\n",
      "Epoch 3/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4583 - accuracy: 0.8431\n",
      "Epoch 3: val_accuracy improved from 0.78523 to 0.85011, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4559 - accuracy: 0.8440 - val_loss: 0.4647 - val_accuracy: 0.8501\n",
      "Epoch 4/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4151 - accuracy: 0.8830\n",
      "Epoch 4: val_accuracy improved from 0.85011 to 0.87584, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4129 - accuracy: 0.8848 - val_loss: 0.4275 - val_accuracy: 0.8758\n",
      "Epoch 5/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3785 - accuracy: 0.8966\n",
      "Epoch 5: val_accuracy improved from 0.87584 to 0.89262, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3766 - accuracy: 0.8990 - val_loss: 0.4024 - val_accuracy: 0.8926\n",
      "Epoch 6/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3514 - accuracy: 0.9102\n",
      "Epoch 6: val_accuracy improved from 0.89262 to 0.90604, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3499 - accuracy: 0.9122 - val_loss: 0.3807 - val_accuracy: 0.9060\n",
      "Epoch 7/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.9211\n",
      "Epoch 7: val_accuracy improved from 0.90604 to 0.90940, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3276 - accuracy: 0.9211 - val_loss: 0.3645 - val_accuracy: 0.9094\n",
      "Epoch 8/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3093 - accuracy: 0.9196\n",
      "Epoch 8: val_accuracy improved from 0.90940 to 0.91387, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3118 - accuracy: 0.9195 - val_loss: 0.3497 - val_accuracy: 0.9139\n",
      "Epoch 9/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2925 - accuracy: 0.9365\n",
      "Epoch 9: val_accuracy did not improve from 0.91387\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2924 - accuracy: 0.9365 - val_loss: 0.3386 - val_accuracy: 0.9128\n",
      "Epoch 10/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2793 - accuracy: 0.9303\n",
      "Epoch 10: val_accuracy did not improve from 0.91387\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2792 - accuracy: 0.9304 - val_loss: 0.3529 - val_accuracy: 0.8591\n",
      "Epoch 11/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2679 - accuracy: 0.9400\n",
      "Epoch 11: val_accuracy did not improve from 0.91387\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2687 - accuracy: 0.9390 - val_loss: 0.3202 - val_accuracy: 0.9038\n",
      "Epoch 12/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2587 - accuracy: 0.9424\n",
      "Epoch 12: val_accuracy improved from 0.91387 to 0.92729, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2575 - accuracy: 0.9427 - val_loss: 0.3047 - val_accuracy: 0.9273\n",
      "Epoch 13/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2478 - accuracy: 0.9453\n",
      "Epoch 13: val_accuracy did not improve from 0.92729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2483 - accuracy: 0.9446 - val_loss: 0.2998 - val_accuracy: 0.9251\n",
      "Epoch 14/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2400 - accuracy: 0.9430\n",
      "Epoch 14: val_accuracy did not improve from 0.92729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2394 - accuracy: 0.9421 - val_loss: 0.2950 - val_accuracy: 0.9195\n",
      "Epoch 15/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2319 - accuracy: 0.9501\n",
      "Epoch 15: val_accuracy did not improve from 0.92729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2331 - accuracy: 0.9494 - val_loss: 0.2863 - val_accuracy: 0.9206\n",
      "Epoch 16/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2259 - accuracy: 0.9489\n",
      "Epoch 16: val_accuracy did not improve from 0.92729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2244 - accuracy: 0.9497 - val_loss: 0.2768 - val_accuracy: 0.9273\n",
      "Epoch 17/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2176 - accuracy: 0.9504\n",
      "Epoch 17: val_accuracy did not improve from 0.92729\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2178 - accuracy: 0.9508 - val_loss: 0.2714 - val_accuracy: 0.9273\n",
      "Epoch 18/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2131 - accuracy: 0.9536\n",
      "Epoch 18: val_accuracy improved from 0.92729 to 0.92953, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2124 - accuracy: 0.9541 - val_loss: 0.2688 - val_accuracy: 0.9295\n",
      "Epoch 19/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2077 - accuracy: 0.9530\n",
      "Epoch 19: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2077 - accuracy: 0.9530 - val_loss: 0.2708 - val_accuracy: 0.9217\n",
      "Epoch 20/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2055 - accuracy: 0.9495\n",
      "Epoch 20: val_accuracy improved from 0.92953 to 0.93177, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2042 - accuracy: 0.9508 - val_loss: 0.2574 - val_accuracy: 0.9318\n",
      "Epoch 21/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1975 - accuracy: 0.9574\n",
      "Epoch 21: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1977 - accuracy: 0.9578 - val_loss: 0.2629 - val_accuracy: 0.9251\n",
      "Epoch 22/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1926 - accuracy: 0.9572\n",
      "Epoch 22: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1936 - accuracy: 0.9561 - val_loss: 0.2673 - val_accuracy: 0.9161\n",
      "Epoch 23/40\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.1876 - accuracy: 0.9553\n",
      "Epoch 23: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1891 - accuracy: 0.9550 - val_loss: 0.2471 - val_accuracy: 0.9262\n",
      "Epoch 24/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.9581\n",
      "Epoch 24: val_accuracy improved from 0.93177 to 0.93512, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1857 - accuracy: 0.9581 - val_loss: 0.2406 - val_accuracy: 0.9351\n",
      "Epoch 25/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1801 - accuracy: 0.9569\n",
      "Epoch 25: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1797 - accuracy: 0.9581 - val_loss: 0.2378 - val_accuracy: 0.9340\n",
      "Epoch 26/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1769 - accuracy: 0.9592\n",
      "Epoch 26: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1776 - accuracy: 0.9592 - val_loss: 0.2433 - val_accuracy: 0.9183\n",
      "Epoch 27/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1730 - accuracy: 0.9607\n",
      "Epoch 27: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1744 - accuracy: 0.9595 - val_loss: 0.2328 - val_accuracy: 0.9340\n",
      "Epoch 28/40\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.9622\n",
      "Epoch 28: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1722 - accuracy: 0.9622 - val_loss: 0.2319 - val_accuracy: 0.9329\n",
      "Epoch 29/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1690 - accuracy: 0.9607\n",
      "Epoch 29: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1689 - accuracy: 0.9614 - val_loss: 0.2278 - val_accuracy: 0.9340\n",
      "Epoch 30/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1643 - accuracy: 0.9625\n",
      "Epoch 30: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1658 - accuracy: 0.9625 - val_loss: 0.2247 - val_accuracy: 0.9340\n",
      "Epoch 31/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1626 - accuracy: 0.9607\n",
      "Epoch 31: val_accuracy improved from 0.93512 to 0.93624, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1640 - accuracy: 0.9609 - val_loss: 0.2223 - val_accuracy: 0.9362\n",
      "Epoch 32/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1588 - accuracy: 0.9666\n",
      "Epoch 32: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1604 - accuracy: 0.9645 - val_loss: 0.2228 - val_accuracy: 0.9318\n",
      "Epoch 33/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1576 - accuracy: 0.9657\n",
      "Epoch 33: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1579 - accuracy: 0.9648 - val_loss: 0.2208 - val_accuracy: 0.9306\n",
      "Epoch 34/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1546 - accuracy: 0.9654\n",
      "Epoch 34: val_accuracy improved from 0.93624 to 0.93960, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1561 - accuracy: 0.9653 - val_loss: 0.2154 - val_accuracy: 0.9396\n",
      "Epoch 35/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1555 - accuracy: 0.9631\n",
      "Epoch 35: val_accuracy did not improve from 0.93960\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1537 - accuracy: 0.9645 - val_loss: 0.2209 - val_accuracy: 0.9251\n",
      "Epoch 36/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1521 - accuracy: 0.9648\n",
      "Epoch 36: val_accuracy did not improve from 0.93960\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1514 - accuracy: 0.9648 - val_loss: 0.2126 - val_accuracy: 0.9351\n",
      "Epoch 37/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1487 - accuracy: 0.9681\n",
      "Epoch 37: val_accuracy did not improve from 0.93960\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1475 - accuracy: 0.9678 - val_loss: 0.2097 - val_accuracy: 0.9351\n",
      "Epoch 38/40\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1468 - accuracy: 0.9698\n",
      "Epoch 38: val_accuracy did not improve from 0.93960\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1468 - accuracy: 0.9698 - val_loss: 0.2079 - val_accuracy: 0.9374\n",
      "Epoch 39/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1458 - accuracy: 0.9666\n",
      "Epoch 39: val_accuracy did not improve from 0.93960\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1443 - accuracy: 0.9673 - val_loss: 0.2194 - val_accuracy: 0.9228\n",
      "Epoch 40/40\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1412 - accuracy: 0.9687\n",
      "Epoch 40: val_accuracy did not improve from 0.93960\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1427 - accuracy: 0.9676 - val_loss: 0.2035 - val_accuracy: 0.9362\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 50, 'optimizer': 'adam'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6548 - accuracy: 0.6182\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64989, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6503 - accuracy: 0.6250 - val_loss: 0.6215 - val_accuracy: 0.6499\n",
      "Epoch 2/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.5494 - accuracy: 0.7492\n",
      "Epoch 2: val_accuracy improved from 0.64989 to 0.81544, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5484 - accuracy: 0.7506 - val_loss: 0.5297 - val_accuracy: 0.8154\n",
      "Epoch 3/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4843 - accuracy: 0.8150\n",
      "Epoch 3: val_accuracy did not improve from 0.81544\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4847 - accuracy: 0.8140 - val_loss: 0.5125 - val_accuracy: 0.7651\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8702\n",
      "Epoch 4: val_accuracy did not improve from 0.81544\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4318 - accuracy: 0.8702 - val_loss: 0.4741 - val_accuracy: 0.8098\n",
      "Epoch 5/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4018 - accuracy: 0.8750\n",
      "Epoch 5: val_accuracy improved from 0.81544 to 0.87919, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4022 - accuracy: 0.8753 - val_loss: 0.4247 - val_accuracy: 0.8792\n",
      "Epoch 6/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3704 - accuracy: 0.9048\n",
      "Epoch 6: val_accuracy did not improve from 0.87919\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3714 - accuracy: 0.9018 - val_loss: 0.4101 - val_accuracy: 0.8736\n",
      "Epoch 7/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3489 - accuracy: 0.8983\n",
      "Epoch 7: val_accuracy improved from 0.87919 to 0.89038, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3504 - accuracy: 0.8982 - val_loss: 0.3899 - val_accuracy: 0.8904\n",
      "Epoch 8/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3263 - accuracy: 0.9178\n",
      "Epoch 8: val_accuracy improved from 0.89038 to 0.90380, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3273 - accuracy: 0.9175 - val_loss: 0.3679 - val_accuracy: 0.9038\n",
      "Epoch 9/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3133 - accuracy: 0.9190\n",
      "Epoch 9: val_accuracy did not improve from 0.90380\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3115 - accuracy: 0.9211 - val_loss: 0.3588 - val_accuracy: 0.9027\n",
      "Epoch 10/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2921 - accuracy: 0.9297\n",
      "Epoch 10: val_accuracy did not improve from 0.90380\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2943 - accuracy: 0.9290 - val_loss: 0.3444 - val_accuracy: 0.8881\n",
      "Epoch 11/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2836 - accuracy: 0.9297\n",
      "Epoch 11: val_accuracy improved from 0.90380 to 0.91946, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2835 - accuracy: 0.9298 - val_loss: 0.3234 - val_accuracy: 0.9195\n",
      "Epoch 12/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2721 - accuracy: 0.9347\n",
      "Epoch 12: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2708 - accuracy: 0.9351 - val_loss: 0.3238 - val_accuracy: 0.8993\n",
      "Epoch 13/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2580 - accuracy: 0.9412\n",
      "Epoch 13: val_accuracy improved from 0.91946 to 0.92170, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2583 - accuracy: 0.9413 - val_loss: 0.3060 - val_accuracy: 0.9217\n",
      "Epoch 14/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2493 - accuracy: 0.9447\n",
      "Epoch 14: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2508 - accuracy: 0.9432 - val_loss: 0.3082 - val_accuracy: 0.9150\n",
      "Epoch 15/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2461 - accuracy: 0.9359\n",
      "Epoch 15: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2447 - accuracy: 0.9368 - val_loss: 0.2964 - val_accuracy: 0.9038\n",
      "Epoch 16/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2529 - accuracy: 0.9244\n",
      "Epoch 16: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2535 - accuracy: 0.9239 - val_loss: 0.2916 - val_accuracy: 0.9183\n",
      "Epoch 17/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2273 - accuracy: 0.9462\n",
      "Epoch 17: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2275 - accuracy: 0.9466 - val_loss: 0.2794 - val_accuracy: 0.9217\n",
      "Epoch 18/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2266 - accuracy: 0.9489\n",
      "Epoch 18: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2255 - accuracy: 0.9485 - val_loss: 0.2740 - val_accuracy: 0.9195\n",
      "Epoch 19/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2209 - accuracy: 0.9496\n",
      "Epoch 19: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2195 - accuracy: 0.9502 - val_loss: 0.2707 - val_accuracy: 0.9183\n",
      "Epoch 20/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2140 - accuracy: 0.9447\n",
      "Epoch 20: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2139 - accuracy: 0.9441 - val_loss: 0.2920 - val_accuracy: 0.8870\n",
      "Epoch 21/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2032 - accuracy: 0.9554\n",
      "Epoch 21: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2059 - accuracy: 0.9536 - val_loss: 0.2765 - val_accuracy: 0.9183\n",
      "Epoch 22/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2016 - accuracy: 0.9542\n",
      "Epoch 22: val_accuracy did not improve from 0.92170\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2042 - accuracy: 0.9519 - val_loss: 0.2693 - val_accuracy: 0.9217\n",
      "Epoch 23/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2019 - accuracy: 0.9527\n",
      "Epoch 23: val_accuracy improved from 0.92170 to 0.92506, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2014 - accuracy: 0.9536 - val_loss: 0.2597 - val_accuracy: 0.9251\n",
      "Epoch 24/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1921 - accuracy: 0.9580\n",
      "Epoch 24: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1915 - accuracy: 0.9578 - val_loss: 0.2584 - val_accuracy: 0.9172\n",
      "Epoch 25/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1894 - accuracy: 0.9557\n",
      "Epoch 25: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1912 - accuracy: 0.9544 - val_loss: 0.2473 - val_accuracy: 0.9251\n",
      "Epoch 26/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1867 - accuracy: 0.9557\n",
      "Epoch 26: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1861 - accuracy: 0.9561 - val_loss: 0.2574 - val_accuracy: 0.9049\n",
      "Epoch 27/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1876 - accuracy: 0.9534\n",
      "Epoch 27: val_accuracy improved from 0.92506 to 0.92729, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1864 - accuracy: 0.9536 - val_loss: 0.2451 - val_accuracy: 0.9273\n",
      "Epoch 28/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1868 - accuracy: 0.9509\n",
      "Epoch 28: val_accuracy improved from 0.92729 to 0.93065, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1883 - accuracy: 0.9508 - val_loss: 0.2428 - val_accuracy: 0.9306\n",
      "Epoch 29/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1747 - accuracy: 0.9580\n",
      "Epoch 29: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1759 - accuracy: 0.9575 - val_loss: 0.2361 - val_accuracy: 0.9239\n",
      "Epoch 30/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1759 - accuracy: 0.9598\n",
      "Epoch 30: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1759 - accuracy: 0.9595 - val_loss: 0.2438 - val_accuracy: 0.9206\n",
      "Epoch 31/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1731 - accuracy: 0.9592\n",
      "Epoch 31: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1724 - accuracy: 0.9589 - val_loss: 0.2334 - val_accuracy: 0.9273\n",
      "Epoch 32/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1710 - accuracy: 0.9586\n",
      "Epoch 32: val_accuracy improved from 0.93065 to 0.93289, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9597 - val_loss: 0.2264 - val_accuracy: 0.9329\n",
      "Epoch 33/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1717 - accuracy: 0.9557\n",
      "Epoch 33: val_accuracy did not improve from 0.93289\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1717 - accuracy: 0.9564 - val_loss: 0.2525 - val_accuracy: 0.9172\n",
      "Epoch 34/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 0.9611\n",
      "Epoch 34: val_accuracy did not improve from 0.93289\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1614 - accuracy: 0.9611 - val_loss: 0.2382 - val_accuracy: 0.9295\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9650\n",
      "Epoch 35: val_accuracy improved from 0.93289 to 0.93512, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1607 - accuracy: 0.9650 - val_loss: 0.2229 - val_accuracy: 0.9351\n",
      "Epoch 36/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1639 - accuracy: 0.9589\n",
      "Epoch 36: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1639 - accuracy: 0.9600 - val_loss: 0.2176 - val_accuracy: 0.9351\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9667\n",
      "Epoch 37: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1557 - accuracy: 0.9667 - val_loss: 0.2435 - val_accuracy: 0.9027\n",
      "Epoch 38/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1557 - accuracy: 0.9645\n",
      "Epoch 38: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1557 - accuracy: 0.9650 - val_loss: 0.2144 - val_accuracy: 0.9351\n",
      "Epoch 39/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1529 - accuracy: 0.9645\n",
      "Epoch 39: val_accuracy improved from 0.93512 to 0.93624, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1525 - accuracy: 0.9639 - val_loss: 0.2114 - val_accuracy: 0.9362\n",
      "Epoch 40/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1512 - accuracy: 0.9657\n",
      "Epoch 40: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1506 - accuracy: 0.9667 - val_loss: 0.2141 - val_accuracy: 0.9295\n",
      "Epoch 41/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1463 - accuracy: 0.9669\n",
      "Epoch 41: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1463 - accuracy: 0.9667 - val_loss: 0.2111 - val_accuracy: 0.9329\n",
      "Epoch 42/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1422 - accuracy: 0.9687\n",
      "Epoch 42: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1445 - accuracy: 0.9670 - val_loss: 0.2251 - val_accuracy: 0.9206\n",
      "Epoch 43/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.9642\n",
      "Epoch 43: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1454 - accuracy: 0.9645 - val_loss: 0.2230 - val_accuracy: 0.9262\n",
      "Epoch 44/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1432 - accuracy: 0.9654\n",
      "Epoch 44: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1438 - accuracy: 0.9650 - val_loss: 0.2211 - val_accuracy: 0.9161\n",
      "Epoch 45/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1436 - accuracy: 0.9663\n",
      "Epoch 45: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1428 - accuracy: 0.9673 - val_loss: 0.2069 - val_accuracy: 0.9329\n",
      "Epoch 46/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1418 - accuracy: 0.9657\n",
      "Epoch 46: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1418 - accuracy: 0.9664 - val_loss: 0.2118 - val_accuracy: 0.9295\n",
      "Epoch 47/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9692\n",
      "Epoch 47: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1364 - accuracy: 0.9690 - val_loss: 0.2003 - val_accuracy: 0.9351\n",
      "Epoch 48/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1412 - accuracy: 0.9648\n",
      "Epoch 48: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1400 - accuracy: 0.9650 - val_loss: 0.2009 - val_accuracy: 0.9351\n",
      "Epoch 49/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1400 - accuracy: 0.9639\n",
      "Epoch 49: val_accuracy did not improve from 0.93624\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1402 - accuracy: 0.9639 - val_loss: 0.1971 - val_accuracy: 0.9362\n",
      "Epoch 50/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1315 - accuracy: 0.9710\n",
      "Epoch 50: val_accuracy improved from 0.93624 to 0.93736, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1320 - accuracy: 0.9701 - val_loss: 0.1971 - val_accuracy: 0.9374\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 50, 'optimizer': 'sgd'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6698 - accuracy: 0.5940\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67785, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6659 - accuracy: 0.5996 - val_loss: 0.6183 - val_accuracy: 0.6779\n",
      "Epoch 2/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5793 - accuracy: 0.7234\n",
      "Epoch 2: val_accuracy improved from 0.67785 to 0.70694, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5786 - accuracy: 0.7218 - val_loss: 0.5808 - val_accuracy: 0.7069\n",
      "Epoch 3/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5248 - accuracy: 0.7822\n",
      "Epoch 3: val_accuracy improved from 0.70694 to 0.78635, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5227 - accuracy: 0.7852 - val_loss: 0.5213 - val_accuracy: 0.7864\n",
      "Epoch 4/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4825 - accuracy: 0.8216\n",
      "Epoch 4: val_accuracy improved from 0.78635 to 0.82438, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4817 - accuracy: 0.8221 - val_loss: 0.4916 - val_accuracy: 0.8244\n",
      "Epoch 5/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4529 - accuracy: 0.8484\n",
      "Epoch 5: val_accuracy improved from 0.82438 to 0.85235, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4509 - accuracy: 0.8518 - val_loss: 0.4742 - val_accuracy: 0.8523\n",
      "Epoch 6/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4275 - accuracy: 0.8679\n",
      "Epoch 6: val_accuracy improved from 0.85235 to 0.85570, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4278 - accuracy: 0.8686 - val_loss: 0.4494 - val_accuracy: 0.8557\n",
      "Epoch 7/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4046 - accuracy: 0.8904\n",
      "Epoch 7: val_accuracy improved from 0.85570 to 0.88702, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4062 - accuracy: 0.8901 - val_loss: 0.4312 - val_accuracy: 0.8870\n",
      "Epoch 8/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3839 - accuracy: 0.9010\n",
      "Epoch 8: val_accuracy did not improve from 0.88702\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3830 - accuracy: 0.9010 - val_loss: 0.4165 - val_accuracy: 0.8859\n",
      "Epoch 9/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3715 - accuracy: 0.9004\n",
      "Epoch 9: val_accuracy improved from 0.88702 to 0.88926, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3687 - accuracy: 0.9027 - val_loss: 0.4032 - val_accuracy: 0.8893\n",
      "Epoch 10/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3573 - accuracy: 0.9111\n",
      "Epoch 10: val_accuracy did not improve from 0.88926\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3551 - accuracy: 0.9130 - val_loss: 0.4007 - val_accuracy: 0.8669\n",
      "Epoch 11/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3444 - accuracy: 0.9184\n",
      "Epoch 11: val_accuracy improved from 0.88926 to 0.90157, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3442 - accuracy: 0.9183 - val_loss: 0.3827 - val_accuracy: 0.9016\n",
      "Epoch 12/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3340 - accuracy: 0.9202\n",
      "Epoch 12: val_accuracy did not improve from 0.90157\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3333 - accuracy: 0.9206 - val_loss: 0.3813 - val_accuracy: 0.8770\n",
      "Epoch 13/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3276 - accuracy: 0.9249\n",
      "Epoch 13: val_accuracy improved from 0.90157 to 0.91163, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3260 - accuracy: 0.9253 - val_loss: 0.3665 - val_accuracy: 0.9116\n",
      "Epoch 14/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3163 - accuracy: 0.9238\n",
      "Epoch 14: val_accuracy did not improve from 0.91163\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3154 - accuracy: 0.9251 - val_loss: 0.3618 - val_accuracy: 0.9083\n",
      "Epoch 15/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3069 - accuracy: 0.9309\n",
      "Epoch 15: val_accuracy improved from 0.91163 to 0.91499, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3086 - accuracy: 0.9298 - val_loss: 0.3523 - val_accuracy: 0.9150\n",
      "Epoch 16/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3005 - accuracy: 0.9350\n",
      "Epoch 16: val_accuracy did not improve from 0.91499\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3019 - accuracy: 0.9337 - val_loss: 0.3521 - val_accuracy: 0.8926\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.9404\n",
      "Epoch 17: val_accuracy did not improve from 0.91499\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2940 - accuracy: 0.9404 - val_loss: 0.3464 - val_accuracy: 0.9128\n",
      "Epoch 18/50\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.2884 - accuracy: 0.9325\n",
      "Epoch 18: val_accuracy did not improve from 0.91499\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2884 - accuracy: 0.9329 - val_loss: 0.3367 - val_accuracy: 0.9139\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.9346\n",
      "Epoch 19: val_accuracy improved from 0.91499 to 0.91611, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2839 - accuracy: 0.9346 - val_loss: 0.3315 - val_accuracy: 0.9161\n",
      "Epoch 20/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2793 - accuracy: 0.9323\n",
      "Epoch 20: val_accuracy did not improve from 0.91611\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2788 - accuracy: 0.9334 - val_loss: 0.3270 - val_accuracy: 0.9161\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2753 - accuracy: 0.9382\n",
      "Epoch 21: val_accuracy did not improve from 0.91611\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2753 - accuracy: 0.9382 - val_loss: 0.3229 - val_accuracy: 0.9150\n",
      "Epoch 22/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2674 - accuracy: 0.9444\n",
      "Epoch 22: val_accuracy improved from 0.91611 to 0.91723, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2689 - accuracy: 0.9421 - val_loss: 0.3196 - val_accuracy: 0.9172\n",
      "Epoch 23/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2644 - accuracy: 0.9371\n",
      "Epoch 23: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2639 - accuracy: 0.9376 - val_loss: 0.3190 - val_accuracy: 0.9161\n",
      "Epoch 24/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2603 - accuracy: 0.9382\n",
      "Epoch 24: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2620 - accuracy: 0.9362 - val_loss: 0.3117 - val_accuracy: 0.9150\n",
      "Epoch 25/50\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.2573 - accuracy: 0.9411\n",
      "Epoch 25: val_accuracy did not improve from 0.91723\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2577 - accuracy: 0.9413 - val_loss: 0.3174 - val_accuracy: 0.9060\n",
      "Epoch 26/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2533 - accuracy: 0.9486\n",
      "Epoch 26: val_accuracy improved from 0.91723 to 0.91946, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2531 - accuracy: 0.9474 - val_loss: 0.3052 - val_accuracy: 0.9195\n",
      "Epoch 27/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2486 - accuracy: 0.9453\n",
      "Epoch 27: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2486 - accuracy: 0.9463 - val_loss: 0.3022 - val_accuracy: 0.9172\n",
      "Epoch 28/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2445 - accuracy: 0.9427\n",
      "Epoch 28: val_accuracy improved from 0.91946 to 0.92058, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2456 - accuracy: 0.9418 - val_loss: 0.2995 - val_accuracy: 0.9206\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.9483\n",
      "Epoch 29: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2443 - accuracy: 0.9483 - val_loss: 0.2984 - val_accuracy: 0.9206\n",
      "Epoch 30/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2387 - accuracy: 0.9453\n",
      "Epoch 30: val_accuracy improved from 0.92058 to 0.92282, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2407 - accuracy: 0.9446 - val_loss: 0.2964 - val_accuracy: 0.9228\n",
      "Epoch 31/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2371 - accuracy: 0.9453\n",
      "Epoch 31: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2373 - accuracy: 0.9449 - val_loss: 0.2992 - val_accuracy: 0.9161\n",
      "Epoch 32/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2331 - accuracy: 0.9518\n",
      "Epoch 32: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2360 - accuracy: 0.9502 - val_loss: 0.2900 - val_accuracy: 0.9172\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9471\n",
      "Epoch 33: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2323 - accuracy: 0.9471 - val_loss: 0.2883 - val_accuracy: 0.9206\n",
      "Epoch 34/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2296 - accuracy: 0.9518\n",
      "Epoch 34: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2298 - accuracy: 0.9522 - val_loss: 0.2855 - val_accuracy: 0.9228\n",
      "Epoch 35/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2249 - accuracy: 0.9512\n",
      "Epoch 35: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2275 - accuracy: 0.9511 - val_loss: 0.2858 - val_accuracy: 0.9206\n",
      "Epoch 36/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2258 - accuracy: 0.9512\n",
      "Epoch 36: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2255 - accuracy: 0.9516 - val_loss: 0.2817 - val_accuracy: 0.9183\n",
      "Epoch 37/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2239 - accuracy: 0.9507\n",
      "Epoch 37: val_accuracy improved from 0.92282 to 0.92394, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2229 - accuracy: 0.9508 - val_loss: 0.2795 - val_accuracy: 0.9239\n",
      "Epoch 38/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2218 - accuracy: 0.9501\n",
      "Epoch 38: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2206 - accuracy: 0.9505 - val_loss: 0.2877 - val_accuracy: 0.9172\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9519\n",
      "Epoch 39: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2178 - accuracy: 0.9519 - val_loss: 0.2756 - val_accuracy: 0.9217\n",
      "Epoch 40/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2177 - accuracy: 0.9507\n",
      "Epoch 40: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2171 - accuracy: 0.9505 - val_loss: 0.2761 - val_accuracy: 0.9217\n",
      "Epoch 41/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2148 - accuracy: 0.9551\n",
      "Epoch 41: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2154 - accuracy: 0.9544 - val_loss: 0.2756 - val_accuracy: 0.9228\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9522\n",
      "Epoch 42: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2141 - accuracy: 0.9522 - val_loss: 0.2732 - val_accuracy: 0.9239\n",
      "Epoch 43/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2125 - accuracy: 0.9509\n",
      "Epoch 43: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2121 - accuracy: 0.9511 - val_loss: 0.2692 - val_accuracy: 0.9206\n",
      "Epoch 44/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2080 - accuracy: 0.9557\n",
      "Epoch 44: val_accuracy improved from 0.92394 to 0.92506, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2088 - accuracy: 0.9544 - val_loss: 0.2700 - val_accuracy: 0.9251\n",
      "Epoch 45/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2080 - accuracy: 0.9551\n",
      "Epoch 45: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2086 - accuracy: 0.9553 - val_loss: 0.2665 - val_accuracy: 0.9217\n",
      "Epoch 46/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2045 - accuracy: 0.9564\n",
      "Epoch 46: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2059 - accuracy: 0.9547 - val_loss: 0.2714 - val_accuracy: 0.9150\n",
      "Epoch 47/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2056 - accuracy: 0.9548\n",
      "Epoch 47: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2053 - accuracy: 0.9553 - val_loss: 0.2632 - val_accuracy: 0.9217\n",
      "Epoch 48/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2017 - accuracy: 0.9560\n",
      "Epoch 48: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2032 - accuracy: 0.9553 - val_loss: 0.2650 - val_accuracy: 0.9239\n",
      "Epoch 49/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2002 - accuracy: 0.9557\n",
      "Epoch 49: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2028 - accuracy: 0.9553 - val_loss: 0.2630 - val_accuracy: 0.9251\n",
      "Epoch 50/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1998 - accuracy: 0.9574\n",
      "Epoch 50: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1998 - accuracy: 0.9569 - val_loss: 0.2751 - val_accuracy: 0.9150\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 50, 'optimizer': 'rmsprop'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6755 - accuracy: 0.6126\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69575, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 11ms/step - loss: 0.6718 - accuracy: 0.6186 - val_loss: 0.6057 - val_accuracy: 0.6957\n",
      "Epoch 2/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5850 - accuracy: 0.6980\n",
      "Epoch 2: val_accuracy improved from 0.69575 to 0.75168, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5810 - accuracy: 0.7039 - val_loss: 0.5420 - val_accuracy: 0.7517\n",
      "Epoch 3/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5346 - accuracy: 0.7497\n",
      "Epoch 3: val_accuracy improved from 0.75168 to 0.81320, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5332 - accuracy: 0.7514 - val_loss: 0.4970 - val_accuracy: 0.8132\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.4822 - accuracy: 0.7987\n",
      "Epoch 4: val_accuracy improved from 0.81320 to 0.83445, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4822 - accuracy: 0.7987 - val_loss: 0.4653 - val_accuracy: 0.8345\n",
      "Epoch 5/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4557 - accuracy: 0.8144\n",
      "Epoch 5: val_accuracy improved from 0.83445 to 0.86018, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4514 - accuracy: 0.8180 - val_loss: 0.4458 - val_accuracy: 0.8602\n",
      "Epoch 6/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4242 - accuracy: 0.8454\n",
      "Epoch 6: val_accuracy did not improve from 0.86018\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4246 - accuracy: 0.8451 - val_loss: 0.5714 - val_accuracy: 0.6678\n",
      "Epoch 7/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4040 - accuracy: 0.8490\n",
      "Epoch 7: val_accuracy improved from 0.86018 to 0.86130, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4015 - accuracy: 0.8512 - val_loss: 0.4063 - val_accuracy: 0.8613\n",
      "Epoch 8/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3651 - accuracy: 0.8780\n",
      "Epoch 8: val_accuracy did not improve from 0.86130\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3669 - accuracy: 0.8761 - val_loss: 0.5339 - val_accuracy: 0.7002\n",
      "Epoch 9/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.8852\n",
      "Epoch 9: val_accuracy improved from 0.86130 to 0.89485, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3525 - accuracy: 0.8853 - val_loss: 0.3740 - val_accuracy: 0.8949\n",
      "Epoch 10/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3380 - accuracy: 0.8877\n",
      "Epoch 10: val_accuracy improved from 0.89485 to 0.90157, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3384 - accuracy: 0.8887 - val_loss: 0.3505 - val_accuracy: 0.9016\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.8946\n",
      "Epoch 11: val_accuracy did not improve from 0.90157\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3231 - accuracy: 0.8946 - val_loss: 0.4459 - val_accuracy: 0.7864\n",
      "Epoch 12/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3112 - accuracy: 0.9060\n",
      "Epoch 12: val_accuracy did not improve from 0.90157\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3139 - accuracy: 0.9032 - val_loss: 0.3596 - val_accuracy: 0.8837\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2966 - accuracy: 0.9088\n",
      "Epoch 13: val_accuracy improved from 0.90157 to 0.91275, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2966 - accuracy: 0.9088 - val_loss: 0.3229 - val_accuracy: 0.9128\n",
      "Epoch 14/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2882 - accuracy: 0.9128\n",
      "Epoch 14: val_accuracy did not improve from 0.91275\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2899 - accuracy: 0.9111 - val_loss: 0.3183 - val_accuracy: 0.9072\n",
      "Epoch 15/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2794 - accuracy: 0.9173\n",
      "Epoch 15: val_accuracy did not improve from 0.91275\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2793 - accuracy: 0.9167 - val_loss: 0.3391 - val_accuracy: 0.8870\n",
      "Epoch 16/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2734 - accuracy: 0.9190\n",
      "Epoch 16: val_accuracy did not improve from 0.91275\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2736 - accuracy: 0.9181 - val_loss: 0.3076 - val_accuracy: 0.9128\n",
      "Epoch 17/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2641 - accuracy: 0.9184\n",
      "Epoch 17: val_accuracy improved from 0.91275 to 0.91946, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2616 - accuracy: 0.9197 - val_loss: 0.2992 - val_accuracy: 0.9195\n",
      "Epoch 18/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2572 - accuracy: 0.9226\n",
      "Epoch 18: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2603 - accuracy: 0.9200 - val_loss: 0.2872 - val_accuracy: 0.9183\n",
      "Epoch 19/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2457 - accuracy: 0.9300\n",
      "Epoch 19: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2466 - accuracy: 0.9293 - val_loss: 0.2844 - val_accuracy: 0.9183\n",
      "Epoch 20/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2404 - accuracy: 0.9285\n",
      "Epoch 20: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2432 - accuracy: 0.9270 - val_loss: 0.2784 - val_accuracy: 0.9195\n",
      "Epoch 21/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2344 - accuracy: 0.9329\n",
      "Epoch 21: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2326 - accuracy: 0.9337 - val_loss: 0.4054 - val_accuracy: 0.8233\n",
      "Epoch 22/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2374 - accuracy: 0.9309\n",
      "Epoch 22: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2351 - accuracy: 0.9320 - val_loss: 0.3975 - val_accuracy: 0.8054\n",
      "Epoch 23/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2247 - accuracy: 0.9350\n",
      "Epoch 23: val_accuracy did not improve from 0.91946\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2260 - accuracy: 0.9334 - val_loss: 0.2816 - val_accuracy: 0.9161\n",
      "Epoch 24/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2249 - accuracy: 0.9320\n",
      "Epoch 24: val_accuracy improved from 0.91946 to 0.92506, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2231 - accuracy: 0.9337 - val_loss: 0.2614 - val_accuracy: 0.9251\n",
      "Epoch 25/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2188 - accuracy: 0.9332\n",
      "Epoch 25: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2172 - accuracy: 0.9340 - val_loss: 0.2935 - val_accuracy: 0.8971\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9404\n",
      "Epoch 26: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.2115 - accuracy: 0.9404 - val_loss: 0.3040 - val_accuracy: 0.8714\n",
      "Epoch 27/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2113 - accuracy: 0.9343\n",
      "Epoch 27: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2110 - accuracy: 0.9346 - val_loss: 0.2516 - val_accuracy: 0.9239\n",
      "Epoch 28/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1999 - accuracy: 0.9447\n",
      "Epoch 28: val_accuracy did not improve from 0.92506\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2026 - accuracy: 0.9441 - val_loss: 0.2710 - val_accuracy: 0.9172\n",
      "Epoch 29/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1952 - accuracy: 0.9477\n",
      "Epoch 29: val_accuracy improved from 0.92506 to 0.92841, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1999 - accuracy: 0.9438 - val_loss: 0.2464 - val_accuracy: 0.9284\n",
      "Epoch 30/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1994 - accuracy: 0.9376\n",
      "Epoch 30: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1999 - accuracy: 0.9385 - val_loss: 0.2554 - val_accuracy: 0.9072\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1943 - accuracy: 0.9402\n",
      "Epoch 31: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1943 - accuracy: 0.9402 - val_loss: 0.2410 - val_accuracy: 0.9284\n",
      "Epoch 32/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1967 - accuracy: 0.9444\n",
      "Epoch 32: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1938 - accuracy: 0.9449 - val_loss: 0.2433 - val_accuracy: 0.9273\n",
      "Epoch 33/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1858 - accuracy: 0.9517\n",
      "Epoch 33: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1873 - accuracy: 0.9502 - val_loss: 0.2542 - val_accuracy: 0.9183\n",
      "Epoch 34/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1836 - accuracy: 0.9512\n",
      "Epoch 34: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1847 - accuracy: 0.9502 - val_loss: 0.2355 - val_accuracy: 0.9284\n",
      "Epoch 35/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1808 - accuracy: 0.9512\n",
      "Epoch 35: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1799 - accuracy: 0.9525 - val_loss: 0.2417 - val_accuracy: 0.9150\n",
      "Epoch 36/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1831 - accuracy: 0.9483\n",
      "Epoch 36: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1835 - accuracy: 0.9488 - val_loss: 0.2379 - val_accuracy: 0.9150\n",
      "Epoch 37/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1848 - accuracy: 0.9459\n",
      "Epoch 37: val_accuracy improved from 0.92841 to 0.92953, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1842 - accuracy: 0.9457 - val_loss: 0.2277 - val_accuracy: 0.9295\n",
      "Epoch 38/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1771 - accuracy: 0.9499\n",
      "Epoch 38: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1746 - accuracy: 0.9508 - val_loss: 0.2324 - val_accuracy: 0.9228\n",
      "Epoch 39/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1754 - accuracy: 0.9459\n",
      "Epoch 39: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1741 - accuracy: 0.9471 - val_loss: 0.2287 - val_accuracy: 0.9239\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9516\n",
      "Epoch 40: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1744 - accuracy: 0.9516 - val_loss: 0.2341 - val_accuracy: 0.9262\n",
      "Epoch 41/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1652 - accuracy: 0.9574\n",
      "Epoch 41: val_accuracy improved from 0.92953 to 0.93400, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1680 - accuracy: 0.9553 - val_loss: 0.2179 - val_accuracy: 0.9340\n",
      "Epoch 42/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1687 - accuracy: 0.9530\n",
      "Epoch 42: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1673 - accuracy: 0.9539 - val_loss: 0.2308 - val_accuracy: 0.9217\n",
      "Epoch 43/50\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.1640 - accuracy: 0.9555\n",
      "Epoch 43: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1638 - accuracy: 0.9553 - val_loss: 0.2433 - val_accuracy: 0.9150\n",
      "Epoch 44/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1620 - accuracy: 0.9536\n",
      "Epoch 44: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1620 - accuracy: 0.9541 - val_loss: 0.2187 - val_accuracy: 0.9273\n",
      "Epoch 45/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1622 - accuracy: 0.9536\n",
      "Epoch 45: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1611 - accuracy: 0.9544 - val_loss: 0.2138 - val_accuracy: 0.9306\n",
      "Epoch 46/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1568 - accuracy: 0.9545\n",
      "Epoch 46: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1578 - accuracy: 0.9536 - val_loss: 0.2196 - val_accuracy: 0.9217\n",
      "Epoch 47/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1601 - accuracy: 0.9523\n",
      "Epoch 47: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.1597 - accuracy: 0.9525 - val_loss: 0.2113 - val_accuracy: 0.9295\n",
      "Epoch 48/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1526 - accuracy: 0.9577\n",
      "Epoch 48: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1550 - accuracy: 0.9572 - val_loss: 0.2131 - val_accuracy: 0.9284\n",
      "Epoch 49/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1514 - accuracy: 0.9598\n",
      "Epoch 49: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1523 - accuracy: 0.9592 - val_loss: 0.2155 - val_accuracy: 0.9262\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.9575\n",
      "Epoch 50: val_accuracy improved from 0.93400 to 0.93624, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1575 - accuracy: 0.9575 - val_loss: 0.2049 - val_accuracy: 0.9362\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 50, 'optimizer': 'adagrad'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6713 - accuracy: 0.6005\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60850, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 0.6715 - accuracy: 0.5998 - val_loss: 0.6615 - val_accuracy: 0.6085\n",
      "Epoch 2/50\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.6479 - accuracy: 0.6480\n",
      "Epoch 2: val_accuracy improved from 0.60850 to 0.63311, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6479 - accuracy: 0.6493 - val_loss: 0.6500 - val_accuracy: 0.6331\n",
      "Epoch 3/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6325 - accuracy: 0.6640\n",
      "Epoch 3: val_accuracy improved from 0.63311 to 0.63982, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6336 - accuracy: 0.6636 - val_loss: 0.6391 - val_accuracy: 0.6398\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.6857\n",
      "Epoch 4: val_accuracy improved from 0.63982 to 0.64765, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6233 - accuracy: 0.6857 - val_loss: 0.6320 - val_accuracy: 0.6477\n",
      "Epoch 5/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6169 - accuracy: 0.6941\n",
      "Epoch 5: val_accuracy improved from 0.64765 to 0.65884, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6155 - accuracy: 0.6955 - val_loss: 0.6259 - val_accuracy: 0.6588\n",
      "Epoch 6/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6068 - accuracy: 0.7083\n",
      "Epoch 6: val_accuracy improved from 0.65884 to 0.67114, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6081 - accuracy: 0.7081 - val_loss: 0.6219 - val_accuracy: 0.6711\n",
      "Epoch 7/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6017 - accuracy: 0.7125\n",
      "Epoch 7: val_accuracy improved from 0.67114 to 0.68233, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6022 - accuracy: 0.7125 - val_loss: 0.6176 - val_accuracy: 0.6823\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5965 - accuracy: 0.7243\n",
      "Epoch 8: val_accuracy improved from 0.68233 to 0.68345, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5965 - accuracy: 0.7243 - val_loss: 0.6117 - val_accuracy: 0.6834\n",
      "Epoch 9/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5917 - accuracy: 0.7272\n",
      "Epoch 9: val_accuracy improved from 0.68345 to 0.69016, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5915 - accuracy: 0.7290 - val_loss: 0.6080 - val_accuracy: 0.6902\n",
      "Epoch 10/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5868 - accuracy: 0.7367\n",
      "Epoch 10: val_accuracy improved from 0.69016 to 0.70694, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5871 - accuracy: 0.7366 - val_loss: 0.6051 - val_accuracy: 0.7069\n",
      "Epoch 11/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5829 - accuracy: 0.7470\n",
      "Epoch 11: val_accuracy did not improve from 0.70694\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5822 - accuracy: 0.7480 - val_loss: 0.6021 - val_accuracy: 0.6957\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5788 - accuracy: 0.7503\n",
      "Epoch 12: val_accuracy improved from 0.70694 to 0.71141, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5788 - accuracy: 0.7503 - val_loss: 0.5980 - val_accuracy: 0.7114\n",
      "Epoch 13/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5755 - accuracy: 0.7547\n",
      "Epoch 13: val_accuracy improved from 0.71141 to 0.71365, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5754 - accuracy: 0.7556 - val_loss: 0.5951 - val_accuracy: 0.7136\n",
      "Epoch 14/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5701 - accuracy: 0.7583\n",
      "Epoch 14: val_accuracy improved from 0.71365 to 0.72148, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5717 - accuracy: 0.7573 - val_loss: 0.5925 - val_accuracy: 0.7215\n",
      "Epoch 15/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5690 - accuracy: 0.7568\n",
      "Epoch 15: val_accuracy improved from 0.72148 to 0.72371, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5689 - accuracy: 0.7570 - val_loss: 0.5896 - val_accuracy: 0.7237\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.7603\n",
      "Epoch 16: val_accuracy improved from 0.72371 to 0.72931, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5656 - accuracy: 0.7603 - val_loss: 0.5876 - val_accuracy: 0.7293\n",
      "Epoch 17/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5645 - accuracy: 0.7671\n",
      "Epoch 17: val_accuracy improved from 0.72931 to 0.73490, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5630 - accuracy: 0.7685 - val_loss: 0.5847 - val_accuracy: 0.7349\n",
      "Epoch 18/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5623 - accuracy: 0.7704\n",
      "Epoch 18: val_accuracy improved from 0.73490 to 0.73937, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5602 - accuracy: 0.7738 - val_loss: 0.5827 - val_accuracy: 0.7394\n",
      "Epoch 19/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5570 - accuracy: 0.7742\n",
      "Epoch 19: val_accuracy improved from 0.73937 to 0.74273, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5573 - accuracy: 0.7732 - val_loss: 0.5802 - val_accuracy: 0.7427\n",
      "Epoch 20/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5548 - accuracy: 0.7742\n",
      "Epoch 20: val_accuracy improved from 0.74273 to 0.74385, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5547 - accuracy: 0.7746 - val_loss: 0.5782 - val_accuracy: 0.7438\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.7833\n",
      "Epoch 21: val_accuracy improved from 0.74385 to 0.74944, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5525 - accuracy: 0.7833 - val_loss: 0.5761 - val_accuracy: 0.7494\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.7822\n",
      "Epoch 22: val_accuracy did not improve from 0.74944\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5500 - accuracy: 0.7822 - val_loss: 0.5744 - val_accuracy: 0.7438\n",
      "Epoch 23/50\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.7867\n",
      "Epoch 23: val_accuracy improved from 0.74944 to 0.75280, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5477 - accuracy: 0.7880 - val_loss: 0.5722 - val_accuracy: 0.7528\n",
      "Epoch 24/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5471 - accuracy: 0.7866\n",
      "Epoch 24: val_accuracy improved from 0.75280 to 0.75951, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5457 - accuracy: 0.7894 - val_loss: 0.5703 - val_accuracy: 0.7595\n",
      "Epoch 25/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5421 - accuracy: 0.7920\n",
      "Epoch 25: val_accuracy did not improve from 0.75951\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5434 - accuracy: 0.7905 - val_loss: 0.5692 - val_accuracy: 0.7550\n",
      "Epoch 26/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5393 - accuracy: 0.7952\n",
      "Epoch 26: val_accuracy did not improve from 0.75951\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5411 - accuracy: 0.7925 - val_loss: 0.5672 - val_accuracy: 0.7573\n",
      "Epoch 27/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5399 - accuracy: 0.7946\n",
      "Epoch 27: val_accuracy improved from 0.75951 to 0.76063, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5395 - accuracy: 0.7942 - val_loss: 0.5651 - val_accuracy: 0.7606\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.7953\n",
      "Epoch 28: val_accuracy improved from 0.76063 to 0.77181, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5372 - accuracy: 0.7953 - val_loss: 0.5634 - val_accuracy: 0.7718\n",
      "Epoch 29/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5361 - accuracy: 0.7992\n",
      "Epoch 29: val_accuracy did not improve from 0.77181\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5352 - accuracy: 0.8009 - val_loss: 0.5632 - val_accuracy: 0.7562\n",
      "Epoch 30/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5337 - accuracy: 0.7973\n",
      "Epoch 30: val_accuracy did not improve from 0.77181\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5333 - accuracy: 0.7987 - val_loss: 0.5617 - val_accuracy: 0.7640\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.8009\n",
      "Epoch 31: val_accuracy did not improve from 0.77181\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5316 - accuracy: 0.8009 - val_loss: 0.5591 - val_accuracy: 0.7651\n",
      "Epoch 32/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5294 - accuracy: 0.8032\n",
      "Epoch 32: val_accuracy improved from 0.77181 to 0.77629, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5301 - accuracy: 0.8026 - val_loss: 0.5573 - val_accuracy: 0.7763\n",
      "Epoch 33/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5294 - accuracy: 0.8053\n",
      "Epoch 33: val_accuracy improved from 0.77629 to 0.77852, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5285 - accuracy: 0.8070 - val_loss: 0.5559 - val_accuracy: 0.7785\n",
      "Epoch 34/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5257 - accuracy: 0.8094\n",
      "Epoch 34: val_accuracy did not improve from 0.77852\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5266 - accuracy: 0.8068 - val_loss: 0.5548 - val_accuracy: 0.7740\n",
      "Epoch 35/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5244 - accuracy: 0.8061\n",
      "Epoch 35: val_accuracy did not improve from 0.77852\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5247 - accuracy: 0.8051 - val_loss: 0.5537 - val_accuracy: 0.7740\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5235 - accuracy: 0.8121\n",
      "Epoch 36: val_accuracy did not improve from 0.77852\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5235 - accuracy: 0.8121 - val_loss: 0.5520 - val_accuracy: 0.7785\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.8138\n",
      "Epoch 37: val_accuracy did not improve from 0.77852\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5219 - accuracy: 0.8138 - val_loss: 0.5506 - val_accuracy: 0.7785\n",
      "Epoch 38/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5197 - accuracy: 0.8129\n",
      "Epoch 38: val_accuracy improved from 0.77852 to 0.78635, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5204 - accuracy: 0.8098 - val_loss: 0.5490 - val_accuracy: 0.7864\n",
      "Epoch 39/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5177 - accuracy: 0.8146\n",
      "Epoch 39: val_accuracy improved from 0.78635 to 0.79083, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5188 - accuracy: 0.8135 - val_loss: 0.5478 - val_accuracy: 0.7908\n",
      "Epoch 40/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5177 - accuracy: 0.8162\n",
      "Epoch 40: val_accuracy did not improve from 0.79083\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5176 - accuracy: 0.8146 - val_loss: 0.5464 - val_accuracy: 0.7875\n",
      "Epoch 41/50\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.5147 - accuracy: 0.8175\n",
      "Epoch 41: val_accuracy improved from 0.79083 to 0.79418, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5161 - accuracy: 0.8171 - val_loss: 0.5452 - val_accuracy: 0.7942\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.8207\n",
      "Epoch 42: val_accuracy did not improve from 0.79418\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5146 - accuracy: 0.8207 - val_loss: 0.5441 - val_accuracy: 0.7931\n",
      "Epoch 43/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5130 - accuracy: 0.8191\n",
      "Epoch 43: val_accuracy did not improve from 0.79418\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5132 - accuracy: 0.8199 - val_loss: 0.5429 - val_accuracy: 0.7919\n",
      "Epoch 44/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5110 - accuracy: 0.8212\n",
      "Epoch 44: val_accuracy improved from 0.79418 to 0.80089, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5118 - accuracy: 0.8191 - val_loss: 0.5417 - val_accuracy: 0.8009\n",
      "Epoch 45/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5107 - accuracy: 0.8194\n",
      "Epoch 45: val_accuracy did not improve from 0.80089\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5104 - accuracy: 0.8210 - val_loss: 0.5410 - val_accuracy: 0.7897\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5092 - accuracy: 0.8233\n",
      "Epoch 46: val_accuracy did not improve from 0.80089\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5092 - accuracy: 0.8233 - val_loss: 0.5394 - val_accuracy: 0.7953\n",
      "Epoch 47/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5075 - accuracy: 0.8248\n",
      "Epoch 47: val_accuracy improved from 0.80089 to 0.80313, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5080 - accuracy: 0.8233 - val_loss: 0.5383 - val_accuracy: 0.8031\n",
      "Epoch 48/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5058 - accuracy: 0.8280\n",
      "Epoch 48: val_accuracy did not improve from 0.80313\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5068 - accuracy: 0.8269 - val_loss: 0.5373 - val_accuracy: 0.7953\n",
      "Epoch 49/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5060 - accuracy: 0.8245\n",
      "Epoch 49: val_accuracy did not improve from 0.80313\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5055 - accuracy: 0.8238 - val_loss: 0.5362 - val_accuracy: 0.7987\n",
      "Epoch 50/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5045 - accuracy: 0.8262\n",
      "Epoch 50: val_accuracy did not improve from 0.80313\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5042 - accuracy: 0.8252 - val_loss: 0.5351 - val_accuracy: 0.8020\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 50, 'optimizer': 'adadelta'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.8011 - accuracy: 0.5011\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50783, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 0.8012 - accuracy: 0.5020 - val_loss: 0.7715 - val_accuracy: 0.5078\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.7640 - accuracy: 0.5028\n",
      "Epoch 2: val_accuracy improved from 0.50783 to 0.50895, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7640 - accuracy: 0.5028 - val_loss: 0.7398 - val_accuracy: 0.5089\n",
      "Epoch 3/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.7346 - accuracy: 0.5045\n",
      "Epoch 3: val_accuracy improved from 0.50895 to 0.51678, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7347 - accuracy: 0.5045 - val_loss: 0.7153 - val_accuracy: 0.5168\n",
      "Epoch 4/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.7112 - accuracy: 0.5089\n",
      "Epoch 4: val_accuracy improved from 0.51678 to 0.52685, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.7125 - accuracy: 0.5059 - val_loss: 0.6975 - val_accuracy: 0.5268\n",
      "Epoch 5/50\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.6971 - accuracy: 0.5203\n",
      "Epoch 5: val_accuracy improved from 0.52685 to 0.53691, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6970 - accuracy: 0.5218 - val_loss: 0.6857 - val_accuracy: 0.5369\n",
      "Epoch 6/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6869 - accuracy: 0.5467\n",
      "Epoch 6: val_accuracy improved from 0.53691 to 0.56376, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6867 - accuracy: 0.5473 - val_loss: 0.6779 - val_accuracy: 0.5638\n",
      "Epoch 7/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6803 - accuracy: 0.5668\n",
      "Epoch 7: val_accuracy improved from 0.56376 to 0.56935, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6797 - accuracy: 0.5685 - val_loss: 0.6729 - val_accuracy: 0.5694\n",
      "Epoch 8/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6747 - accuracy: 0.5848\n",
      "Epoch 8: val_accuracy improved from 0.56935 to 0.57830, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6754 - accuracy: 0.5847 - val_loss: 0.6701 - val_accuracy: 0.5783\n",
      "Epoch 9/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6727 - accuracy: 0.5907\n",
      "Epoch 9: val_accuracy improved from 0.57830 to 0.58501, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6730 - accuracy: 0.5906 - val_loss: 0.6687 - val_accuracy: 0.5850\n",
      "Epoch 10/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6709 - accuracy: 0.5966\n",
      "Epoch 10: val_accuracy improved from 0.58501 to 0.58725, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6716 - accuracy: 0.5951 - val_loss: 0.6678 - val_accuracy: 0.5872\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.5959\n",
      "Epoch 11: val_accuracy improved from 0.58725 to 0.59172, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.6707 - accuracy: 0.5959 - val_loss: 0.6672 - val_accuracy: 0.5917\n",
      "Epoch 12/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6697 - accuracy: 0.5966\n",
      "Epoch 12: val_accuracy did not improve from 0.59172\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6701 - accuracy: 0.5954 - val_loss: 0.6668 - val_accuracy: 0.5895\n",
      "Epoch 13/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6698 - accuracy: 0.6002\n",
      "Epoch 13: val_accuracy did not improve from 0.59172\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6696 - accuracy: 0.5998 - val_loss: 0.6665 - val_accuracy: 0.5906\n",
      "Epoch 14/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6685 - accuracy: 0.6055\n",
      "Epoch 14: val_accuracy improved from 0.59172 to 0.59284, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6692 - accuracy: 0.6032 - val_loss: 0.6662 - val_accuracy: 0.5928\n",
      "Epoch 15/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6693 - accuracy: 0.6017\n",
      "Epoch 15: val_accuracy improved from 0.59284 to 0.59843, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6688 - accuracy: 0.6023 - val_loss: 0.6660 - val_accuracy: 0.5984\n",
      "Epoch 16/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6685 - accuracy: 0.6017\n",
      "Epoch 16: val_accuracy improved from 0.59843 to 0.60067, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.6684 - accuracy: 0.6023 - val_loss: 0.6657 - val_accuracy: 0.6007\n",
      "Epoch 17/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6689 - accuracy: 0.6037\n",
      "Epoch 17: val_accuracy did not improve from 0.60067\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6680 - accuracy: 0.6029 - val_loss: 0.6654 - val_accuracy: 0.5996\n",
      "Epoch 18/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6669 - accuracy: 0.6064\n",
      "Epoch 18: val_accuracy did not improve from 0.60067\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6677 - accuracy: 0.6046 - val_loss: 0.6651 - val_accuracy: 0.6007\n",
      "Epoch 19/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6663 - accuracy: 0.6093\n",
      "Epoch 19: val_accuracy did not improve from 0.60067\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6673 - accuracy: 0.6051 - val_loss: 0.6649 - val_accuracy: 0.6007\n",
      "Epoch 20/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6682 - accuracy: 0.6031\n",
      "Epoch 20: val_accuracy improved from 0.60067 to 0.60291, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6670 - accuracy: 0.6065 - val_loss: 0.6646 - val_accuracy: 0.6029\n",
      "Epoch 21/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6662 - accuracy: 0.6067\n",
      "Epoch 21: val_accuracy improved from 0.60291 to 0.60515, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6667 - accuracy: 0.6079 - val_loss: 0.6643 - val_accuracy: 0.6051\n",
      "Epoch 22/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6671 - accuracy: 0.6058\n",
      "Epoch 22: val_accuracy did not improve from 0.60515\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6663 - accuracy: 0.6077 - val_loss: 0.6640 - val_accuracy: 0.6040\n",
      "Epoch 23/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6664 - accuracy: 0.6087\n",
      "Epoch 23: val_accuracy did not improve from 0.60515\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6660 - accuracy: 0.6096 - val_loss: 0.6638 - val_accuracy: 0.6040\n",
      "Epoch 24/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6652 - accuracy: 0.6126\n",
      "Epoch 24: val_accuracy did not improve from 0.60515\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6656 - accuracy: 0.6105 - val_loss: 0.6635 - val_accuracy: 0.6051\n",
      "Epoch 25/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6654 - accuracy: 0.6141\n",
      "Epoch 25: val_accuracy did not improve from 0.60515\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6653 - accuracy: 0.6127 - val_loss: 0.6633 - val_accuracy: 0.6051\n",
      "Epoch 26/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6643 - accuracy: 0.6114\n",
      "Epoch 26: val_accuracy improved from 0.60515 to 0.60850, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6650 - accuracy: 0.6116 - val_loss: 0.6630 - val_accuracy: 0.6085\n",
      "Epoch 27/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6656 - accuracy: 0.6108\n",
      "Epoch 27: val_accuracy improved from 0.60850 to 0.61074, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6646 - accuracy: 0.6135 - val_loss: 0.6627 - val_accuracy: 0.6107\n",
      "Epoch 28/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6632 - accuracy: 0.6155\n",
      "Epoch 28: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6643 - accuracy: 0.6147 - val_loss: 0.6625 - val_accuracy: 0.6107\n",
      "Epoch 29/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6633 - accuracy: 0.6167\n",
      "Epoch 29: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6640 - accuracy: 0.6152 - val_loss: 0.6622 - val_accuracy: 0.6096\n",
      "Epoch 30/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6629 - accuracy: 0.6188\n",
      "Epoch 30: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6636 - accuracy: 0.6166 - val_loss: 0.6620 - val_accuracy: 0.6096\n",
      "Epoch 31/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6635 - accuracy: 0.6194\n",
      "Epoch 31: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6633 - accuracy: 0.6191 - val_loss: 0.6617 - val_accuracy: 0.6096\n",
      "Epoch 32/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6628 - accuracy: 0.6188\n",
      "Epoch 32: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6630 - accuracy: 0.6197 - val_loss: 0.6615 - val_accuracy: 0.6107\n",
      "Epoch 33/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6626 - accuracy: 0.6202\n",
      "Epoch 33: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6627 - accuracy: 0.6205 - val_loss: 0.6612 - val_accuracy: 0.6085\n",
      "Epoch 34/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6629 - accuracy: 0.6200\n",
      "Epoch 34: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6623 - accuracy: 0.6211 - val_loss: 0.6610 - val_accuracy: 0.6096\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.6211\n",
      "Epoch 35: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6620 - accuracy: 0.6211 - val_loss: 0.6607 - val_accuracy: 0.6085\n",
      "Epoch 36/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6607 - accuracy: 0.6277\n",
      "Epoch 36: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6617 - accuracy: 0.6239 - val_loss: 0.6605 - val_accuracy: 0.6085\n",
      "Epoch 37/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6619 - accuracy: 0.6194\n",
      "Epoch 37: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6614 - accuracy: 0.6225 - val_loss: 0.6602 - val_accuracy: 0.6096\n",
      "Epoch 38/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6605 - accuracy: 0.6262\n",
      "Epoch 38: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6610 - accuracy: 0.6239 - val_loss: 0.6599 - val_accuracy: 0.6096\n",
      "Epoch 39/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6604 - accuracy: 0.6226\n",
      "Epoch 39: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6607 - accuracy: 0.6239 - val_loss: 0.6597 - val_accuracy: 0.6096\n",
      "Epoch 40/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6618 - accuracy: 0.6238\n",
      "Epoch 40: val_accuracy did not improve from 0.61074\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6604 - accuracy: 0.6250 - val_loss: 0.6594 - val_accuracy: 0.6107\n",
      "Epoch 41/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6605 - accuracy: 0.6215\n",
      "Epoch 41: val_accuracy improved from 0.61074 to 0.61186, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6601 - accuracy: 0.6242 - val_loss: 0.6592 - val_accuracy: 0.6119\n",
      "Epoch 42/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6584 - accuracy: 0.6288\n",
      "Epoch 42: val_accuracy did not improve from 0.61186\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6598 - accuracy: 0.6264 - val_loss: 0.6590 - val_accuracy: 0.6085\n",
      "Epoch 43/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.6593 - accuracy: 0.6270\n",
      "Epoch 43: val_accuracy did not improve from 0.61186\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6595 - accuracy: 0.6272 - val_loss: 0.6587 - val_accuracy: 0.6096\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6592 - accuracy: 0.6264\n",
      "Epoch 44: val_accuracy did not improve from 0.61186\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6592 - accuracy: 0.6264 - val_loss: 0.6585 - val_accuracy: 0.6119\n",
      "Epoch 45/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6585 - accuracy: 0.6256\n",
      "Epoch 45: val_accuracy did not improve from 0.61186\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6589 - accuracy: 0.6264 - val_loss: 0.6582 - val_accuracy: 0.6119\n",
      "Epoch 46/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6597 - accuracy: 0.6250\n",
      "Epoch 46: val_accuracy did not improve from 0.61186\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6585 - accuracy: 0.6289 - val_loss: 0.6580 - val_accuracy: 0.6119\n",
      "Epoch 47/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6583 - accuracy: 0.6306\n",
      "Epoch 47: val_accuracy did not improve from 0.61186\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6582 - accuracy: 0.6309 - val_loss: 0.6578 - val_accuracy: 0.6096\n",
      "Epoch 48/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6587 - accuracy: 0.6285\n",
      "Epoch 48: val_accuracy did not improve from 0.61186\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6579 - accuracy: 0.6300 - val_loss: 0.6575 - val_accuracy: 0.6107\n",
      "Epoch 49/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6570 - accuracy: 0.6291\n",
      "Epoch 49: val_accuracy did not improve from 0.61186\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6576 - accuracy: 0.6300 - val_loss: 0.6573 - val_accuracy: 0.6107\n",
      "Epoch 50/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6574 - accuracy: 0.6327\n",
      "Epoch 50: val_accuracy did not improve from 0.61186\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6573 - accuracy: 0.6334 - val_loss: 0.6570 - val_accuracy: 0.6107\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 50, 'optimizer': 'adamax'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6501 - accuracy: 0.6188\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66219, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 0.6464 - accuracy: 0.6222 - val_loss: 0.6197 - val_accuracy: 0.6622\n",
      "Epoch 2/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.5924 - accuracy: 0.6970\n",
      "Epoch 2: val_accuracy improved from 0.66219 to 0.66779, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5923 - accuracy: 0.6971 - val_loss: 0.6074 - val_accuracy: 0.6678\n",
      "Epoch 3/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5521 - accuracy: 0.7615\n",
      "Epoch 3: val_accuracy improved from 0.66779 to 0.73826, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5518 - accuracy: 0.7612 - val_loss: 0.5633 - val_accuracy: 0.7383\n",
      "Epoch 4/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5259 - accuracy: 0.7837\n",
      "Epoch 4: val_accuracy improved from 0.73826 to 0.79866, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5237 - accuracy: 0.7864 - val_loss: 0.5350 - val_accuracy: 0.7987\n",
      "Epoch 5/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4960 - accuracy: 0.8274\n",
      "Epoch 5: val_accuracy did not improve from 0.79866\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4938 - accuracy: 0.8283 - val_loss: 0.5116 - val_accuracy: 0.7942\n",
      "Epoch 6/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4689 - accuracy: 0.8443\n",
      "Epoch 6: val_accuracy improved from 0.79866 to 0.81991, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4676 - accuracy: 0.8465 - val_loss: 0.4890 - val_accuracy: 0.8199\n",
      "Epoch 7/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.4457 - accuracy: 0.8657\n",
      "Epoch 7: val_accuracy improved from 0.81991 to 0.84452, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4454 - accuracy: 0.8658 - val_loss: 0.4693 - val_accuracy: 0.8445\n",
      "Epoch 8/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4271 - accuracy: 0.8732\n",
      "Epoch 8: val_accuracy did not improve from 0.84452\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4269 - accuracy: 0.8725 - val_loss: 0.4558 - val_accuracy: 0.8423\n",
      "Epoch 9/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4148 - accuracy: 0.8735\n",
      "Epoch 9: val_accuracy improved from 0.84452 to 0.86242, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4152 - accuracy: 0.8730 - val_loss: 0.4404 - val_accuracy: 0.8624\n",
      "Epoch 10/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4015 - accuracy: 0.8815\n",
      "Epoch 10: val_accuracy improved from 0.86242 to 0.87919, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4008 - accuracy: 0.8826 - val_loss: 0.4288 - val_accuracy: 0.8792\n",
      "Epoch 11/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3862 - accuracy: 0.8930\n",
      "Epoch 11: val_accuracy did not improve from 0.87919\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3857 - accuracy: 0.8926 - val_loss: 0.4318 - val_accuracy: 0.8244\n",
      "Epoch 12/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3648 - accuracy: 0.9037\n",
      "Epoch 12: val_accuracy improved from 0.87919 to 0.89933, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3651 - accuracy: 0.9046 - val_loss: 0.4034 - val_accuracy: 0.8993\n",
      "Epoch 13/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3528 - accuracy: 0.9131\n",
      "Epoch 13: val_accuracy did not improve from 0.89933\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3537 - accuracy: 0.9125 - val_loss: 0.3922 - val_accuracy: 0.8926\n",
      "Epoch 14/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3422 - accuracy: 0.9196\n",
      "Epoch 14: val_accuracy did not improve from 0.89933\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3418 - accuracy: 0.9175 - val_loss: 0.3805 - val_accuracy: 0.8949\n",
      "Epoch 15/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3335 - accuracy: 0.9190\n",
      "Epoch 15: val_accuracy improved from 0.89933 to 0.90828, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3320 - accuracy: 0.9203 - val_loss: 0.3713 - val_accuracy: 0.9083\n",
      "Epoch 16/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3223 - accuracy: 0.9252\n",
      "Epoch 16: val_accuracy did not improve from 0.90828\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3222 - accuracy: 0.9253 - val_loss: 0.3645 - val_accuracy: 0.9027\n",
      "Epoch 17/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3134 - accuracy: 0.9300\n",
      "Epoch 17: val_accuracy did not improve from 0.90828\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3141 - accuracy: 0.9290 - val_loss: 0.3611 - val_accuracy: 0.8915\n",
      "Epoch 18/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3060 - accuracy: 0.9263\n",
      "Epoch 18: val_accuracy did not improve from 0.90828\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3067 - accuracy: 0.9267 - val_loss: 0.3602 - val_accuracy: 0.8837\n",
      "Epoch 19/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2992 - accuracy: 0.9284\n",
      "Epoch 19: val_accuracy did not improve from 0.90828\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2993 - accuracy: 0.9293 - val_loss: 0.3509 - val_accuracy: 0.8915\n",
      "Epoch 20/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2929 - accuracy: 0.9359\n",
      "Epoch 20: val_accuracy improved from 0.90828 to 0.91387, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2925 - accuracy: 0.9351 - val_loss: 0.3396 - val_accuracy: 0.9139\n",
      "Epoch 21/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2832 - accuracy: 0.9359\n",
      "Epoch 21: val_accuracy improved from 0.91387 to 0.91611, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2836 - accuracy: 0.9360 - val_loss: 0.3337 - val_accuracy: 0.9161\n",
      "Epoch 22/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2779 - accuracy: 0.9371\n",
      "Epoch 22: val_accuracy improved from 0.91611 to 0.92058, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2774 - accuracy: 0.9379 - val_loss: 0.3298 - val_accuracy: 0.9206\n",
      "Epoch 23/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2733 - accuracy: 0.9379\n",
      "Epoch 23: val_accuracy did not improve from 0.92058\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2735 - accuracy: 0.9376 - val_loss: 0.3230 - val_accuracy: 0.9206\n",
      "Epoch 24/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2699 - accuracy: 0.9368\n",
      "Epoch 24: val_accuracy improved from 0.92058 to 0.92617, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2692 - accuracy: 0.9374 - val_loss: 0.3183 - val_accuracy: 0.9262\n",
      "Epoch 25/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2616 - accuracy: 0.9427\n",
      "Epoch 25: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2623 - accuracy: 0.9430 - val_loss: 0.3204 - val_accuracy: 0.9150\n",
      "Epoch 26/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2582 - accuracy: 0.9430\n",
      "Epoch 26: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2576 - accuracy: 0.9438 - val_loss: 0.3154 - val_accuracy: 0.9161\n",
      "Epoch 27/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2536 - accuracy: 0.9421\n",
      "Epoch 27: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2538 - accuracy: 0.9416 - val_loss: 0.3055 - val_accuracy: 0.9161\n",
      "Epoch 28/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2488 - accuracy: 0.9468\n",
      "Epoch 28: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2485 - accuracy: 0.9469 - val_loss: 0.3030 - val_accuracy: 0.9262\n",
      "Epoch 29/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2450 - accuracy: 0.9477\n",
      "Epoch 29: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2446 - accuracy: 0.9477 - val_loss: 0.2980 - val_accuracy: 0.9195\n",
      "Epoch 30/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2416 - accuracy: 0.9439\n",
      "Epoch 30: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2402 - accuracy: 0.9457 - val_loss: 0.2975 - val_accuracy: 0.9239\n",
      "Epoch 31/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2376 - accuracy: 0.9489\n",
      "Epoch 31: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2372 - accuracy: 0.9488 - val_loss: 0.2945 - val_accuracy: 0.9150\n",
      "Epoch 32/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2356 - accuracy: 0.9444\n",
      "Epoch 32: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2341 - accuracy: 0.9452 - val_loss: 0.2906 - val_accuracy: 0.9228\n",
      "Epoch 33/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2321 - accuracy: 0.9433\n",
      "Epoch 33: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2313 - accuracy: 0.9432 - val_loss: 0.2868 - val_accuracy: 0.9172\n",
      "Epoch 34/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2247 - accuracy: 0.9489\n",
      "Epoch 34: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2265 - accuracy: 0.9485 - val_loss: 0.2906 - val_accuracy: 0.9172\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.9522\n",
      "Epoch 35: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2227 - accuracy: 0.9522 - val_loss: 0.2803 - val_accuracy: 0.9172\n",
      "Epoch 36/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2207 - accuracy: 0.9515\n",
      "Epoch 36: val_accuracy improved from 0.92617 to 0.92953, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2203 - accuracy: 0.9519 - val_loss: 0.2761 - val_accuracy: 0.9295\n",
      "Epoch 37/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2168 - accuracy: 0.9515\n",
      "Epoch 37: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2165 - accuracy: 0.9516 - val_loss: 0.2760 - val_accuracy: 0.9183\n",
      "Epoch 38/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2161 - accuracy: 0.9536\n",
      "Epoch 38: val_accuracy did not improve from 0.92953\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2139 - accuracy: 0.9544 - val_loss: 0.2708 - val_accuracy: 0.9251\n",
      "Epoch 39/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2101 - accuracy: 0.9536\n",
      "Epoch 39: val_accuracy improved from 0.92953 to 0.93065, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2098 - accuracy: 0.9533 - val_loss: 0.2676 - val_accuracy: 0.9306\n",
      "Epoch 40/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2083 - accuracy: 0.9507\n",
      "Epoch 40: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2096 - accuracy: 0.9491 - val_loss: 0.2646 - val_accuracy: 0.9306\n",
      "Epoch 41/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2065 - accuracy: 0.9572\n",
      "Epoch 41: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2044 - accuracy: 0.9578 - val_loss: 0.2624 - val_accuracy: 0.9273\n",
      "Epoch 42/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2015 - accuracy: 0.9548\n",
      "Epoch 42: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2018 - accuracy: 0.9553 - val_loss: 0.2600 - val_accuracy: 0.9273\n",
      "Epoch 43/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1991 - accuracy: 0.9551\n",
      "Epoch 43: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1997 - accuracy: 0.9564 - val_loss: 0.2648 - val_accuracy: 0.9150\n",
      "Epoch 44/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1970 - accuracy: 0.9589\n",
      "Epoch 44: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1968 - accuracy: 0.9592 - val_loss: 0.2626 - val_accuracy: 0.9172\n",
      "Epoch 45/50\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.1958 - accuracy: 0.9570\n",
      "Epoch 45: val_accuracy did not improve from 0.93065\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1966 - accuracy: 0.9572 - val_loss: 0.2549 - val_accuracy: 0.9295\n",
      "Epoch 46/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1942 - accuracy: 0.9548\n",
      "Epoch 46: val_accuracy improved from 0.93065 to 0.93177, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1949 - accuracy: 0.9553 - val_loss: 0.2543 - val_accuracy: 0.9318\n",
      "Epoch 47/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1921 - accuracy: 0.9577\n",
      "Epoch 47: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1928 - accuracy: 0.9575 - val_loss: 0.2522 - val_accuracy: 0.9295\n",
      "Epoch 48/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1909 - accuracy: 0.9583\n",
      "Epoch 48: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1901 - accuracy: 0.9592 - val_loss: 0.2588 - val_accuracy: 0.9116\n",
      "Epoch 49/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1881 - accuracy: 0.9572\n",
      "Epoch 49: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1867 - accuracy: 0.9581 - val_loss: 0.2499 - val_accuracy: 0.9318\n",
      "Epoch 50/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1878 - accuracy: 0.9580\n",
      "Epoch 50: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1867 - accuracy: 0.9581 - val_loss: 0.2532 - val_accuracy: 0.9262\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 50, 'optimizer': 'ftrl'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.6675 - accuracy: 0.6187\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61521, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 0.6674 - accuracy: 0.6202 - val_loss: 0.6621 - val_accuracy: 0.6152\n",
      "Epoch 2/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6464 - accuracy: 0.6599\n",
      "Epoch 2: val_accuracy improved from 0.61521 to 0.64206, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6448 - accuracy: 0.6630 - val_loss: 0.6459 - val_accuracy: 0.6421\n",
      "Epoch 3/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6307 - accuracy: 0.6876\n",
      "Epoch 3: val_accuracy improved from 0.64206 to 0.64318, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6313 - accuracy: 0.6865 - val_loss: 0.6384 - val_accuracy: 0.6432\n",
      "Epoch 4/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6224 - accuracy: 0.7027\n",
      "Epoch 4: val_accuracy improved from 0.64318 to 0.67114, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6217 - accuracy: 0.7039 - val_loss: 0.6306 - val_accuracy: 0.6711\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6134 - accuracy: 0.7027\n",
      "Epoch 5: val_accuracy improved from 0.67114 to 0.67562, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6134 - accuracy: 0.7027 - val_loss: 0.6248 - val_accuracy: 0.6756\n",
      "Epoch 6/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6072 - accuracy: 0.7083\n",
      "Epoch 6: val_accuracy did not improve from 0.67562\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6069 - accuracy: 0.7103 - val_loss: 0.6200 - val_accuracy: 0.6745\n",
      "Epoch 7/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6012 - accuracy: 0.7204\n",
      "Epoch 7: val_accuracy improved from 0.67562 to 0.68345, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.6010 - accuracy: 0.7201 - val_loss: 0.6154 - val_accuracy: 0.6834\n",
      "Epoch 8/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5965 - accuracy: 0.7272\n",
      "Epoch 8: val_accuracy improved from 0.68345 to 0.69016, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5960 - accuracy: 0.7276 - val_loss: 0.6115 - val_accuracy: 0.6902\n",
      "Epoch 9/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5918 - accuracy: 0.7311\n",
      "Epoch 9: val_accuracy improved from 0.69016 to 0.70246, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5908 - accuracy: 0.7307 - val_loss: 0.6081 - val_accuracy: 0.7025\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5870 - accuracy: 0.7313\n",
      "Epoch 10: val_accuracy improved from 0.70246 to 0.70358, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5870 - accuracy: 0.7313 - val_loss: 0.6043 - val_accuracy: 0.7036\n",
      "Epoch 11/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5826 - accuracy: 0.7388\n",
      "Epoch 11: val_accuracy improved from 0.70358 to 0.70805, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5825 - accuracy: 0.7383 - val_loss: 0.6014 - val_accuracy: 0.7081\n",
      "Epoch 12/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5775 - accuracy: 0.7482\n",
      "Epoch 12: val_accuracy improved from 0.70805 to 0.71253, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5791 - accuracy: 0.7475 - val_loss: 0.5985 - val_accuracy: 0.7125\n",
      "Epoch 13/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5760 - accuracy: 0.7423\n",
      "Epoch 13: val_accuracy improved from 0.71253 to 0.71700, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5749 - accuracy: 0.7444 - val_loss: 0.5961 - val_accuracy: 0.7170\n",
      "Epoch 14/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5706 - accuracy: 0.7509\n",
      "Epoch 14: val_accuracy improved from 0.71700 to 0.72036, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5719 - accuracy: 0.7486 - val_loss: 0.5927 - val_accuracy: 0.7204\n",
      "Epoch 15/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5688 - accuracy: 0.7592\n",
      "Epoch 15: val_accuracy improved from 0.72036 to 0.72595, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5682 - accuracy: 0.7584 - val_loss: 0.5902 - val_accuracy: 0.7260\n",
      "Epoch 16/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5664 - accuracy: 0.7583\n",
      "Epoch 16: val_accuracy improved from 0.72595 to 0.72707, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5661 - accuracy: 0.7606 - val_loss: 0.5875 - val_accuracy: 0.7271\n",
      "Epoch 17/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5626 - accuracy: 0.7654\n",
      "Epoch 17: val_accuracy improved from 0.72707 to 0.73043, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5628 - accuracy: 0.7659 - val_loss: 0.5856 - val_accuracy: 0.7304\n",
      "Epoch 18/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5609 - accuracy: 0.7645\n",
      "Epoch 18: val_accuracy improved from 0.73043 to 0.73490, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5601 - accuracy: 0.7659 - val_loss: 0.5833 - val_accuracy: 0.7349\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.7715\n",
      "Epoch 19: val_accuracy improved from 0.73490 to 0.74161, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5574 - accuracy: 0.7715 - val_loss: 0.5808 - val_accuracy: 0.7416\n",
      "Epoch 20/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5556 - accuracy: 0.7751\n",
      "Epoch 20: val_accuracy improved from 0.74161 to 0.74273, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5550 - accuracy: 0.7760 - val_loss: 0.5787 - val_accuracy: 0.7427\n",
      "Epoch 21/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5521 - accuracy: 0.7789\n",
      "Epoch 21: val_accuracy did not improve from 0.74273\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5525 - accuracy: 0.7785 - val_loss: 0.5769 - val_accuracy: 0.7394\n",
      "Epoch 22/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5504 - accuracy: 0.7798\n",
      "Epoch 22: val_accuracy improved from 0.74273 to 0.74608, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5496 - accuracy: 0.7813 - val_loss: 0.5748 - val_accuracy: 0.7461\n",
      "Epoch 23/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5486 - accuracy: 0.7816\n",
      "Epoch 23: val_accuracy improved from 0.74608 to 0.74832, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5479 - accuracy: 0.7816 - val_loss: 0.5734 - val_accuracy: 0.7483\n",
      "Epoch 24/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5460 - accuracy: 0.7866\n",
      "Epoch 24: val_accuracy did not improve from 0.74832\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5456 - accuracy: 0.7861 - val_loss: 0.5729 - val_accuracy: 0.7394\n",
      "Epoch 25/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5435 - accuracy: 0.7798\n",
      "Epoch 25: val_accuracy improved from 0.74832 to 0.75168, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5438 - accuracy: 0.7816 - val_loss: 0.5694 - val_accuracy: 0.7517\n",
      "Epoch 26/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5421 - accuracy: 0.7866\n",
      "Epoch 26: val_accuracy improved from 0.75168 to 0.75503, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5415 - accuracy: 0.7891 - val_loss: 0.5676 - val_accuracy: 0.7550\n",
      "Epoch 27/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5395 - accuracy: 0.7937\n",
      "Epoch 27: val_accuracy did not improve from 0.75503\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5395 - accuracy: 0.7925 - val_loss: 0.5661 - val_accuracy: 0.7550\n",
      "Epoch 28/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5372 - accuracy: 0.7890\n",
      "Epoch 28: val_accuracy improved from 0.75503 to 0.75615, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5377 - accuracy: 0.7883 - val_loss: 0.5644 - val_accuracy: 0.7562\n",
      "Epoch 29/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5359 - accuracy: 0.7961\n",
      "Epoch 29: val_accuracy improved from 0.75615 to 0.76174, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5359 - accuracy: 0.7945 - val_loss: 0.5627 - val_accuracy: 0.7617\n",
      "Epoch 30/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5342 - accuracy: 0.7993\n",
      "Epoch 30: val_accuracy did not improve from 0.76174\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5340 - accuracy: 0.7981 - val_loss: 0.5613 - val_accuracy: 0.7606\n",
      "Epoch 31/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5324 - accuracy: 0.7976\n",
      "Epoch 31: val_accuracy improved from 0.76174 to 0.76510, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5323 - accuracy: 0.7992 - val_loss: 0.5597 - val_accuracy: 0.7651\n",
      "Epoch 32/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5291 - accuracy: 0.7991\n",
      "Epoch 32: val_accuracy improved from 0.76510 to 0.76622, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5305 - accuracy: 0.7981 - val_loss: 0.5587 - val_accuracy: 0.7662\n",
      "Epoch 33/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5289 - accuracy: 0.8029\n",
      "Epoch 33: val_accuracy did not improve from 0.76622\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5289 - accuracy: 0.8031 - val_loss: 0.5571 - val_accuracy: 0.7617\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.8037\n",
      "Epoch 34: val_accuracy improved from 0.76622 to 0.76957, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5273 - accuracy: 0.8037 - val_loss: 0.5554 - val_accuracy: 0.7696\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.5255 - accuracy: 0.8040\n",
      "Epoch 35: val_accuracy did not improve from 0.76957\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5255 - accuracy: 0.8040 - val_loss: 0.5540 - val_accuracy: 0.7685\n",
      "Epoch 36/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5237 - accuracy: 0.8051\n",
      "Epoch 36: val_accuracy improved from 0.76957 to 0.77181, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5241 - accuracy: 0.8054 - val_loss: 0.5527 - val_accuracy: 0.7718\n",
      "Epoch 37/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5217 - accuracy: 0.8079\n",
      "Epoch 37: val_accuracy improved from 0.77181 to 0.77517, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5225 - accuracy: 0.8076 - val_loss: 0.5515 - val_accuracy: 0.7752\n",
      "Epoch 38/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5200 - accuracy: 0.8088\n",
      "Epoch 38: val_accuracy did not improve from 0.77517\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5211 - accuracy: 0.8076 - val_loss: 0.5501 - val_accuracy: 0.7740\n",
      "Epoch 39/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5181 - accuracy: 0.8103\n",
      "Epoch 39: val_accuracy did not improve from 0.77517\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5195 - accuracy: 0.8096 - val_loss: 0.5491 - val_accuracy: 0.7740\n",
      "Epoch 40/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5179 - accuracy: 0.8124\n",
      "Epoch 40: val_accuracy did not improve from 0.77517\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5183 - accuracy: 0.8118 - val_loss: 0.5476 - val_accuracy: 0.7729\n",
      "Epoch 41/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5170 - accuracy: 0.8126\n",
      "Epoch 41: val_accuracy improved from 0.77517 to 0.77964, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5167 - accuracy: 0.8129 - val_loss: 0.5466 - val_accuracy: 0.7796\n",
      "Epoch 42/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5174 - accuracy: 0.8100\n",
      "Epoch 42: val_accuracy did not improve from 0.77964\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5154 - accuracy: 0.8121 - val_loss: 0.5452 - val_accuracy: 0.7774\n",
      "Epoch 43/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5134 - accuracy: 0.8138\n",
      "Epoch 43: val_accuracy did not improve from 0.77964\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5138 - accuracy: 0.8143 - val_loss: 0.5440 - val_accuracy: 0.7785\n",
      "Epoch 44/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5121 - accuracy: 0.8150\n",
      "Epoch 44: val_accuracy did not improve from 0.77964\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5127 - accuracy: 0.8154 - val_loss: 0.5428 - val_accuracy: 0.7796\n",
      "Epoch 45/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5103 - accuracy: 0.8212\n",
      "Epoch 45: val_accuracy improved from 0.77964 to 0.78076, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5112 - accuracy: 0.8194 - val_loss: 0.5426 - val_accuracy: 0.7808\n",
      "Epoch 46/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5096 - accuracy: 0.8257\n",
      "Epoch 46: val_accuracy improved from 0.78076 to 0.78412, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5098 - accuracy: 0.8235 - val_loss: 0.5407 - val_accuracy: 0.7841\n",
      "Epoch 47/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5094 - accuracy: 0.8245\n",
      "Epoch 47: val_accuracy did not improve from 0.78412\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5087 - accuracy: 0.8247 - val_loss: 0.5395 - val_accuracy: 0.7830\n",
      "Epoch 48/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5059 - accuracy: 0.8206\n",
      "Epoch 48: val_accuracy did not improve from 0.78412\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5075 - accuracy: 0.8191 - val_loss: 0.5385 - val_accuracy: 0.7841\n",
      "Epoch 49/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5063 - accuracy: 0.8200\n",
      "Epoch 49: val_accuracy improved from 0.78412 to 0.78523, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5059 - accuracy: 0.8219 - val_loss: 0.5386 - val_accuracy: 0.7852\n",
      "Epoch 50/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5072 - accuracy: 0.8218\n",
      "Epoch 50: val_accuracy improved from 0.78523 to 0.78747, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5052 - accuracy: 0.8244 - val_loss: 0.5365 - val_accuracy: 0.7875\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Start training with hyperparameters: {'epochs': 50, 'optimizer': 'nadam'}\n",
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6232 - accuracy: 0.6705\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71029, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 0.6206 - accuracy: 0.6745 - val_loss: 0.5875 - val_accuracy: 0.7103\n",
      "Epoch 2/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5181 - accuracy: 0.7908\n",
      "Epoch 2: val_accuracy improved from 0.71029 to 0.82215, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5148 - accuracy: 0.7936 - val_loss: 0.5027 - val_accuracy: 0.8221\n",
      "Epoch 3/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4473 - accuracy: 0.8620\n",
      "Epoch 3: val_accuracy improved from 0.82215 to 0.87025, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4485 - accuracy: 0.8619 - val_loss: 0.4590 - val_accuracy: 0.8702\n",
      "Epoch 4/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4044 - accuracy: 0.8865\n",
      "Epoch 4: val_accuracy did not improve from 0.87025\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4045 - accuracy: 0.8865 - val_loss: 0.4289 - val_accuracy: 0.8658\n",
      "Epoch 5/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3720 - accuracy: 0.9022\n",
      "Epoch 5: val_accuracy improved from 0.87025 to 0.88591, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3707 - accuracy: 0.9024 - val_loss: 0.4004 - val_accuracy: 0.8859\n",
      "Epoch 6/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3442 - accuracy: 0.9161\n",
      "Epoch 6: val_accuracy improved from 0.88591 to 0.90157, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3429 - accuracy: 0.9183 - val_loss: 0.3839 - val_accuracy: 0.9016\n",
      "Epoch 7/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3205 - accuracy: 0.9246\n",
      "Epoch 7: val_accuracy did not improve from 0.90157\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3214 - accuracy: 0.9234 - val_loss: 0.3593 - val_accuracy: 0.8971\n",
      "Epoch 8/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3052 - accuracy: 0.9294\n",
      "Epoch 8: val_accuracy improved from 0.90157 to 0.90828, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3032 - accuracy: 0.9298 - val_loss: 0.3513 - val_accuracy: 0.9083\n",
      "Epoch 9/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2872 - accuracy: 0.9314\n",
      "Epoch 9: val_accuracy improved from 0.90828 to 0.91163, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2883 - accuracy: 0.9293 - val_loss: 0.3363 - val_accuracy: 0.9116\n",
      "Epoch 10/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2745 - accuracy: 0.9371\n",
      "Epoch 10: val_accuracy improved from 0.91163 to 0.91499, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2740 - accuracy: 0.9374 - val_loss: 0.3195 - val_accuracy: 0.9150\n",
      "Epoch 11/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2660 - accuracy: 0.9365\n",
      "Epoch 11: val_accuracy improved from 0.91499 to 0.92282, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2644 - accuracy: 0.9374 - val_loss: 0.3121 - val_accuracy: 0.9228\n",
      "Epoch 12/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2536 - accuracy: 0.9421\n",
      "Epoch 12: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2516 - accuracy: 0.9435 - val_loss: 0.3024 - val_accuracy: 0.9172\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.9410\n",
      "Epoch 13: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2441 - accuracy: 0.9410 - val_loss: 0.2962 - val_accuracy: 0.9128\n",
      "Epoch 14/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2358 - accuracy: 0.9472\n",
      "Epoch 14: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2348 - accuracy: 0.9474 - val_loss: 0.2923 - val_accuracy: 0.9027\n",
      "Epoch 15/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2276 - accuracy: 0.9521\n",
      "Epoch 15: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2277 - accuracy: 0.9525 - val_loss: 0.2845 - val_accuracy: 0.9217\n",
      "Epoch 16/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2194 - accuracy: 0.9490\n",
      "Epoch 16: val_accuracy did not improve from 0.92282\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2200 - accuracy: 0.9491 - val_loss: 0.2795 - val_accuracy: 0.9105\n",
      "Epoch 17/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2184 - accuracy: 0.9501\n",
      "Epoch 17: val_accuracy improved from 0.92282 to 0.92394, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2172 - accuracy: 0.9508 - val_loss: 0.2693 - val_accuracy: 0.9239\n",
      "Epoch 18/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9520\n",
      "Epoch 18: val_accuracy improved from 0.92394 to 0.92617, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2083 - accuracy: 0.9516 - val_loss: 0.2632 - val_accuracy: 0.9262\n",
      "Epoch 19/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2024 - accuracy: 0.9542\n",
      "Epoch 19: val_accuracy did not improve from 0.92617\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2031 - accuracy: 0.9533 - val_loss: 0.2695 - val_accuracy: 0.9217\n",
      "Epoch 20/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1980 - accuracy: 0.9542\n",
      "Epoch 20: val_accuracy improved from 0.92617 to 0.92841, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1981 - accuracy: 0.9550 - val_loss: 0.2554 - val_accuracy: 0.9284\n",
      "Epoch 21/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1916 - accuracy: 0.9557\n",
      "Epoch 21: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1925 - accuracy: 0.9555 - val_loss: 0.2641 - val_accuracy: 0.9060\n",
      "Epoch 22/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 0.9565\n",
      "Epoch 22: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1901 - accuracy: 0.9561 - val_loss: 0.2512 - val_accuracy: 0.9228\n",
      "Epoch 23/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1851 - accuracy: 0.9572\n",
      "Epoch 23: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1856 - accuracy: 0.9575 - val_loss: 0.2425 - val_accuracy: 0.9273\n",
      "Epoch 24/50\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.1830 - accuracy: 0.9568\n",
      "Epoch 24: val_accuracy did not improve from 0.92841\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.1823 - accuracy: 0.9575 - val_loss: 0.2399 - val_accuracy: 0.9273\n",
      "Epoch 25/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1782 - accuracy: 0.9611\n",
      "Epoch 25: val_accuracy improved from 0.92841 to 0.93065, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.1780 - accuracy: 0.9609 - val_loss: 0.2367 - val_accuracy: 0.9306\n",
      "Epoch 26/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1745 - accuracy: 0.9591\n",
      "Epoch 26: val_accuracy improved from 0.93065 to 0.93289, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.1744 - accuracy: 0.9592 - val_loss: 0.2338 - val_accuracy: 0.9329\n",
      "Epoch 27/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1718 - accuracy: 0.9642\n",
      "Epoch 27: val_accuracy did not improve from 0.93289\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1715 - accuracy: 0.9642 - val_loss: 0.2473 - val_accuracy: 0.9060\n",
      "Epoch 28/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1658 - accuracy: 0.9622\n",
      "Epoch 28: val_accuracy did not improve from 0.93289\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1675 - accuracy: 0.9611 - val_loss: 0.2302 - val_accuracy: 0.9273\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9625\n",
      "Epoch 29: val_accuracy did not improve from 0.93289\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1656 - accuracy: 0.9625 - val_loss: 0.2249 - val_accuracy: 0.9318\n",
      "Epoch 30/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 0.9591\n",
      "Epoch 30: val_accuracy did not improve from 0.93289\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1627 - accuracy: 0.9586 - val_loss: 0.2225 - val_accuracy: 0.9329\n",
      "Epoch 31/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1598 - accuracy: 0.9628\n",
      "Epoch 31: val_accuracy improved from 0.93289 to 0.93400, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1586 - accuracy: 0.9634 - val_loss: 0.2203 - val_accuracy: 0.9340\n",
      "Epoch 32/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1549 - accuracy: 0.9645\n",
      "Epoch 32: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1579 - accuracy: 0.9634 - val_loss: 0.2173 - val_accuracy: 0.9340\n",
      "Epoch 33/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9667\n",
      "Epoch 33: val_accuracy did not improve from 0.93400\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1551 - accuracy: 0.9667 - val_loss: 0.2171 - val_accuracy: 0.9340\n",
      "Epoch 34/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1531 - accuracy: 0.9673\n",
      "Epoch 34: val_accuracy improved from 0.93400 to 0.93512, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1526 - accuracy: 0.9676 - val_loss: 0.2146 - val_accuracy: 0.9351\n",
      "Epoch 35/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1542 - accuracy: 0.9657\n",
      "Epoch 35: val_accuracy improved from 0.93512 to 0.93736, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1514 - accuracy: 0.9662 - val_loss: 0.2103 - val_accuracy: 0.9374\n",
      "Epoch 36/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1487 - accuracy: 0.9642\n",
      "Epoch 36: val_accuracy did not improve from 0.93736\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1490 - accuracy: 0.9645 - val_loss: 0.2105 - val_accuracy: 0.9374\n",
      "Epoch 37/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1438 - accuracy: 0.9707\n",
      "Epoch 37: val_accuracy did not improve from 0.93736\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1454 - accuracy: 0.9690 - val_loss: 0.2545 - val_accuracy: 0.8926\n",
      "Epoch 38/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 0.9695\n",
      "Epoch 38: val_accuracy did not improve from 0.93736\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1443 - accuracy: 0.9692 - val_loss: 0.2120 - val_accuracy: 0.9262\n",
      "Epoch 39/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1428 - accuracy: 0.9669\n",
      "Epoch 39: val_accuracy did not improve from 0.93736\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1418 - accuracy: 0.9670 - val_loss: 0.2081 - val_accuracy: 0.9351\n",
      "Epoch 40/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1390 - accuracy: 0.9704\n",
      "Epoch 40: val_accuracy improved from 0.93736 to 0.93960, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1403 - accuracy: 0.9695 - val_loss: 0.2026 - val_accuracy: 0.9396\n",
      "Epoch 41/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1378 - accuracy: 0.9696\n",
      "Epoch 41: val_accuracy did not improve from 0.93960\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1388 - accuracy: 0.9695 - val_loss: 0.2093 - val_accuracy: 0.9273\n",
      "Epoch 42/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1365 - accuracy: 0.9692\n",
      "Epoch 42: val_accuracy did not improve from 0.93960\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1361 - accuracy: 0.9695 - val_loss: 0.1982 - val_accuracy: 0.9396\n",
      "Epoch 43/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1348 - accuracy: 0.9687\n",
      "Epoch 43: val_accuracy improved from 0.93960 to 0.94072, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1365 - accuracy: 0.9681 - val_loss: 0.1970 - val_accuracy: 0.9407\n",
      "Epoch 44/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1339 - accuracy: 0.9704\n",
      "Epoch 44: val_accuracy did not improve from 0.94072\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1329 - accuracy: 0.9712 - val_loss: 0.1964 - val_accuracy: 0.9396\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.9737\n",
      "Epoch 45: val_accuracy did not improve from 0.94072\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1319 - accuracy: 0.9737 - val_loss: 0.1980 - val_accuracy: 0.9362\n",
      "Epoch 46/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9729\n",
      "Epoch 46: val_accuracy did not improve from 0.94072\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1308 - accuracy: 0.9732 - val_loss: 0.1932 - val_accuracy: 0.9374\n",
      "Epoch 47/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1289 - accuracy: 0.9722\n",
      "Epoch 47: val_accuracy did not improve from 0.94072\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1275 - accuracy: 0.9734 - val_loss: 0.2014 - val_accuracy: 0.9329\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9701\n",
      "Epoch 48: val_accuracy did not improve from 0.94072\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1280 - accuracy: 0.9701 - val_loss: 0.1910 - val_accuracy: 0.9407\n",
      "Epoch 49/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1274 - accuracy: 0.9710\n",
      "Epoch 49: val_accuracy improved from 0.94072 to 0.94183, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1275 - accuracy: 0.9715 - val_loss: 0.1889 - val_accuracy: 0.9418\n",
      "Epoch 50/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 0.9738\n",
      "Epoch 50: val_accuracy did not improve from 0.94183\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1253 - accuracy: 0.9734 - val_loss: 0.1945 - val_accuracy: 0.9295\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Best Hyperparameters: {'epochs': 50, 'optimizer': 'nadam'}\n",
      "Best Validation Accuracy: 0.9418344497680664\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Grid Search\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop', 'adagrad', 'adadelta', 'adamax', 'ftrl', 'nadam'],\n",
    "    'epochs': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print('Start training with hyperparameters: {}'.format(params))\n",
    "    \n",
    "    model = create_single_neuron_model(input_shape=(image_size[0], image_size[1], 3))  # 3 for RGB channels\n",
    "    train_generator, val_generator = load_and_preprocess_data(data_dir, image_size)\n",
    "    \n",
    "    history = train_model(model, train_generator, val_generator, optimizer=params['optimizer'], batch_size=batch_size, epochs=params['epochs'])\n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    \n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        best_hyperparams = params\n",
    "        \n",
    "    print()\n",
    "    print('------------------------------------------------------------')\n",
    "    print()\n",
    "\n",
    "print('Best Hyperparameters: {}'.format(best_hyperparams))\n",
    "print('Best Validation Accuracy: {}'.format(best_accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:21:52.188343Z",
     "start_time": "2024-03-08T19:58:15.214693Z"
    }
   },
   "id": "ac9627fd8d24aa9c",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.6370 - accuracy: 0.6395\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73826, saving model to best_model.keras\n",
      "112/112 [==============================] - 2s 12ms/step - loss: 0.6337 - accuracy: 0.6460 - val_loss: 0.5818 - val_accuracy: 0.7383\n",
      "Epoch 2/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.5325 - accuracy: 0.7852\n",
      "Epoch 2: val_accuracy improved from 0.73826 to 0.82550, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.5317 - accuracy: 0.7869 - val_loss: 0.5167 - val_accuracy: 0.8255\n",
      "Epoch 3/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4678 - accuracy: 0.8389\n",
      "Epoch 3: val_accuracy did not improve from 0.82550\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4677 - accuracy: 0.8389 - val_loss: 0.4736 - val_accuracy: 0.8210\n",
      "Epoch 4/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.4225 - accuracy: 0.8732\n",
      "Epoch 4: val_accuracy improved from 0.82550 to 0.86689, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.4228 - accuracy: 0.8711 - val_loss: 0.4364 - val_accuracy: 0.8669\n",
      "Epoch 5/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3873 - accuracy: 0.8948\n",
      "Epoch 5: val_accuracy did not improve from 0.86689\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3858 - accuracy: 0.8946 - val_loss: 0.4299 - val_accuracy: 0.8624\n",
      "Epoch 6/50\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.3598 - accuracy: 0.9021\n",
      "Epoch 6: val_accuracy improved from 0.86689 to 0.89709, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3595 - accuracy: 0.9027 - val_loss: 0.3876 - val_accuracy: 0.8971\n",
      "Epoch 7/50\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.3344 - accuracy: 0.9200\n",
      "Epoch 7: val_accuracy did not improve from 0.89709\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3346 - accuracy: 0.9197 - val_loss: 0.3716 - val_accuracy: 0.8937\n",
      "Epoch 8/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.3156 - accuracy: 0.9255\n",
      "Epoch 8: val_accuracy improved from 0.89709 to 0.90828, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.3149 - accuracy: 0.9276 - val_loss: 0.3570 - val_accuracy: 0.9083\n",
      "Epoch 9/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2980 - accuracy: 0.9335\n",
      "Epoch 9: val_accuracy improved from 0.90828 to 0.91387, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2992 - accuracy: 0.9318 - val_loss: 0.3418 - val_accuracy: 0.9139\n",
      "Epoch 10/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2860 - accuracy: 0.9344\n",
      "Epoch 10: val_accuracy improved from 0.91387 to 0.91611, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2848 - accuracy: 0.9351 - val_loss: 0.3284 - val_accuracy: 0.9161\n",
      "Epoch 11/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2734 - accuracy: 0.9344\n",
      "Epoch 11: val_accuracy improved from 0.91611 to 0.91834, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2718 - accuracy: 0.9354 - val_loss: 0.3204 - val_accuracy: 0.9183\n",
      "Epoch 12/50\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.2612 - accuracy: 0.9382\n",
      "Epoch 12: val_accuracy improved from 0.91834 to 0.92394, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2616 - accuracy: 0.9379 - val_loss: 0.3095 - val_accuracy: 0.9239\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2538 - accuracy: 0.9393\n",
      "Epoch 13: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2538 - accuracy: 0.9393 - val_loss: 0.3145 - val_accuracy: 0.9072\n",
      "Epoch 14/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2441 - accuracy: 0.9430\n",
      "Epoch 14: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2427 - accuracy: 0.9435 - val_loss: 0.2931 - val_accuracy: 0.9239\n",
      "Epoch 15/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2339 - accuracy: 0.9458\n",
      "Epoch 15: val_accuracy did not improve from 0.92394\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2344 - accuracy: 0.9446 - val_loss: 0.2888 - val_accuracy: 0.9195\n",
      "Epoch 16/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2281 - accuracy: 0.9477\n",
      "Epoch 16: val_accuracy improved from 0.92394 to 0.93177, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2275 - accuracy: 0.9480 - val_loss: 0.2812 - val_accuracy: 0.9318\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.9508\n",
      "Epoch 17: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2204 - accuracy: 0.9508 - val_loss: 0.2788 - val_accuracy: 0.9183\n",
      "Epoch 18/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2167 - accuracy: 0.9498\n",
      "Epoch 18: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2163 - accuracy: 0.9502 - val_loss: 0.2690 - val_accuracy: 0.9239\n",
      "Epoch 19/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2103 - accuracy: 0.9504\n",
      "Epoch 19: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2103 - accuracy: 0.9497 - val_loss: 0.2696 - val_accuracy: 0.9172\n",
      "Epoch 20/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.2044 - accuracy: 0.9539\n",
      "Epoch 20: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.2038 - accuracy: 0.9541 - val_loss: 0.2596 - val_accuracy: 0.9251\n",
      "Epoch 21/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1997 - accuracy: 0.9586\n",
      "Epoch 21: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1996 - accuracy: 0.9575 - val_loss: 0.2640 - val_accuracy: 0.9150\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9533\n",
      "Epoch 22: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1942 - accuracy: 0.9533 - val_loss: 0.2519 - val_accuracy: 0.9262\n",
      "Epoch 23/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1905 - accuracy: 0.9575\n",
      "Epoch 23: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1896 - accuracy: 0.9578 - val_loss: 0.2552 - val_accuracy: 0.9139\n",
      "Epoch 24/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1849 - accuracy: 0.9604\n",
      "Epoch 24: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1854 - accuracy: 0.9589 - val_loss: 0.2433 - val_accuracy: 0.9318\n",
      "Epoch 25/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1830 - accuracy: 0.9586\n",
      "Epoch 25: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1820 - accuracy: 0.9592 - val_loss: 0.2406 - val_accuracy: 0.9273\n",
      "Epoch 26/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1781 - accuracy: 0.9592\n",
      "Epoch 26: val_accuracy did not improve from 0.93177\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1783 - accuracy: 0.9600 - val_loss: 0.2438 - val_accuracy: 0.9239\n",
      "Epoch 27/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1784 - accuracy: 0.9566\n",
      "Epoch 27: val_accuracy improved from 0.93177 to 0.93289, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1764 - accuracy: 0.9581 - val_loss: 0.2327 - val_accuracy: 0.9329\n",
      "Epoch 28/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1723 - accuracy: 0.9580\n",
      "Epoch 28: val_accuracy did not improve from 0.93289\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1709 - accuracy: 0.9597 - val_loss: 0.2332 - val_accuracy: 0.9295\n",
      "Epoch 29/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1688 - accuracy: 0.9619\n",
      "Epoch 29: val_accuracy did not improve from 0.93289\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9609 - val_loss: 0.2287 - val_accuracy: 0.9306\n",
      "Epoch 30/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1651 - accuracy: 0.9626\n",
      "Epoch 30: val_accuracy improved from 0.93289 to 0.93512, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1663 - accuracy: 0.9603 - val_loss: 0.2255 - val_accuracy: 0.9351\n",
      "Epoch 31/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1645 - accuracy: 0.9601\n",
      "Epoch 31: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1635 - accuracy: 0.9609 - val_loss: 0.2252 - val_accuracy: 0.9273\n",
      "Epoch 32/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1635 - accuracy: 0.9631\n",
      "Epoch 32: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1619 - accuracy: 0.9642 - val_loss: 0.2243 - val_accuracy: 0.9295\n",
      "Epoch 33/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1594 - accuracy: 0.9628\n",
      "Epoch 33: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1582 - accuracy: 0.9639 - val_loss: 0.2358 - val_accuracy: 0.9139\n",
      "Epoch 34/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1530 - accuracy: 0.9660\n",
      "Epoch 34: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1549 - accuracy: 0.9653 - val_loss: 0.2240 - val_accuracy: 0.9262\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.9648\n",
      "Epoch 35: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1541 - accuracy: 0.9648 - val_loss: 0.2192 - val_accuracy: 0.9295\n",
      "Epoch 36/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1522 - accuracy: 0.9625\n",
      "Epoch 36: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1527 - accuracy: 0.9631 - val_loss: 0.2132 - val_accuracy: 0.9351\n",
      "Epoch 37/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1489 - accuracy: 0.9690\n",
      "Epoch 37: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1493 - accuracy: 0.9678 - val_loss: 0.2125 - val_accuracy: 0.9351\n",
      "Epoch 38/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1468 - accuracy: 0.9654\n",
      "Epoch 38: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1466 - accuracy: 0.9662 - val_loss: 0.2099 - val_accuracy: 0.9340\n",
      "Epoch 39/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1473 - accuracy: 0.9684\n",
      "Epoch 39: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1459 - accuracy: 0.9687 - val_loss: 0.2255 - val_accuracy: 0.9128\n",
      "Epoch 40/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1444 - accuracy: 0.9657\n",
      "Epoch 40: val_accuracy did not improve from 0.93512\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1446 - accuracy: 0.9662 - val_loss: 0.2096 - val_accuracy: 0.9273\n",
      "Epoch 41/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1405 - accuracy: 0.9681\n",
      "Epoch 41: val_accuracy improved from 0.93512 to 0.93736, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1426 - accuracy: 0.9664 - val_loss: 0.2049 - val_accuracy: 0.9374\n",
      "Epoch 42/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1388 - accuracy: 0.9696\n",
      "Epoch 42: val_accuracy did not improve from 0.93736\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9695 - val_loss: 0.2024 - val_accuracy: 0.9374\n",
      "Epoch 43/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1365 - accuracy: 0.9702\n",
      "Epoch 43: val_accuracy improved from 0.93736 to 0.94183, saving model to best_model.keras\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1381 - accuracy: 0.9690 - val_loss: 0.1999 - val_accuracy: 0.9418\n",
      "Epoch 44/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1369 - accuracy: 0.9693\n",
      "Epoch 44: val_accuracy did not improve from 0.94183\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1363 - accuracy: 0.9695 - val_loss: 0.2066 - val_accuracy: 0.9284\n",
      "Epoch 45/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1357 - accuracy: 0.9713\n",
      "Epoch 45: val_accuracy did not improve from 0.94183\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1353 - accuracy: 0.9715 - val_loss: 0.2000 - val_accuracy: 0.9351\n",
      "Epoch 46/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1319 - accuracy: 0.9716\n",
      "Epoch 46: val_accuracy did not improve from 0.94183\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1317 - accuracy: 0.9709 - val_loss: 0.2121 - val_accuracy: 0.9273\n",
      "Epoch 47/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1321 - accuracy: 0.9722\n",
      "Epoch 47: val_accuracy did not improve from 0.94183\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1312 - accuracy: 0.9723 - val_loss: 0.2024 - val_accuracy: 0.9318\n",
      "Epoch 48/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1295 - accuracy: 0.9699\n",
      "Epoch 48: val_accuracy did not improve from 0.94183\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1300 - accuracy: 0.9704 - val_loss: 0.1934 - val_accuracy: 0.9396\n",
      "Epoch 49/50\n",
      "106/112 [===========================>..] - ETA: 0s - loss: 0.1280 - accuracy: 0.9702\n",
      "Epoch 49: val_accuracy did not improve from 0.94183\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1280 - accuracy: 0.9706 - val_loss: 0.1979 - val_accuracy: 0.9329\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9718\n",
      "Epoch 50: val_accuracy did not improve from 0.94183\n",
      "112/112 [==============================] - 1s 10ms/step - loss: 0.1270 - accuracy: 0.9718 - val_loss: 0.2011 - val_accuracy: 0.9351\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create and compile the best model using the best hyperparameters\n",
    "model = create_single_neuron_model(input_shape=(image_size[0], image_size[1], 3))  # 3 for RGB channels\n",
    "train_generator, val_generator = load_and_preprocess_data(data_dir, image_size)\n",
    "history = train_model(model, train_generator, val_generator, optimizer=best_hyperparams['optimizer'], batch_size=batch_size, epochs=best_hyperparams['epochs'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:25:50.049485Z",
     "start_time": "2024-03-08T20:24:51.159420Z"
    }
   },
   "id": "498877b5ec5317a5",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 7: Plot the training history to see accuracy and loss curves\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:26:01.792719Z",
     "start_time": "2024-03-08T20:26:01.551444Z"
    }
   },
   "id": "b6f373f7d367a09f",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 8: Evaluate the model on the test set\n",
    "def evaluate_model(model, test_generator):\n",
    "    model.load_weights('best_neuron.keras')\n",
    "    loss, accuracy = model.evaluate(test_generator)\n",
    "    print('Test Loss: {}, Test Accuracy: {}'.format(loss, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:26:43.011885Z",
     "start_time": "2024-03-08T20:26:43.008337Z"
    }
   },
   "id": "d5fdd546fb31b476",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1999 - accuracy: 0.9418\n",
      "Test Loss: 0.1998700499534607, Test Accuracy: 0.9418344497680664\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_generator = val_generator\n",
    "evaluate_model(model, test_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:26:44.804105Z",
     "start_time": "2024-03-08T20:26:44.491004Z"
    }
   },
   "id": "5891b08b910410f3",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 2: Define the model with multiple layers\n",
    "def create_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:35:42.896364Z",
     "start_time": "2024-03-08T20:35:42.891864Z"
    }
   },
   "id": "23763b04e193aa6d",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 3: Train the model with early stopping\n",
    "def train_model(model, train_generator, val_generator, batch_size=32, max_epochs=100, min_accuracy=0.95):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpoint = ModelCheckpoint('multiple_layers.keras', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, mode='max', verbose=1)  # Stop if val_accuracy stops improving for 5 epochs\n",
    "    history = model.fit(train_generator, epochs=max_epochs, batch_size=batch_size, validation_data=val_generator, callbacks=[checkpoint, early_stopping])\n",
    "    \n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:35:44.770591Z",
     "start_time": "2024-03-08T20:35:44.766839Z"
    }
   },
   "id": "e8aaed16cbee8baf",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3576 images belonging to 2 classes.\n",
      "Found 894 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Load and preprocess the data\n",
    "image_size = (32, 32)\n",
    "batch_size = 32\n",
    "\n",
    "def load_and_preprocess_data(data_dir, image_size):\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "    train_generator = datagen.flow_from_directory(data_dir, target_size=image_size, batch_size=batch_size, class_mode='binary', subset='training')\n",
    "    val_generator = datagen.flow_from_directory(data_dir, target_size=image_size, batch_size=batch_size, class_mode='binary', subset='validation')\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n",
    "train_generator, val_generator = load_and_preprocess_data(data_dir, image_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:35:46.567254Z",
     "start_time": "2024-03-08T20:35:46.464782Z"
    }
   },
   "id": "9adca931f3b2b28e",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 15, 15, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 2, 2, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167233 (653.25 KB)\n",
      "Trainable params: 167233 (653.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create and compile the model\n",
    "model = create_model(input_shape=(image_size[0], image_size[1], 3))  # 3 for RGB channels\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:35:48.783388Z",
     "start_time": "2024-03-08T20:35:48.713316Z"
    }
   },
   "id": "c037f61c71e459db",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.7640\n",
      "Epoch 1: val_accuracy improved from -inf to 0.93512, saving model to multiple_layers.keras\n",
      "112/112 [==============================] - 2s 13ms/step - loss: 0.4550 - accuracy: 0.7640 - val_loss: 0.1752 - val_accuracy: 0.9351\n",
      "Epoch 2/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9796\n",
      "Epoch 2: val_accuracy improved from 0.93512 to 0.97092, saving model to multiple_layers.keras\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.0668 - accuracy: 0.9793 - val_loss: 0.0729 - val_accuracy: 0.9709\n",
      "Epoch 3/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9879\n",
      "Epoch 3: val_accuracy improved from 0.97092 to 0.97651, saving model to multiple_layers.keras\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.0395 - accuracy: 0.9880 - val_loss: 0.0736 - val_accuracy: 0.9765\n",
      "Epoch 4/100\n",
      "110/112 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9935\n",
      "Epoch 4: val_accuracy did not improve from 0.97651\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0844 - val_accuracy: 0.9720\n",
      "Epoch 5/100\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9929\n",
      "Epoch 5: val_accuracy improved from 0.97651 to 0.98546, saving model to multiple_layers.keras\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.0199 - accuracy: 0.9930 - val_loss: 0.0375 - val_accuracy: 0.9855\n",
      "Epoch 6/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9997\n",
      "Epoch 6: val_accuracy improved from 0.98546 to 0.98993, saving model to multiple_layers.keras\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0480 - val_accuracy: 0.9899\n",
      "Epoch 7/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 7: val_accuracy did not improve from 0.98993\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0892 - val_accuracy: 0.9810\n",
      "Epoch 8/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 8: val_accuracy did not improve from 0.98993\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0356 - val_accuracy: 0.9888\n",
      "Epoch 9/100\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.0078 - accuracy: 0.9971\n",
      "Epoch 9: val_accuracy improved from 0.98993 to 0.99217, saving model to multiple_layers.keras\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.0327 - val_accuracy: 0.9922\n",
      "Epoch 10/100\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9986\n",
      "Epoch 10: val_accuracy did not improve from 0.99217\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0359 - val_accuracy: 0.9899\n",
      "Epoch 11/100\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 11: val_accuracy did not improve from 0.99217\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0257 - val_accuracy: 0.9911\n",
      "Epoch 12/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9983\n",
      "Epoch 12: val_accuracy did not improve from 0.99217\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0321 - val_accuracy: 0.9899\n",
      "Epoch 13/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 13: val_accuracy did not improve from 0.99217\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0683 - val_accuracy: 0.9832\n",
      "Epoch 14/100\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 0.0161 - accuracy: 0.9962\n",
      "Epoch 14: val_accuracy did not improve from 0.99217\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.0183 - val_accuracy: 0.9922\n",
      "Epoch 15/100\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 15: val_accuracy did not improve from 0.99217\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0972 - val_accuracy: 0.9776\n",
      "Epoch 16/100\n",
      "107/112 [===========================>..] - ETA: 0s - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 16: val_accuracy did not improve from 0.99217\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0378 - val_accuracy: 0.9888\n",
      "Epoch 17/100\n",
      "111/112 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9960\n",
      "Epoch 17: val_accuracy improved from 0.99217 to 0.99441, saving model to multiple_layers.keras\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.0319 - val_accuracy: 0.9944\n",
      "Epoch 18/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 18: val_accuracy did not improve from 0.99441\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9933\n",
      "Epoch 19/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 4.6572e-04 - accuracy: 1.0000\n",
      "Epoch 19: val_accuracy did not improve from 0.99441\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 4.5423e-04 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9944\n",
      "Epoch 20/100\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 2.3100e-04 - accuracy: 1.0000\n",
      "Epoch 20: val_accuracy did not improve from 0.99441\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 2.2389e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9933\n",
      "Epoch 21/100\n",
      "108/112 [===========================>..] - ETA: 0s - loss: 1.7484e-04 - accuracy: 1.0000\n",
      "Epoch 21: val_accuracy did not improve from 0.99441\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 1.6962e-04 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9933\n",
      "Epoch 22/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 1.4383e-04 - accuracy: 1.0000\n",
      "Epoch 22: val_accuracy did not improve from 0.99441\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 1.4146e-04 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9933\n",
      "Epoch 23/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 1.2181e-04 - accuracy: 1.0000\n",
      "Epoch 23: val_accuracy did not improve from 0.99441\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 1.1936e-04 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9933\n",
      "Epoch 24/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 9.9679e-05 - accuracy: 1.0000\n",
      "Epoch 24: val_accuracy did not improve from 0.99441\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 1.0036e-04 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9933\n",
      "Epoch 25/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 8.7264e-05 - accuracy: 1.0000\n",
      "Epoch 25: val_accuracy did not improve from 0.99441\n",
      "112/112 [==============================] - 1s 12ms/step - loss: 8.5320e-05 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9933\n",
      "Epoch 26/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 7.7313e-05 - accuracy: 1.0000\n",
      "Epoch 26: val_accuracy did not improve from 0.99441\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 7.5378e-05 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9933\n",
      "Epoch 27/100\n",
      "109/112 [============================>.] - ETA: 0s - loss: 6.7139e-05 - accuracy: 1.0000\n",
      "Epoch 27: val_accuracy did not improve from 0.99441\n",
      "112/112 [==============================] - 1s 11ms/step - loss: 6.5685e-05 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9933\n",
      "Epoch 27: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the model\n",
    "history = train_model(model, train_generator, val_generator, batch_size=batch_size, max_epochs=100, min_accuracy=0.95)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:36:28.959532Z",
     "start_time": "2024-03-08T20:35:52.235145Z"
    }
   },
   "id": "fb428977e28b3acf",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 7: Plot the training history to see accuracy and loss curves\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:36:36.256025Z",
     "start_time": "2024-03-08T20:36:36.024242Z"
    }
   },
   "id": "b35d2a10c2618e53",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 8: Evaluate the model on the test set\n",
    "def evaluate_model(model, test_generator):\n",
    "    model.load_weights('multiple_layers.keras')\n",
    "    loss, accuracy = model.evaluate(test_generator)\n",
    "    print('Test Loss: {}, Test Accuracy: {}'.format(loss, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:36:40.283220Z",
     "start_time": "2024-03-08T20:36:40.279219Z"
    }
   },
   "id": "33f49d82b40e39fd",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0319 - accuracy: 0.9944\n",
      "Test Loss: 0.03190184384584427, Test Accuracy: 0.9944071769714355\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_generator = val_generator\n",
    "evaluate_model(model, test_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T20:36:42.581662Z",
     "start_time": "2024-03-08T20:36:42.213138Z"
    }
   },
   "id": "ae610077b4f2c577",
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
